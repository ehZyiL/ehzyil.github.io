{"meta":{"title":"ehzyil's blog","subtitle":"","description":"test description","author":"John Doe","url":"https://blog.ehzyil.xyz","root":"/"},"pages":[{"title":"","date":"2024-01-06T04:54:46.223Z","updated":"2024-01-06T04:54:46.223Z","comments":true,"path":"about/index.html","permalink":"https://blog.ehzyil.xyz/about/index.html","excerpt":"","text":"个人简介昵称：ehzyil性别：男爱好：跑步"},{"title":"所有分类","date":"2024-01-06T04:54:46.223Z","updated":"2024-01-06T04:54:46.223Z","comments":true,"path":"categories/index.html","permalink":"https://blog.ehzyil.xyz/categories/index.html","excerpt":"","text":""},{"title":"","date":"2024-01-06T04:54:46.223Z","updated":"2024-01-06T04:54:46.223Z","comments":true,"path":"daily-attendance/index.html","permalink":"https://blog.ehzyil.xyz/daily-attendance/index.html","excerpt":"","text":"2023年10月 2023年10月 2023年10月21日将博客部署到cloudflare上。配置小工具的域名。优化图床界面和网盘设置。总结:收货很少。2023年10月20日总结:无心学习，搞各种对我来说新奇的东西，买了域名，搭建了图床，重新配置MS365E5并且搭建了onedrive的个人网盘，但功能较少还需要完善。2023年10月19日做了一道算法题。总结前几天的刷题笔记写了一道无重复字符的最长子串和删除倒数节点算法题。写了保融的朴朴的和一家对日开发公司的面试题不知道能不能过。打卡： 多邻国15min 靠墙站10min 总结:这两天学到了新的算法思想，滑动窗口和快慢指针。精神状态比前两天有进步，想的也少了。2023年10月18日下午配置ruoyi,配置若依所需的docker环境，跑起来了。看了看昨天写的两道算法题，最长公共子序列太难了。。。打卡： 多邻国10min 靠墙站10min 爬4*26层楼梯 总结：面试的时候脑子一坨屎。2023年10月17日上午面了个试，一坨狗屎。整理之前的笔记。打卡： 多邻国15min 靠墙站15min 爬4*26层楼梯 2023年10月16日写了几道算法题，使用递归实现翻转链表还是头痛。。。似懂非懂Spring Boot整合Quartz实现动态定时任务。投100简历。打卡： 多邻国15min 靠墙站15min 总结：感觉自己肚里没有墨水，需要积累，今天过得一般，晚上回去别拿手机上床了。2023年10月15日找毕设导师学习Quartz的使用与基础知识，明白了blog项目中定时任务的实现方式。找到了下一个学习的项目，学习完成后可以将其融合进blog项目。打卡： 多邻国15min 靠墙站15min 总结：昨天通知开始找毕设导师，询问了几个老师的意见，想着晚上打扰老师周六的生活不好，就通过wx去联系导师，没想到等到添加上好友之后，导师的名额都满了...于是上午通过打电话联系导师...下次做事不要为别人想太多，多关注自己的利益2023年10月14日全天摆烂！！！废物一个2023年10月13日学习单路递归和多路递归。刷题：二分查找、冒泡排序、插入排序、汉诺塔、杨辉三角，明天整理笔记。投若干简历。做了个测评个在线笔试，难死我！！！。打卡： 多邻国15min 靠墙站15min 做了在线笔试，做完直接摆烂，明天再学。 2023年10月12日学习单链表(带哨兵)、双向链表(带哨兵)、环形链表(带哨兵)并整理代码。投若干简历。整理idea创建jsp项目的方法。链表翻转，三种方法只会最简单的。打卡： 多邻国10min 靠墙站10min 破戒了！！！ 我觉得我应该列个象限表把重要和不重要的事情列出来，再做，不然想到什么就是什么。2023年10月11日学习数组和单链表。学习二分查找并记录笔记。投递若干简历跑步8k打卡： 多邻国15min 靠墙站10min 二分查找-力扣 704 题&#x2F;搜索插入位置-力扣 35 题&#x2F;搜索开始结束位置-力扣 34 题 总结：本打算上午学习但总被工作上的事打断，中午开始看数据结构，只看文档有些地方还有有些不明白，比如二分查找的平衡板为什么临界点不减一，晚上回来跑步、洗澡、写了三道二分法的题，明天继续坚持！2023年10月10日完善博客。投递若干简历半小时就写了一道二分法..打卡： 多邻国10min 靠墙站10min 坚持打卡博客 明天更改学习时间到早上！！！2023年10月9日改变多次后定下了博客主题并部署。投Max份简历。3.又有了学习的欲望。4.立下flag： 每天打卡多邻国至少10min 每天靠墙站10min 坚持打卡博客"},{"title":"","date":"2021-09-19T04:33:48.000Z","updated":"2024-01-06T04:54:46.223Z","comments":true,"path":"friends/index.html","permalink":"https://blog.ehzyil.xyz/friends/index.html","excerpt":"友链格式。title: xxxurl: xxxavatar: xxx","text":"友链格式。title: xxxurl: xxxavatar: xxx 收藏的链接 volantis_developervolantis_developerxaoxuuhttps://github.com/xaoxuuMHuiGhttps://github.com/MHuiGinksshttps://github.com/inkssColsrchhttps://github.com/ColsrchDrew233https://github.com/Drew233Linhk1606https://github.com/Linhk1606W4J1ehttps://github.com/W4J1ecommunity_builderxaoxuuhttps://github.com/xaoxuuMHuiGhttps://github.com/MHuiGColsrchhttps://github.com/Colsrchpennduhttps://github.com/penndu有用的网站或博客收藏夹太乱,就放这里了Hexo+Qexo+Vercel建站https://hoyue.fun/hexo_qexo.html福音戰士標題生成器https://lab.magiconch.com/eva-title/MikuTools - 工具集合https://tools.miku.ac/一个小型常用shell工具箱https://www.nodeseek.com/post-21153-1从零开始搭建个人书签导航应用：Flarehttps://soulteary.com/2022/02/23/building-a-personal-bookmark-navigation-app-from-scratch-flare.htmMS365 E5 Renew Xhttps://ms-e5.hm0420.cc/User/Home在Linux上部署kuku的tg机器人https://www.kuku.me/archives/40/在线工具箱https://tools.laoda.de/一键DD系统脚本 支持国内小鸡，长期更新https://blockxyz.notion.site/DD-fb837703b3ac4011bb2362e3a56ac148萌导航网https://www.rrnav.com/xuexiMac软件收录https://www.macat.vip/SHSSEDU-开源知识社区https://shssedu.github.io/易波叶平|https://zhaouncle.com/posts/xloghttps://xlog.app/网盘直链解析API演示https://lz.qaiu.top/ 友链 volantis_developervolantis_developerxaoxuuMHuiGxaoxuuMHuiGColsrch"},{"title":"我的动态","date":"2024-01-06T04:54:46.283Z","updated":"2024-01-06T04:54:46.283Z","comments":true,"path":"memos/index.html","permalink":"https://blog.ehzyil.xyz/memos/index.html","excerpt":"","text":"","author":"ehzyil"},{"title":"","date":"2024-01-06T04:54:46.287Z","updated":"2024-01-06T04:54:46.287Z","comments":true,"path":"shuoshuo/index.html","permalink":"https://blog.ehzyil.xyz/shuoshuo/index.html","excerpt":"","text":"已废弃"},{"title":"所有标签","date":"2024-01-06T04:54:46.287Z","updated":"2024-01-06T04:54:46.287Z","comments":true,"path":"tags/index.html","permalink":"https://blog.ehzyil.xyz/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"记录SQL执行日志","slug":"2024/记录SQL执行日志","date":"2024-01-06T20:22:46.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2024/01/06/2024/记录SQL执行日志/","link":"","permalink":"https://blog.ehzyil.xyz/2024/01/06/2024/%E8%AE%B0%E5%BD%95SQL%E6%89%A7%E8%A1%8C%E6%97%A5%E5%BF%97/","excerpt":"","text":"记录SQL执行日志MybaitPlus执行日志因为技术派使用MybatisPlus作为ORM框架进行数据源的CURD，因此我们可以直接使用mybatis提供的日志输出 如开启控制台输出 mybatis: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl map-underscore-to-camel-case: true 日志结果： JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@62f94ee2] will not be managed by Spring &#x3D;&#x3D;&gt; Preparing: select * from user where id &#x3D;? &#x3D;&#x3D;&gt; Parameters: 1(Integer) &lt;&#x3D;&#x3D; Columns: id, third_account_id, user_name, password, login_type, deleted, create_time, update_time &lt;&#x3D;&#x3D; Row: 1, master, admin, admin, 0, 0, 2023-12-28 15:53:47, 2023-12-29 11:23:18 &lt;&#x3D;&#x3D; Total: 1 使用Mybatis插件Mybatis插件机制在Mybatis中，插件机制提供了非常强大的扩展能力，在sql最终执行之前，提供了四个拦截点，支持不同场景的功能扩展 Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) Mybatis插件实现流程1.实现接口Interceptorpublic class SqlStateInterceptor implements Interceptor &#123;&#125; 2.添加注解@Intercepts(value &#x3D; &#123;@Signature(type &#x3D; Executor.class, method &#x3D; &quot;query&quot;, args &#x3D; &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;), @Signature(type &#x3D; Executor.class, method &#x3D; &quot;update&quot;, args &#x3D; &#123;MappedStatement.class, Object.class&#125;), &#125;) 类上的@Intercepts注解，它表明这个类是一个mybatis的插件类，通过@Signature来指定切点 其中的type, method, args用来精确命中切点的具体方法 首先从切点为Executor，然后两个方法的执行会被拦截；这两个方法的方法名分别是query, update，参数类型也一并定义了，通过这些信息，可以精确匹配Executor接口上定义的类，如下 &#x2F;&#x2F; org.apache.ibatis.executor.Executor &#x2F;&#x2F; 对应第一个@Signature &lt;E&gt; List&lt;E&gt; query(MappedStatement var1, Object var2, RowBounds var3, ResultHandler var4) throws SQLException; &#x2F;&#x2F; 对应第二个@Signature int update(MappedStatement var1, Object var2) throws SQLException; mybatis提供了四个切点，那么他们之间有什么区别，什么样的场景选择什么样的切点呢？ 一般来讲，拦截ParameterHandler是最常见的，虽然上面的实例是拦截Executor，切点的选择，主要与它的功能强相关，想要更好的理解它，需要从mybatis的工作原理出发，这里将只做最基本的介绍，待后续源码进行详细分析 Executor：代表执行器，由它调度StatementHandler、ParameterHandler、ResultSetHandler等来执行对应的SQL，其中StatementHandler是最重要的。 StatementHandler：作用是使用数据库的Statement（PreparedStatement）执行操作，它是四大对象的核心，起到承上启下的作用，许多重要的插件都是通过拦截它来实现的。 ParameterHandler：是用来处理SQL参数的。 ResultSetHandler：是进行数据集（ResultSet）的封装返回处理的，它非常的复杂，好在不常用。 借用网上的一张mybatis执行过程来辅助说明 3.重载方法public class SqlStateInterceptor implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; return null; &#125; @Override public Object plugin(Object target) &#123; return null; &#125; @Override public void setProperties(Properties properties) &#123; &#125; &#125; 4.拦截器注册自定义的拦截器实现，还需要注册到应用中让它生效，一般有下面几种姿势 1.spring bean对象 @Bean public SqlStateInterceptor sqlStateInterceptor() &#123; return new SqlStateInterceptor(); &#125; 2.SqlSessionFactory 除了上面的姿势之外还可以直接再sql会话工厂中指定 @Bean(name &#x3D; &quot;sqlSessionFactory&quot;) public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean &#x3D; new SqlSessionFactoryBean(); bean.setDataSource(dataSource); bean.setMapperLocations( &#x2F;&#x2F; 设置mybatis的xml所在位置，这里使用mybatis注解方式，没有配置xml文件 new PathMatchingResourcePatternResolver().getResources(&quot;classpath*:mapping&#x2F;*.xml&quot;)); &#x2F;&#x2F; 注册typehandler，供全局使用 bean.setTypeHandlers(new Timestamp2LongHandler()); bean.setPlugins(new SqlStatInterceptor()); return bean.getObject(); &#125; 3.xml配置 对于习惯使用myabtis的同学而言，这一种方式不少见，直接再myabtis-config.xml中进行定义 @Bean public SqlStateInterceptor sqlStateInterceptor() &#123; return new SqlStateInterceptor(); &#125; 实现package com.example.senstive.senstive; import com.alibaba.druid.pool.DruidPooledPreparedStatement; import com.baomidou.mybatisplus.core.MybatisParameterHandler; import com.example.senstive.util.DateUtil; import com.example.senstive.util.DruidCheckUtil; import com.mysql.cj.MysqlConnection; import com.zaxxer.hikari.pool.HikariProxyConnection; import com.zaxxer.hikari.pool.HikariProxyPreparedStatement; import lombok.extern.slf4j.Slf4j; import nonapi.io.github.classgraph.reflection.ReflectionUtils; import org.apache.ibatis.executor.statement.StatementHandler; import org.apache.ibatis.mapping.BoundSql; import org.apache.ibatis.mapping.MappedStatement; import org.apache.ibatis.mapping.ParameterMapping; import org.apache.ibatis.mapping.ParameterMode; import org.apache.ibatis.plugin.*; import org.apache.ibatis.reflection.MetaObject; import org.apache.ibatis.scripting.defaults.DefaultParameterHandler; import org.apache.ibatis.session.Configuration; import org.apache.ibatis.session.ResultHandler; import org.springframework.util.CollectionUtils; import java.sql.Connection; import java.sql.Statement; import java.util.Date; import java.util.List; import java.util.Properties; import java.util.regex.Matcher; // Define a custom MyBatis plugin to handle data masking. /** * SQL状态拦截器 */ @Intercepts(&#123; @Signature(type = StatementHandler.class, method = \"query\", args = &#123;Statement.class, ResultHandler.class&#125;), @Signature(type = StatementHandler.class, method = \"update\", args = &#123;Statement.class&#125;) &#125;) @Slf4j public class SqlStateInterceptor implements Interceptor &#123; /** * 拦截方法 * * @param invocation 调用的Invocation对象 * @return Object * @throws Throwable 异常 */ @Override public Object intercept(Invocation invocation) throws Throwable &#123; long time = System.currentTimeMillis(); final List&lt;Object> results = (List&lt;Object>) invocation.proceed(); if (results.isEmpty()) &#123; return results; &#125; StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); String sql = buildSql(statementHandler); //判断数据库连接池类型 Object[] args = invocation.getArgs(); String uname = \"\"; if (args[0] instanceof HikariProxyPreparedStatement) &#123; HikariProxyConnection connection = (HikariProxyConnection) ((HikariProxyPreparedStatement) invocation.getArgs()[0]).getConnection(); uname = connection.getMetaData().getUserName(); &#125; else if (DruidCheckUtil.hasDuridPkg()) &#123; if (args[0] instanceof DruidPooledPreparedStatement) &#123; Connection connection = ((DruidPooledPreparedStatement) args[0]).getStatement().getConnection(); if (connection instanceof MysqlConnection) &#123; Properties properties = ((MysqlConnection) connection).getProperties(); uname = properties.getProperty(\"user\"); &#125; &#125; &#125; Object rs = null; try &#123; rs = invocation.proceed(); &#125; catch (Throwable e) &#123; log.error(\"error sql: \" + sql, e); throw e; &#125; finally &#123; long cost = System.currentTimeMillis() - time; sql = this.replaceContinueSpace(sql); // 这个方法的总耗时 log.info(\"\\n\\n ============= \\nsql ----> &#123;&#125;\\n&#123;&#125;\\nuser ----> &#123;&#125;\\ncost ----> &#123;&#125;\\n ============= \\n\", sql, getResult(rs.toString()), uname, cost); &#125; return rs; &#125; /** * 获取结果 * * @param input 输入 * @return 结果 */ private String getResult(String input) &#123; return input.substring(input.indexOf(\"(\") + 1, input.lastIndexOf(\")\")); &#125; /** * 替换连续的空白 * * @param str 字符串 * @return 替换后的字符串 */ private String replaceContinueSpace(String str) &#123; StringBuilder builder = new StringBuilder(str.length()); boolean preSpace = false; for (int i = 0, len = str.length(); i &lt; len; i++) &#123; char ch = str.charAt(i); boolean isSpace = Character.isWhitespace(ch); if (preSpace &amp;&amp; isSpace) &#123; continue; &#125; if (preSpace) &#123; // 前面的是空白字符，当前的不是的 preSpace = false; builder.append(ch); &#125; else if (isSpace) &#123; // 当前字符为空白字符，前面的那个不是的 preSpace = true; builder.append(\" \"); &#125; else &#123; // 前一个和当前字符都非空白字符 builder.append(ch); &#125; &#125; return builder.toString(); &#125; /** * 构建SQL * * @param statementHandler StatementHandler对象 * @return SQL语句 */ private String buildSql(StatementHandler statementHandler) &#123; BoundSql boundSql = statementHandler.getBoundSql(); Configuration configuration = null; if (statementHandler.getParameterHandler() instanceof DefaultParameterHandler) &#123; DefaultParameterHandler handler = (DefaultParameterHandler) statementHandler.getParameterHandler(); configuration = (Configuration) new ReflectionUtils().getFieldVal(false, handler, \"configuration\"); &#125; else if (statementHandler.getParameterHandler() instanceof MybatisParameterHandler) &#123; MybatisParameterHandler paramHandler = (MybatisParameterHandler) statementHandler.getParameterHandler(); configuration = ((MappedStatement) new ReflectionUtils().getFieldVal(false, paramHandler, \"mappedStatement\")).getConfiguration(); &#125; if (configuration == null) &#123; return boundSql.getSql(); &#125; return buildSql(boundSql, configuration); &#125; /** * 构建SQL * * @param boundSql BoundSql对象 * @param configuration Configuration对象 * @return SQL语句 */ private String buildSql(BoundSql boundSql, Configuration configuration) &#123; String sql = boundSql.getSql(); //获取参数 Object parameterObject = boundSql.getParameterObject(); List&lt;ParameterMapping> parameterMappings = boundSql.getParameterMappings(); //没有参数直接返回 if (CollectionUtils.isEmpty(parameterMappings) || parameterObject == null) &#123; return sql; &#125; MetaObject mo = configuration.newMetaObject(boundSql.getParameterObject()); for (ParameterMapping parameterMapping : parameterMappings) &#123; //只拦截 输出参数 if (parameterMapping.getMode() == ParameterMode.OUT) &#123; continue; &#125; //参数值 Object value; //获取参数名称 String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; value = boundSql.getAdditionalParameter(propertyName); &#125; else if (configuration.getTypeHandlerRegistry().hasTypeHandler(parameterObject.getClass())) &#123; //如果是单个值则直接赋值 value = parameterObject; &#125; else &#123; value = mo.getValue(propertyName); &#125; String param = Matcher.quoteReplacement(getParameter(value)); sql = sql.replaceFirst(\"\\\\?\", param); &#125; sql += \";\"; return sql; &#125; /** * 获取参数值 * * @param parameter 参数 * @return 参数值 */ private String getParameter(Object parameter) &#123; if (parameter instanceof String) &#123; return \"'\" + parameter + \"'\"; &#125; else if (parameter instanceof Date) &#123; return \"'\" + DateUtil.format(DateUtil.DB_FORMAT, ((Date) parameter).getTime()) + \"'\"; &#125; else if (parameter instanceof java.util.Date) &#123; return \"'\" + DateUtil.format(DateUtil.DB_FORMAT, ((java.util.Date) parameter).getTime()) + \"'\"; &#125; return parameter.toString(); &#125; /** * 插件方法 * * @param o 对象 * @return 插件后的对象 */ @Override public Object plugin(Object o) &#123; return Plugin.wrap(o, this); &#125; /** * 设置属性 * * @param properties 属性 */ @Override public void setProperties(Properties properties) &#123; &#125; &#125; 当插件的intercept()方法被调用时，它会执行拦截的SQL语句。在这个方法中，会首先获取拦截的SQL语句并根据数据库连接池的类型获取登录用户的用户名。然后，会执行原始的SQL语句，并在执行过程中捕获任何异常并记录日志。最后，会返回原始SQL语句的结果。插件的plugin()方法用于将插件应用到目标对象上。它使用MyBatis提供的Plugin类对目标对象进行包装，从而实现插件的功能。setProperties()方法用于设置插件的属性。 为什么 buildSql()要获取Configuration获取 Configuration 对象是为了能够访问 MyBatis 的配置信息，例如： 类型处理器注册表 (TypeHandlerRegistry) 对象工厂 (ObjectFactory) 对象包装工厂 (ObjectWrapperFactory) 插件列表 (InterceptorChain) 映射语句注册表 (MappedStatementRegistry) 环境 (Environment) 在 buildSql() 方法中，需要使用 Configuration 对象来获取类型处理器注册表，以便能够将参数值转换为数据库可识别的格式。 例如，在以下代码中，使用 Configuration 对象来获取类型处理器注册表，并使用类型处理器注册表来获取字符串类型参数的类型处理器： Configuration configuration = ...; TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry(); TypeHandler&lt;String> stringTypeHandler = typeHandlerRegistry.getTypeHandler(String.class); 然后，可以使用 stringTypeHandler 来将字符串类型参数值转换为数据库可识别的格式。 String parameterValue = ...; String databaseValue = stringTypeHandler.setParameter(parameterValue, null); 获取 Configuration 对象还可以用于访问其他 MyBatis 配置信息，例如： 允许自动映射的别名列表 (typeAliases) 允许自动映射的结果映射列表 (resultMaps) 允许自动映射的缓存列表 (caches) 这些信息可以用于构建更复杂的 SQL 语句或执行其他操作。 下列代码的作用MetaObject mo &#x3D; configuration.newMetaObject(boundSql.getParameterObject()); for (ParameterMapping parameterMapping : parameterMappings) &#123; &#x2F;&#x2F;只拦截 输出参数 if (parameterMapping.getMode() &#x3D;&#x3D; ParameterMode.OUT) &#123; continue; &#125; &#x2F;&#x2F;参数值 Object value; &#x2F;&#x2F;获取参数名称 String propertyName &#x3D; parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; value &#x3D; boundSql.getAdditionalParameter(propertyName); &#125; else if (configuration.getTypeHandlerRegistry().hasTypeHandler(parameterObject.getClass())) &#123; &#x2F;&#x2F;如果是单个值则直接赋值 value &#x3D; parameterObject; &#125; else &#123; value &#x3D; mo.getValue(propertyName); &#125; String param &#x3D; Matcher.quoteReplacement(getParameter(value)); sql &#x3D; sql.replaceFirst(&quot;\\\\?&quot;, param); &#125; 这段代码用于将 MyBatis 查询语句中的参数值替换为实际值。 首先，使用 configuration.newMetaObject(boundSql.getParameterObject()) 创建一个 MetaObject 对象，该对象封装了查询语句的参数对象。 然后，遍历查询语句中的参数映射列表 (parameterMappings)。对于每个参数映射，如果参数模式为 ParameterMode.OUT，则跳过该参数，因为输出参数不需要替换。 对于其他参数，根据参数映射的属性名称 (propertyName) 获取参数值。参数值可能来自以下几个地方： 如果查询语句中包含附加参数，则从附加参数中获取。 如果 MyBatis 配置中注册了参数对象的类型处理器，则直接使用参数对象作为参数值。 否则，从参数对象中获取参数值。 最后，使用 Matcher.quoteReplacement(getParameter(value)) 将参数值转换为字符串，并用该字符串替换查询语句中的第一个问号 (?)。 工具类package com.example.senstive.util; import java.sql.Timestamp; import java.time.Instant; import java.time.LocalDateTime; import java.time.ZoneId; import java.time.format.DateTimeFormatter; public class DateUtil &#123; public static final DateTimeFormatter UTC_FORMAT &#x3D; DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS&#39;Z&#39;&quot;); public static final DateTimeFormatter DB_FORMAT &#x3D; DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss.SSS&quot;); public static final DateTimeFormatter BLOG_TIME_FORMAT &#x3D; DateTimeFormatter.ofPattern(&quot;yyyy年MM月dd日 HH:mm&quot;); public static final DateTimeFormatter BLOG_DATE_FORMAT &#x3D; DateTimeFormatter.ofPattern(&quot;yyyy年MM月dd日&quot;); &#x2F;** * 一天对应的毫秒数 *&#x2F; public static final Long ONE_DAY_MILL &#x3D; 86400_000L; public static final Long ONE_DAY_SECONDS &#x3D; 86400L; public static final Long ONE_MONTH_SECONDS &#x3D; 31 * 86400L; public static final Long THREE_DAY_MILL &#x3D; 3 * ONE_DAY_MILL; &#x2F;** * 毫秒转日期 * * @param timestamp * @return *&#x2F; public static String time2day(long timestamp) &#123; return format(BLOG_TIME_FORMAT, timestamp); &#125; public static String time2day(Timestamp timestamp) &#123; return time2day(timestamp.getTime()); &#125; public static LocalDateTime time2LocalTime(long timestamp) &#123; return LocalDateTime.ofInstant(Instant.ofEpochMilli(timestamp), ZoneId.systemDefault()); &#125; public static String time2utc(long timestamp) &#123; return format(UTC_FORMAT, timestamp); &#125; public static String time2date(long timestamp) &#123; return format(BLOG_DATE_FORMAT, timestamp); &#125; public static String time2date(Timestamp timestamp) &#123; return time2date(timestamp.getTime()); &#125; public static String format(DateTimeFormatter format, long timestamp) &#123; LocalDateTime time &#x3D; time2LocalTime(timestamp); return format.format(time); &#125; &#125; import org.springframework.util.ClassUtils public class DruidCheckUtil &#123; &#x2F;** * 判断是否包含durid相关的数据包 * * @return *&#x2F; public static boolean hasDuridPkg() &#123; return ClassUtils.isPresent(&quot;com.alibaba.druid.pool.DruidDataSource&quot;, DataSourceConfig.class.getClassLoader()); &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://blog.ehzyil.xyz/tags/Mybatis/"}],"author":"ehzyil"},{"title":"通用敏感词替换","slug":"2024/通用敏感词替换","date":"2024-01-06T20:22:46.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2024/01/06/2024/通用敏感词替换/","link":"","permalink":"https://blog.ehzyil.xyz/2024/01/06/2024/%E9%80%9A%E7%94%A8%E6%95%8F%E6%84%9F%E8%AF%8D%E6%9B%BF%E6%8D%A2/","excerpt":"","text":"本文基于开源项目sensitive-word，基础使用方法请看文档。 敏感词服务类新增一个敏感词配置类，处理自定义的敏感词、与白名单 @Data @Component @ConfigurationProperties(prefix &#x3D; &quot;forum.sensitive&quot;) public class SensitiveProperty &#123; &#x2F;** * true 表示开启敏感词校验 *&#x2F; private Boolean enable; &#x2F;** * 自定义的敏感词 *&#x2F; private List&lt;String&gt; deny; &#x2F;** * 自定义的非敏感词 *&#x2F; private List&lt;String&gt; allow; &#125; 封装敏感词的服务类，在项目启动时进行初始化 @Slf4j @Service public class SensitiveService &#123; /** * 敏感词命中计数统计 */ private static final String SENSITIVE_WORD_CNT_PREFIX = \"sensitive_word\"; private volatile SensitiveWordBs sensitiveWordBs; @Autowired private SensitiveProperty sensitiveConfig; @PostConstruct public void refresh() &#123; IWordDeny deny = () -> &#123; List&lt;String> sub = WordDenySystem.getInstance().deny(); sub.addAll(sensitiveConfig.getDeny()); return sub; &#125;; IWordAllow allow = () -> &#123; List&lt;String> sub = WordAllowSystem.getInstance().allow(); sub.addAll(sensitiveConfig.getAllow()); return sub; &#125;; sensitiveWordBs = SensitiveWordBs.newInstance() .wordDeny(deny) .wordAllow(allow) .init(); log.info(\"敏感词初始化完成!\"); &#125; /** * 判断是否包含敏感词 * * @param txt 需要校验的文本 * @return 返回命中的敏感词 */ public List&lt;String> contains(String txt) &#123; if (!BooleanUtils.isTrue(sensitiveConfig.getEnable())) &#123; return Collections.emptyList(); &#125; List&lt;String> ans = sensitiveWordBs.findAll(txt); if (CollectionUtils.isEmpty(ans)) &#123; return ans; &#125; return ans; &#125; /** * 敏感词替换 * * @param txt * @return */ public String replace(String txt) &#123; if (BooleanUtils.isTrue(sensitiveConfig.getEnable())) &#123; return sensitiveWordBs.replace(txt); &#125; return txt; &#125; /** * 查询文本中所有命中的敏感词 * * @param txt 校验文本 * @return 命中的敏感词 */ public List&lt;String> findAll(String txt) &#123; return sensitiveWordBs.findAll(txt); &#125; &#125; 调用测试在application.yml中配置敏感词 调用下列接口测试 @GetMapping(path &#x3D; &quot;sensitive&#x2F;check&quot;) public List&lt;String&gt; check(String txt) &#123; return sensitiveService.findAll(txt); &#125; @GetMapping(path &#x3D; &quot;sensitive&#x2F;contains&quot;) public List&lt;String&gt; contains(String txt) &#123; return sensitiveService.contains(txt); &#125; @GetMapping(path &#x3D; &quot;sensitive&#x2F;replace&quot;) public String replace(String txt) &#123; return sensitiveService.replace(txt); &#125; 自定义的数据库敏感词替换方案 数据脱敏是指使用各种技术手段对敏感数据进行处理，使其无法被未经授权的人员访问或使用。在实际项目中，需要数据脱敏的原因有很多，在此我们在实现Springboot项目中实现敏感词替换。 实际生产项目中使用的数据脱敏机制，为了安全以及某些大家都知道的原因，db中有很多信息是不能存储明文的，比如身份证、银行卡等需要加密之后存储到数据库中，然后再读取时，解密返回对应的明文那么如何实现呢？ 直接编码实现，每次写的时候、读取的时候手动进行加解密 ？ 实现一个通用的解决方案，比如在需要脱敏的字段上加一个标识，然后再实际写db&#x2F;从db读取时，自动实现加解密 我们这里介绍的是第二个解决方案 基于mybatis拦截器的敏感词替换实现方案整体的方案思路比较清晰： 实现一个自定义注解，放在需要脱敏的数据库实体对象的成员上 实现查询拦截器，再返回数据库内容到数据库实体对象上时，若判断成员上有对应注解，则赋值敏感词替换之后的内容 再具体的实现层，我们会增加一下缓存，减少每次都对实体对象的成员都进行判定，是否需要脱敏 具体实现实现一个自定义注解通过自定义注解，灵活地对需要脱敏的数据库实体对象成员进行标记。 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.FIELD) public @interface SensitiveField &#123; String bind() default &quot;&quot;; &#125; 实现敏感数据缓存为了提高脱敏效率，使用缓存系统存储脱敏后的数据，减少重复脱敏的计算。 敏感词缓存类： public class SensitiveMetaCache &#123; &#x2F;&#x2F; 敏感元数据缓存 private static ConcurrentHashMap&lt;String, SensitiveObjectMeta&gt; CACHE &#x3D; new ConcurrentHashMap&lt;&gt;(); &#x2F;** * 获取指定key对应的敏感元数据 * * @param key 键 * @return 指定key对应的敏感元数据 *&#x2F; public static SensitiveObjectMeta get(String key) &#123; return CACHE.get(key); &#125; &#x2F;** * 将敏感元数据放入缓存 * * @param key 键 * @param meta 敏感元数据 *&#x2F; public static void put(String key, SensitiveObjectMeta meta) &#123; CACHE.put(key, meta); &#125; &#x2F;** * 从缓存中移除指定key对应的敏感元数据 * * @param key 键 *&#x2F; public static void remove(String key) &#123; CACHE.remove(key); &#125; &#x2F;** * 检查缓存中是否存在指定key对应的敏感元数据 * * @param key 键 * @return 缓存中是否存在指定key对应的敏感元数据 *&#x2F; public static boolean contains(String key) &#123; return CACHE.containsKey(key); &#125; &#x2F;** * 将敏感元数据放入缓存，如果键已存在，则更新对应的敏感元数据 * * @param key 键 * @param meta 敏感元数据 * @return 新的敏感元数据 *&#x2F; public static SensitiveObjectMeta putIfAbsent(String key, SensitiveObjectMeta meta) &#123; return CACHE.putIfAbsent(key, meta); &#125; &#x2F;** * 从缓存中计算并获取指定key对应的敏感元数据 * * @param key 键 * @param function 计算函数 * @return 指定key对应的敏感元数据 *&#x2F; public static SensitiveObjectMeta computeIfAbsent(String key, Function&lt;String, SensitiveObjectMeta&gt; function) &#123; return CACHE.computeIfAbsent(key, function); &#125; &#125; computeIfAbsent 方法的作用是将一个键值对添加到缓存中，如果键已经存在，则不执行任何操作。 代码分解 public static SensitiveObjectMeta computeIfAbsent(String key, Function&lt;String, SensitiveObjectMeta&gt; function)：这是一个公共静态方法，它接受两个参数：key 是要添加到缓存中的键，function 是一个 lambda 表达式，用于计算键对应的值。 return CACHE.computeIfAbsent(key, function);: 使用 ConcurrentHashMap 的 computeIfAbsent 方法来将键值对添加到缓存中。如果键已经存在，则不执行任何操作。否则，使用 lambda 表达式 function 来计算键对应的值，并将键值对添加到缓存中。 @Data public class SensitiveObjectMeta &#123; private static final String JAVA_LANG_OBJECT &#x3D; &quot;java.lang.object&quot;; &#x2F;** * 是否启用脱敏 *&#x2F; private Boolean enabledSensitiveReplace; &#x2F;** * 类名 *&#x2F; private String className; &#x2F;** * 标注 SensitiveField 的成员 *&#x2F; private List&lt;SensitiveFieldMeta&gt; sensitiveFieldMetaList; &#x2F;** * 构建 SensitiveObjectMeta 对象 * * @param param 对象实例 * @return Optional&lt;SensitiveObjectMeta&gt; 可选的 SensitiveObjectMeta 对象 *&#x2F; public static Optional&lt;SensitiveObjectMeta&gt; buildSensitiveObjectMeta(Object param) &#123; if (isNull(param)) &#123; return Optional.empty(); &#125; Class&lt;?&gt; clazz &#x3D; param.getClass(); SensitiveObjectMeta sensitiveObjectMeta &#x3D; new SensitiveObjectMeta(); sensitiveObjectMeta.setClassName(clazz.getName()); List&lt;SensitiveFieldMeta&gt; sensitiveFieldMetaList &#x3D; newArrayList(); sensitiveObjectMeta.setSensitiveFieldMetaList(sensitiveFieldMetaList); boolean sensitiveField &#x3D; parseAllSensitiveField(clazz, sensitiveFieldMetaList); sensitiveObjectMeta.setEnabledSensitiveReplace(sensitiveField); return Optional.of(sensitiveObjectMeta); &#125; &#x2F;** * 解析类中的所有 SensitiveField 字段 * * @param clazz 类实例 * @param sensitiveFieldMetaList SensitiveFieldMeta 对象列表 * @return boolean 是否包含 SensitiveField *&#x2F; private static boolean parseAllSensitiveField(Class&lt;?&gt; clazz, List&lt;SensitiveFieldMeta&gt; sensitiveFieldMetaList) &#123; Class&lt;?&gt; tempClazz &#x3D; clazz; boolean hasSensitiveField &#x3D; false; while ((nonNull(tempClazz)) &amp;&amp; !JAVA_LANG_OBJECT.equalsIgnoreCase(tempClazz.getName())) &#123; for (java.lang.reflect.Field field : tempClazz.getDeclaredFields()) &#123; SensitiveField sensitiveField &#x3D; field.getAnnotation(SensitiveField.class); if (nonNull(sensitiveField)) &#123; SensitiveFieldMeta sensitiveFieldMeta &#x3D; new SensitiveFieldMeta(); sensitiveFieldMeta.setName(field.getName()); sensitiveFieldMeta.setBindField(sensitiveField.bind()); sensitiveFieldMetaList.add(sensitiveFieldMeta); hasSensitiveField &#x3D; true; &#125; &#125; tempClazz &#x3D; tempClazz.getSuperclass(); &#125; return hasSensitiveField; &#125; @Data public static class SensitiveFieldMeta &#123; &#x2F;** * 默认根据字段名，找db中同名的字段 *&#x2F; private String name; &#x2F;** * 绑定的数据库字段别名 *&#x2F; private String bindField; &#125; &#125; 实现查询拦截器在查询拦截器中，对查询结果进行拦截，并根据自定义注解对敏感数据进行脱敏处理。 拦截器的工作原理 这个拦截器的工作原理如下： 当 MyBatis 执行 SQL 语句时，拦截器会首先被调用。 拦截器会检查 SQL 语句是否需要进行敏感词替换。 如果需要进行敏感词替换，拦截器会对查询结果中的敏感词进行替换。 拦截器会将替换后的查询结果返回给 MyBatis。 代码实现细节 @Intercepts(&#123; @Signature(type = ResultSetHandler.class, method = \"handleResultSets\", args = &#123;java.sql.Statement.class&#125;) &#125;) @Component @Slf4j public class SensitiveReadInterceptor implements Interceptor &#123; private static final String MAPPED_STATEMENT = \"mappedStatement\"; @Autowired private SensitiveService sensitiveService; @Override public Object intercept(Invocation invocation) throws Throwable &#123; final List&lt;Object> results = (List&lt;Object>) invocation.proceed(); if (results.isEmpty()) &#123; return results; &#125; final ResultSetHandler statementHandler = realTarget(invocation.getTarget()); // 获取 statementHandler 对象的元对象。 final MetaObject metaObject = SystemMetaObject.forObject(statementHandler); //获取 statementHandler 对象的 MAPPED_STATEMENT 属性 final MappedStatement mappedStatement = (MappedStatement) metaObject.getValue(MAPPED_STATEMENT); // 从 results 列表中找到第一个非空元素，并将其包装在一个 Optional 对象中。 Optional firstOpt = results.stream().filter(Objects::nonNull).findFirst(); //检查 Optional 对象是否包含值 if (!firstOpt.isPresent()) &#123; return results; &#125; Object firstObject = firstOpt.get(); // 找到需要进行敏感词替换的数据库实体类的成员信息 SensitiveObjectMeta sensitiveObjectMeta = findSensitiveObjectMeta(firstObject); // 执行替换的敏感词替换 replaceSensitiveResults(results, mappedStatement, sensitiveObjectMeta); // 找到需要进行敏感词替换的数据库实体类的成员信息 return results; &#125; @Override public Object plugin(Object o) &#123; return Plugin.wrap(o, this); &#125; @Override public void setProperties(Properties properties) &#123; &#125; &#125; 拦截器注解： @Intercepts 注解用于指定拦截器要拦截的方法。在本例中，拦截器要拦截 ResultSetHandler.handleResultSets 方法。 组件扫描： @Component 注解用于将拦截器注册为 Spring Bean。 日志记录： @Slf4j 注解用于启用日志记录。 拦截方法： intercept 方法是拦截器的主方法。在这个方法中，拦截器会对查询结果进行拦截、检查是否需要进行敏感词替换、对查询结果中的敏感词进行替换，并将替换后的查询结果返回给 MyBatis。 插件方法： plugin 方法用于将拦截器包装成一个插件。 属性设置方法： setProperties 方法用于设置拦截器的属性。 final MetaObject metaObject &#x3D; SystemMetaObject.forObject(statementHandler); 这行代码的作用是获取 statementHandler 对象的元对象。 在 Java 中，元对象是一种包含了对象元数据信息的对象。元数据信息包括对象的类型、属性、方法等。 SystemMetaObject.forObject 方法可以获取一个对象的元对象。这个方法是 MetaObject 类的静态方法。 statementHandler 对象是一个 org.apache.ibatis.executor.statement.StatementHandler 对象。StatementHandler 对象负责将 SQL 语句发送到数据库并处理结果。 获取 statementHandler 对象的元对象后，就可以通过元对象来获取 statementHandler 对象的属性和方法。 查询对象中，携带有 @SensitiveField 的成员，进行敏感词替换： findSensitiveObjectMeta 方法用于查询对象中，携带有 @SensitiveField 的成员，并进行敏感词替换。 /** * 查询对象中，携带有 @SensitiveField 的成员，进行敏感词替换 * * @param firstObject 待查询的对象 * @return 返回对象的敏感词元数据 */ private SensitiveObjectMeta findSensitiveObjectMeta(Object firstObject) &#123; // 缓存中不存在，则计算键对应的值，并缓存 SensitiveMetaCache.computeIfAbsent(firstObject.getClass().getName(), s -> &#123; Optional&lt;SensitiveObjectMeta> sensitiveObjectMeta = SensitiveObjectMeta.buildSensitiveObjectMeta(firstObject); return sensitiveObjectMeta.orElse(null); &#125;); // 从缓存中获取 SensitiveObjectMeta 对象。 return SensitiveMetaCache.get(firstObject.getClass().getName()); &#125; 执行具体的敏感词替换： replaceSensitiveResults 方法用于执行具体的敏感词替换。 &#x2F;** * 执行具体的敏感词替换 * * @param results 结果列表 * @param mappedStatement MappedStatement 对象 * @param sensitiveObjectMeta SensitiveObjectMeta 对象 *&#x2F; private void replaceSensitiveResults(Collection&lt;Object&gt; results, MappedStatement mappedStatement, SensitiveObjectMeta sensitiveObjectMeta) &#123; for (Object obj : results) &#123; if (sensitiveObjectMeta.getSensitiveFieldMetaList() &#x3D;&#x3D; null) continue; MetaObject objMetaObject &#x3D; mappedStatement.getConfiguration().newMetaObject(obj); sensitiveObjectMeta.getSensitiveFieldMetaList().forEach(i -&gt; &#123; Object value &#x3D; objMetaObject.getValue(StringUtils.isBlank(i.getBindField()) ? i.getName() : i.getBindField()); if (value &#x3D;&#x3D; null) &#123; return; &#125; else if (value instanceof String) &#123; String strValue &#x3D; (String) value; &#x2F;&#x2F; 替换字符串中的敏感词 String processVal &#x3D; sensitiveService.replace(strValue); objMetaObject.setValue(i.getName(), processVal); &#125; else if (value instanceof Collection) &#123; Collection listValue &#x3D; (Collection) value; if (CollectionUtils.isNotEmpty(listValue)) &#123; Optional firstValOpt &#x3D; listValue.stream().filter(Objects::nonNull).findFirst(); if (firstValOpt.isPresent()) &#123; &#x2F;&#x2F; 找到第一个非空元素的敏感对象成员信息; SensitiveObjectMeta valSensitiveObjectMeta &#x3D; findSensitiveObjectMeta(firstValOpt.get()); if (Boolean.TRUE.equals(valSensitiveObjectMeta.getEnabledSensitiveReplace()) &amp;&amp; CollectionUtils.isNotEmpty(valSensitiveObjectMeta.getSensitiveFieldMetaList())) &#123; &#x2F;&#x2F; 递归进行敏感词替换 replaceSensitiveResults(listValue, mappedStatement, valSensitiveObjectMeta); &#125; &#125; &#125; &#125; else if (ClassUtils.isPrimitiveOrWrapper(value.getClass())) &#123; &#x2F;&#x2F; 对于非基本类型的，需要对其内部进行敏感词替换 SensitiveObjectMeta valSensitiveObjectMeta &#x3D; findSensitiveObjectMeta(value); if (Boolean.TRUE.equals(valSensitiveObjectMeta.getEnabledSensitiveReplace()) &amp;&amp; CollectionUtils.isNotEmpty(valSensitiveObjectMeta.getSensitiveFieldMetaList())) &#123; replaceSensitiveResults(newArrayList(value), mappedStatement, valSensitiveObjectMeta); &#125; &#125; &#125;); &#125; &#125; 获取代理对象的真实目标对象： realTarget 方法用于获取代理对象的真实目标对象。 &#x2F;** * 获取代理对象的真实目标对象。 * * @param target * @param &lt;T&gt; * @return *&#x2F; public static &lt;T&gt; T realTarget(Object target) &#123; if (Proxy.isProxyClass(target.getClass())) &#123; &#x2F;&#x2F;获取一个对象的元对象 MetaObject metaObject &#x3D; SystemMetaObject.forObject(target); &#x2F;&#x2F;如果 target 是一个代理对象，那么 realTarget 方法会递归地获取代理对象的真实目标对象，直到找到一个不是代理对象的对象。 return realTarget(metaObject.getValue(&quot;h.target&quot;)); &#125; return (T) target; &#125; 在 Java 中，代理对象是一种可以代替真实对象执行操作的对象。代理对象可以用来增强真实对象的某些功能，例如添加日志记录、安全检查等。 Proxy.isProxyClass 方法可以判断一个对象是否是一个代理对象。如果 target 是一个代理对象，那么 realTarget 方法会递归地获取代理对象的真实目标对象，直到找到一个不是代理对象的对象。 SystemMetaObject.forObject 方法可以获取一个对象的元对象。元对象包含了该对象的一些元数据信息，例如对象的类型、属性、方法等。 getValue 方法可以从元对象中获取一个属性的值。在 realTarget 方法中，getValue 方法被用来获取代理对象的 h.target 属性的值。h.target 属性的值就是代理对象的真实目标对象。 最后，realTarget 方法将代理对象的真实目标对象返回。 这个方法可以用于各种场景，例如： 获取代理对象的真实目标对象，以便直接调用真实目标对象的方法。 在代理对象上添加额外的功能，例如日志记录、安全检查等。 在代理对象上进行性能优化，例如缓存代理对象的方法调用结果。 测试在实体类上添加注解 @Data @EqualsAndHashCode(callSuper &#x3D; false) @Accessors(chain &#x3D; true) @TableName(&quot;user&quot;) public class User implements Serializable &#123; private static final long serialVersionUID &#x3D; 1L; List&lt;User&gt; users; &#x2F;** * 主键ID *&#x2F; @TableId(value &#x3D; &quot;id&quot;, type &#x3D; IdType.AUTO) private Integer id; &#x2F;** * 第三方用户ID *&#x2F; @SensitiveField(bind &#x3D; &quot;thirdAccountId&quot;) private String thirdAccountId; &#x2F;** * 用户名 *&#x2F; @SensitiveField(bind &#x3D; &quot;userName&quot;) private String userName; &#x2F;** * 密码 *&#x2F; @SensitiveField() private String password; &#x2F;** * 登录方式: 0-微信登录，1-账号密码登录 *&#x2F; @SensitiveField() private Integer loginType; &#x2F;** * 是否删除 *&#x2F; private Integer deleted; &#x2F;** * 创建时间 *&#x2F; private LocalDateTime createTime; &#x2F;** * 最后更新时间 *&#x2F; private LocalDateTime updateTime; &#125; @SensitiveField()的字段可以指定也可以不指定，因为上述代码中已经做了判断 Object value &#x3D; objMetaObject.getValue(StringUtils.isBlank(i.getBindField()) ? i.getName() : i.getBindField()); 调用下述接口 @GetMapping() public Object getAllUsers() &#123; return userService.getAllUsers(); &#125; SQL日志如下 &#x3D;&#x3D;&gt; Preparing: select * from user &#x3D;&#x3D;&gt; Parameters: &lt;&#x3D;&#x3D; Columns: id, third_account_id, user_name, password, login_type, deleted, create_time, update_time &lt;&#x3D;&#x3D; Row: 1, fuckman, admin, admin, 0, 0, 2023-12-28 15:53:47, 2024-01-04 12:19:49 &lt;&#x3D;&#x3D; Row: 2, a7cb7200-0f85-4dd5-845c-700f3740e91, admin1, admin1, 10, 0, 2023-12-28 15:53:47, 2024-01-04 12:53:47 &lt;&#x3D;&#x3D; Row: 3, third_account_id, user_name, password, 20, 0, 2024-01-02 15:41:22, 2024-01-04 12:53:50 &lt;&#x3D;&#x3D; Row: 4, third_account_id, user_name, password, 0, 0, 2024-01-02 15:41:24, 2024-01-02 15:41:24 &lt;&#x3D;&#x3D; Row: 5, hello, user_name, password, 0, 0, 2024-01-02 15:41:25, 2024-01-04 12:19:52 &lt;&#x3D;&#x3D; Row: 6, master, admin, admin, 0, 0, 2023-12-28 15:53:47, 2023-12-29 11:23:18 &lt;&#x3D;&#x3D; Row: 7, big, admin, admin, 0, 0, 2023-12-28 15:53:47, 2024-01-04 12:19:56 &lt;&#x3D;&#x3D; Total: 7 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@370642cb] 显示结果如下:","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://blog.ehzyil.xyz/tags/Mybatis/"}],"author":"ehzyil"},{"title":"基于AbstractRoutingDataSource与AOP实现多数据源切换","slug":"2023/基于AbstractRoutingDataSource与AOP实现多数据源切换","date":"2023-12-29T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/12/29/2023/基于AbstractRoutingDataSource与AOP实现多数据源切换/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/29/2023/%E5%9F%BA%E4%BA%8EAbstractRoutingDataSource%E4%B8%8EAOP%E5%AE%9E%E7%8E%B0%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E5%88%87%E6%8D%A2/","excerpt":"","text":"环境准备环境配置代码地址 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;&#x2F;groupId&gt; &lt;artifactId&gt;guava&lt;&#x2F;artifactId&gt; &lt;version&gt;30.1-jre&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;&#x2F;artifactId&gt; &lt;version&gt;3.4.1&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt; &lt;artifactId&gt;commons-lang3&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.2&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.2.16&lt;&#x2F;version&gt; &lt;scope&gt;provided&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;&#x2F;groupId&gt; &lt;artifactId&gt;lombok&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; application.yml # 默认的数据库名 database: name: story spring: dynamic: primary: master11 # 这个表示默认的数据源 datasource: master: # 数据库名，从配置 database.name 中获取 url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;story?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666 # 注意下面这个type,选择DruidDataSource时，请确保项目中添加了druid相关依赖 type: com.alibaba.druid.pool.DruidDataSource #DruidDataSource自有属性 filters: stat initialSize: 0 minIdle: 1 maxActive: 200 maxWait: 10000 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 200000 testWhileIdle: true testOnBorrow: true validationQuery: select 1 shop: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;shop?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666 blog: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;sg_blog?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666 logging: level: default: debug mybatis: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl map-underscore-to-camel-case: true 基础知识点主要借助AbstractRoutingDataSource来实现动态数据源，简单介绍下它： AbstractRoutingDataSource 是 Spring 提供的一个抽象类，它可以让我们动态切换数据源。在使用 AbstractRoutingDataSource 时，我们需要实现它的 determineCurrentLookupKey() 方法，该方法返回当前线程使用的数据源的名称或标识符。 AbstractRoutingDataSource 两个重要的成员变量： defaultTargetDataSource：默认数据源，即当无法确定使用哪个数据源时，将使用该默认数据源。在AbstractRoutingDataSource中，我们可以通过调用setDefaultTargetDataSource()方法来设置默认数据源。 targetDataSources：一个Map类型的成员变量，其中保存了多个数据源实例。在AbstractRoutingDataSource中，我们可以通过调用setTargetDataSources()方法来设置多个数据源实例，其中Map的key为数据源标识符或名称，value为对应的数据源实例。 使用AbstractRoutingDataSource实现数据源切换的原理如下： 在应用启动时，我们需要配置多个数据源，并将它们注册到AbstractRoutingDataSource中。 当应用发起数据库操作时，AbstractRoutingDataSource会根据determineCurrentLookupKey()方法返回的值，查找对应的数据源。 在determineCurrentLookupKey()方法中，我们可以根据不同的策略来决定使用哪个数据源。例如，可以根据当前请求的用户信息、请求的URL、当前时间等来选择不同的数据源。 其核心代码如： // 返回选中的数据源 protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, \"DataSource router not initialized\"); Object lookupKey = this.determineCurrentLookupKey(); DataSource dataSource = (DataSource)this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException(\"Cannot determine target DataSource for lookup key [\" + lookupKey + \"]\"); &#125; else &#123; return dataSource; &#125; &#125; @Nullable protected abstract Object determineCurrentLookupKey(); 设计方案基于上面的动态数据源的几个核心知识点，所以当我们需要实现动态数据源切换时，自然而然可以想到的一个方案就是在每次db执行之前，塞入这个希望使用的数据源key ![d82673ae-8d87-48ba-8fbc-288ebdcb237b (1)](..&#x2F;..&#x2F;..&#x2F;images&#x2F;2023&#x2F;assets&#x2F;d82673ae-8d87-48ba-8fbc-288ebdcb237b (1).png) 如上的设计思路，主要借助aop的思想来实现，通过上下文来存储当前方法的执行，具体希望使用的数据源，然后再执行的sql的时候，AbstractRoutingDataSource直接从上下文中获取key，以此来抉择具体的数据源 基于上面的方案，接下来我们补充一下细节 1.数据源选择方式通过AOP的方式进行拦截，写入数据源选择，这种方式适用于方法级别的粒度，基于此常见的实现方式就是通过自定义注解，来标注需要使用的数据源 如自定义注解，通过设置ds值来指定这个方法执行时选择的数据源 @Retention(RetentionPolicy.RUNTIME) @Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;) public @interface DsAno &#123; &#x2F;** * 启用的数据源，默认主库 * * @return *&#x2F; MasterSlaveDsEnum value() default MasterSlaveDsEnum.MASTER; &#x2F;** * 启用的数据源，如果存在，则优先使用它来替换默认的value * * @return *&#x2F; String ds() default &quot;&quot;; &#125; 2.上下文通过上下文来保存当前选中的数据源，因此可以借助 ThreadLocal 来实现一个简单的数据源选择上下文，使用继承的线程上下文，支持异步时选择传递。 private static final ThreadLocal&lt;String&gt; CONTEXT_HOLDER &#x3D; new InheritableThreadLocal&lt;&gt;(); 3.动态数据源选择public class MyRoutingDataSource extends AbstractRoutingDataSource &#123; @Nullable @Override protected Object determineCurrentLookupKey() &#123; return DsContextHolder.get(); &#125; &#125; 4.aop拦截借助AOP，拦截方法、类上拥有DS注解的方法执行，然后从这个注解中读取选中的数据源，然后写入上下文；再方法执行完毕之后，清空上下文 @Aspect public class DsAspect &#123; &#x2F;** * 切入点, 拦截类上、方法上有注解的方法，用于切换数据源 *&#x2F; @Pointcut(&quot;@annotation(com.example.multidatasource.dal.DsAno)||@within(com.example.multidatasource.dal.DsAno)&quot;) public void pointcut() &#123; &#125; @Around(&quot;pointcut()&quot;) public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; DsAno ds &#x3D; getDsAno(proceedingJoinPoint); try &#123; if (ds !&#x3D; null &amp;&amp; (StringUtils.isNotBlank(ds.ds()) || ds.value() !&#x3D; null)) &#123; &#x2F;&#x2F; 当上下文中没有时，则写入线程上下文，应该用哪个DB DsContextHolder.set(StringUtils.isNoneBlank(ds.ds()) ? ds.ds() : ds.value().name()); &#125; return proceedingJoinPoint.proceed(); &#125; finally &#123; &#x2F;&#x2F; 清空上下文信息 if (ds !&#x3D; null) &#123; DsContextHolder.reset(); &#125; &#125; &#125; private DsAno getDsAno(ProceedingJoinPoint proceedingJoinPoint) &#123; MethodSignature signature &#x3D; (MethodSignature) proceedingJoinPoint.getSignature(); Method method &#x3D; signature.getMethod(); DsAno ds &#x3D; method.getAnnotation(DsAno.class); if (ds &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 获取类上的注解 ds &#x3D; (DsAno) proceedingJoinPoint.getSignature().getDeclaringType().getAnnotation(DsAno.class); &#125; return ds; &#125; &#125; 多数据源实现1.多数据源定义对于多数据源，因此无法直接使用默认的数据源配置，我们借助默认的配置规则，加一个多数据源版本的设计对应的多数据源的配置规则如下 spring: dynamic: primary: master # 这个表示默认的数据源 datasource: story: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/$&#123;database.name&#125;?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai username: root password: 666666 shop: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/shop?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai username: root password: 666666 注意上面的定义： spring.dynamic.primary: 指定默认启用的数据源 spring.dynamic.datasource.数据源名.配置: 这里的数据源名不能重复（忽略大小写），数据源下的配置与默认的配置参数要求一致 对应的数据源配置加载方式直接借助了Spring的ConfigurationProperties来实现 2.多数据源注册上面是数据源的配置定义与加载，但是我们需要基于上面的数据源配置来实例化对应的datasource。 @Slf4j @Configuration @ConditionalOnProperty(prefix &#x3D; &quot;spring.dynamic&quot;, name &#x3D; &quot;primary&quot;) @EnableConfigurationProperties(DsProperties.class) public class DataSourceConfig &#123; public DataSourceConfig() &#123; log.info(&quot;动态数据源初始化!&quot;); &#125; @Bean public DsAspect dsAspect() &#123; return new DsAspect(); &#125; &#x2F;** * 整合主从数据源 * * @param dsProperties * @return 1 *&#x2F; @Bean @Primary public DataSource dataSource(DsProperties dsProperties) &#123; Map&lt;Object, Object&gt; targetDataSources &#x3D; Maps.newHashMapWithExpectedSize(dsProperties.getDatasource().size()); dsProperties.getDatasource().forEach((k, v) -&gt; targetDataSources.put(k.toUpperCase(), v.initializeDataSourceBuilder().build())); if (CollectionUtils.isEmpty(targetDataSources)) &#123; throw new IllegalStateException(&quot;多数据源配置，请以 spring.dynamic 开头&quot;); &#125; MyRoutingDataSource myRoutingDataSource &#x3D; new MyRoutingDataSource(); Object key &#x3D; dsProperties.getPrimary().toUpperCase(); if (!targetDataSources.containsKey(key)) &#123; if (targetDataSources.containsKey(MasterSlaveDsEnum.MASTER.name())) &#123; &#x2F;&#x2F; 当们没有配置primary对应的数据源时，存在MASTER数据源，则将主库作为默认的数据源 key &#x3D; MasterSlaveDsEnum.MASTER.name(); &#125; else &#123; key &#x3D; targetDataSources.keySet().iterator().next(); &#125; &#125; log.info(&quot;动态数据源，默认启用为： &quot; + key); myRoutingDataSource.setDefaultTargetDataSource(targetDataSources.get(key)); myRoutingDataSource.setTargetDataSources(targetDataSources); return myRoutingDataSource; &#125; &#125; @ConditionalOnProperty: 这是Spring Boot框架提供的条件注解，它表示只有当指定的属性满足特定条件时，才会创建这个配置类所定义的bean。 @EnableConfigurationProperties(DsProperties.class): 这个注解告诉Spring Boot去启用特定的配置属性类（DsProperties），使其可以被注入到其他bean中。 @Primary: 这个注解用于标识在多个bean候选者中，优先选择被注解的bean作为自动装配的首选项。 datasource实例化方式 DataSourceProperties.initializeDataSourceBuilder().build() 通过上面的方式创建的DataSource为默认的HikariDataSource 3.上下文定义public class DsContextHolder &#123; &#x2F;** * 使用继承的线程上下文，支持异步时选择传递 * 使用DsNode，支持链式的数据源切换，如最外层使用master数据源，内部某个方法使用slave数据源；但是请注意，对于事务的场景，不要交叉 *&#x2F; private static final ThreadLocal&lt;String&gt; CONTEXT_HOLDER &#x3D; new InheritableThreadLocal&lt;&gt;(); private DsContextHolder() &#123; &#125; public static void set(String dbType) &#123; CONTEXT_HOLDER.set(dbType); &#125; public static String get() &#123; return CONTEXT_HOLDER.get(); &#125; public static void set(DS ds) &#123; set(ds.name().toUpperCase()); &#125; &#x2F;** * 移除上下文 *&#x2F; public static void reset() &#123; CONTEXT_HOLDER.remove(); &#125; &#125; 4.AOP实现借助AOP来简化数据源的选择，因此我们先定义一个注解DsAno，可以放在类上，表示这个类下所有的共有方法，都走某个数据源；也可以放在方法上，且方法上的优先级大于类上的注解 public interface DS &#123; &#x2F;** * 使用的数据源名 * * @return *&#x2F; String name(); &#125; @Retention(RetentionPolicy.RUNTIME) @Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;) public @interface DsAno &#123; &#x2F;** * 启用的数据源，默认主库 * * @return *&#x2F; MasterSlaveDsEnum value() default MasterSlaveDsEnum.MASTER; &#x2F;** * 启用的数据源，如果存在，则优先使用它来替换默认的value * * @return *&#x2F; String ds() default &quot;&quot;; &#125; @Aspect public class DsAspect &#123; &#x2F;** * 切入点, 拦截类上、方法上有注解的方法，用于切换数据源 *&#x2F; @Pointcut(&quot;@annotation(com.example.multidatasource.dal.DsAno)||@within(com.example.multidatasource.dal.DsAno)&quot;) public void pointcut() &#123; &#125; @Around(&quot;pointcut()&quot;) public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; DsAno ds &#x3D; getDsAno(proceedingJoinPoint); try &#123; if (ds !&#x3D; null &amp;&amp; (StringUtils.isNotBlank(ds.ds()) || ds.value() !&#x3D; null)) &#123; &#x2F;&#x2F; 当上下文中没有时，则写入线程上下文，应该用哪个DB DsContextHolder.set(StringUtils.isNoneBlank(ds.ds()) ? ds.ds() : ds.value().name()); &#125; return proceedingJoinPoint.proceed(); &#125; finally &#123; &#x2F;&#x2F; 清空上下文信息 if (ds !&#x3D; null) &#123; DsContextHolder.reset(); &#125; &#125; &#125; private DsAno getDsAno(ProceedingJoinPoint proceedingJoinPoint) &#123; MethodSignature signature &#x3D; (MethodSignature) proceedingJoinPoint.getSignature(); Method method &#x3D; signature.getMethod(); DsAno ds &#x3D; method.getAnnotation(DsAno.class); if (ds &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 获取类上的注解 ds &#x3D; (DsAno) proceedingJoinPoint.getSignature().getDeclaringType().getAnnotation(DsAno.class); &#125; return ds; &#125; &#125; 上面的设计中，针对常见的主从切换做了一个简单的兼容，定义了一个主从数据源的枚举，同样也是基于简化使用体验的出发，枚举类设计如下： public enum MasterSlaveDsEnum implements DS &#123; MASTER, SHOP, STORY; &#125; 5.编程式数据源选择与小结import java.util.function.Supplier; &#x2F;** * 手动指定数据源的用法 *&#x2F; public class DsSelectExecutor &#123; &#x2F;** * 有返回结果 * * @param ds 数据源 * @param supplier 供应商 * @param &lt;T&gt; 泛型类型 * @return 返回结果 *&#x2F; public static &lt;T&gt; T submit(DS ds, Supplier&lt;T&gt; supplier) &#123; DsContextHolder.set(ds); try &#123; return supplier.get(); &#125; finally &#123; DsContextHolder.reset(); &#125; &#125; &#x2F;** * 无返回结果 * * @param ds 数据源 * @param call 可调用对象 *&#x2F; public static void execute(DS ds, Runnable call) &#123; DsContextHolder.set(ds); try &#123; call.run(); &#125; finally &#123; DsContextHolder.reset(); &#125; &#125; &#125; submit方法：接收一个数据库连接和一个Supplier接口实例作为参数，返回Supplier接口的返回值。该方法的目的是使用给定的数据库连接执行传入的Supplier接口实例，然后返回该接口的返回值。在方法中，首先通过DsContextHolder类将数据库连接设置到连接池中，然后使用supplier.get()方法获取Supplier接口的返回值。最后，在finally块中重置数据库连接池的状态，以确保数据库连接被正确释放。 execute方法：接收一个数据库连接和一个Runnable接口实例作为参数，无返回值。该方法的目的是使用给定的数据库连接执行传入的Runnable接口实例中的代码。在方法中，首先通过DsContextHolder类将数据库连接设置到连接池中，然后使用call.run()方法执行Runnable接口的代码。最后，在finally块中重置数据库连接池的状态，以确保数据库连接被正确释放。 小结小结一下整个的设计实现，主要基于AOP + 上下文的方式，配合AbstractRoutingDataSource来实现多数据源的自由选择 但是请注意，上面的实现，还有几个缺陷： 如果一个方法上有数据源选择注解，但是内部开了子线程做异步处理，那么上下文存储的数据源会失效 一个方法上指定了数据源，它又调用其他有也指定了数据源的方法，当前的方案会存在数据源的选择冲突 druid数据源怎么兼容？ 优化支持嵌套的数据源选择方案前面提出的一个非常大的问题就是再整个链路中，只支持选择一次的数据源，显然这种方式缺陷比较大，也很容易出现问题； 若我们希望实现在选择了一个数据源之后，在执行某个代码片段时，还可以继续再选择其他的数据源，那么应该怎么实现呢？ 首先我们来看一下之前的实现方案 ![d82673ae-8d87-48ba-8fbc-288ebdcb237b (1)](..&#x2F;..&#x2F;..&#x2F;images&#x2F;2023&#x2F;assets&#x2F;d82673ae-8d87-48ba-8fbc-288ebdcb237b (1).png) 在执行sql时，从上下文中获取当前选中的数据源,前面设计的上下文直接使用线程上线文保存 private static final ThreadLocal&lt;String&gt; CONTEXT_HOLDER &#x3D; new InheritableThreadLocal&lt;&gt;(); 从上面的这个实现来看，上下文赋值只能有一次，当我们希望可以实现标题的效果，自然我们应该想到的数据结构就是栈 – 后进先出 我们定义一个DsNode节点来存储选中的数据源，区别于之前的String，它除了记录选中的数据源之外，还记录前一次选中的数据源 public static class DsNode &#123; DsNode pre; String ds; public DsNode(DsNode parent, String ds) &#123; pre &#x3D; parent; this.ds &#x3D; ds; &#125; &#125; 移除上下文则不能像之前那么粗暴，而是要实现栈的弹出效果 如果无选中的数据源，直接返回 若之前选中的DsNode，存在上一个节点，则将上一个节点重新写入上下文 若之前选中的DsNode，不存在上一个节点，则清空上下文 public static String get() &#123; DsNode dsNode &#x3D; CONTEXT_HOLDER.get(); log.info(&quot;get dbType:&#123;&#125;&quot;, CONTEXT_HOLDER.get()); return dsNode&#x3D;&#x3D;null? null:dsNode.ds; &#125; public static void set(String dbType) &#123; DsNode current &#x3D; CONTEXT_HOLDER.get(); CONTEXT_HOLDER.set(new DsNode(current,dbType)); &#125; public static void set(DS ds) &#123; set(ds.name().toUpperCase()); &#125; &#x2F;** * 移除上下文 *&#x2F; public static void reset() &#123; DsNode ds &#x3D; CONTEXT_HOLDER.get(); if (ds &#x3D;&#x3D; null) &#123; return; &#125; if (ds.pre !&#x3D; null) &#123; &#x2F;&#x2F; 退出当前的数据源选择，切回去走上一次的数据源配置 CONTEXT_HOLDER.set(ds.pre); &#125; else &#123; CONTEXT_HOLDER.remove(); &#125; &#125; Druid数据源支持dsProperties.getDatasource().forEach((k, v) -&gt; targetDataSources.put(k.toUpperCase(), initDataSource(k, v))); 上面代码中使用v.initializeDataSourceBuilder().build()初始化的数据源默认是HikarDataSource,当我们使用Druid数据源时就无法适配，因此需要做以下修改。 1.检查是否引入Druid相关资源 public class DruidCheckUtil &#123; &#x2F;** * 判断是否包含durid相关的数据包 * * @return *&#x2F; public static boolean hasDuridPkg() &#123; return ClassUtils.isPresent(&quot;com.alibaba.druid.pool.DruidDataSource&quot;, DataSourceConfig.class.getClassLoader()); &#125; &#125; 2.创建InitDatasourse方法用来判断是否初始化Druid数据源 &#x2F;** * 初始化数据源 * @param prefix 数据源前缀 * @param properties 数据源属性 * @return 数据源 *&#x2F; public DataSource initDataSource(String prefix, DataSourceProperties properties) &#123; &#x2F;&#x2F; 检查是否包含Druid包 if (!DruidCheckUtil.hasDuridPkg()) &#123; log.info(&quot;实例化HikarDataSource: &#123;&#125;&quot;, prefix); &#x2F;&#x2F; 使用数据源属性初始化数据源构建器并构建数据源 return properties.initializeDataSourceBuilder().build(); &#125; &#x2F;&#x2F; 如果数据源类型为空或者数据源类型不是DruidDataSource类 if (properties.getType() &#x3D;&#x3D; null || !properties.getType().isAssignableFrom(DruidDataSource.class)) &#123; log.info(&quot;实例化HikarDataSource: &#123;&#125;&quot;, prefix); &#x2F;&#x2F; 使用数据源属性初始化数据源构建器并构建数据源 return properties.initializeDataSourceBuilder().build(); &#125; log.info(&quot;实例化DruidDataSource: &#123;&#125;&quot;, prefix); &#x2F;&#x2F; 使用Spring Binder 绑定或创建一个 &quot;spring.dynamic.datasource.&quot; + prefix 的DruidDataSource对象 return Binder.get(environment).bindOrCreate(&quot;spring.dynamic.datasource.&quot; + prefix, DruidDataSource.class); &#125; 上面方法会读取spring.dynamic.datasource.xxx的配置信息，我们只需添加type属性和Druid的配置信息即可初始化DruidDataSource。 配置文件如下： # 默认的数据库名 database: name: story spring: dynamic: primary: master # 这个表示默认的数据源 datasource: master: # 数据库名，从配置 database.name 中获取 url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;$&#123;database.name&#125;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666 # 注意下面这个type,选择DruidDataSource时，请确保项目中添加了druid相关依赖 type: com.alibaba.druid.pool.DruidDataSource #DruidDataSource自有属性 filters: stat initialSize: 0 minIdle: 1 maxActive: 200 maxWait: 10000 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 200000 testWhileIdle: true testOnBorrow: true validationQuery: select 1 story: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;$&#123;database.name&#125;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666 shop: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;shop?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666 blog: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;sg_blog?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"}],"author":"ehzyil"},{"title":"数据库表自动初始化","slug":"2023/数据库表自动初始化","date":"2023-12-28T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/12/28/2023/数据库表自动初始化/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/28/2023/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E8%87%AA%E5%8A%A8%E5%88%9D%E5%A7%8B%E5%8C%96/","excerpt":"","text":"数据库表自动初始化Liquibase数据库表版本管理依赖配置在Maven的pom文件中添加Liquibase依赖 &lt;dependency> &lt;groupId>org.liquibase&lt;/groupId> &lt;artifactId>liquibase-core&lt;/artifactId> &lt;/dependency> 配置数据源和Liquibase 在application.yml文件中添加配置，liquibase: change-log: classpath:liquibase/master.xml用于指定change-log的目录。 # 默认的数据库名 database: name: story spring: liquibase: change-log: classpath:liquibase/master.xml enabled: true # 当实际使用的数据库不支持liquibase，如 mariadb 时，将这个参数设置为false datasource: url: jdbc:mysql://127.0.0.1:3306/$&#123;database.name&#125;?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai username: root password: 666666 说明：●对于不支持liquibase的数据库，如mariadb，请将上面的 spring.liquibase.enabled 设置为 false●change-log: 对应的是核心的数据库版本变更配置 在rescources下创建以下的配置文件。 master.xml 文件中的内容如下 &lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot;?&gt; &lt;databaseChangeLog xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.liquibase.org&#x2F;xml&#x2F;ns&#x2F;dbchangelog&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.liquibase.org&#x2F;xml&#x2F;ns&#x2F;dbchangelog http:&#x2F;&#x2F;www.liquibase.org&#x2F;xml&#x2F;ns&#x2F;dbchangelog&#x2F;dbchangelog-3.5.xsd&quot;&gt; &lt;include file&#x3D;&quot;liquibase&#x2F;changelog&#x2F;000_initial_schema.xml&quot; relativeToChangelogFile&#x3D;&quot;false&quot;&#x2F;&gt; &lt;&#x2F;databaseChangeLog&gt; 说明：●对于不支持liquibase的数据库，如mariadb，请将上面的 spring.liquibase.enabled 设置为 false●change-log: 对应的是核心的数据库版本变更配置 注意上面这个 include， 这里就是告诉liquibase，所有的变更记录，都放在了 liquibase&#x2F;changelog&#x2F;000_initial_schema.xml 这个文件中 changelog文件 changelog文件，用于定义数据库的结构和初始数据。可以使用XML、YAML或者JSON格式来编写changelog文件，例如000_initial_schema.xml。 &lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot;?&gt; &lt;databaseChangeLog xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.liquibase.org&#x2F;xml&#x2F;ns&#x2F;dbchangelog&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.liquibase.org&#x2F;xml&#x2F;ns&#x2F;dbchangelog http:&#x2F;&#x2F;www.liquibase.org&#x2F;xml&#x2F;ns&#x2F;dbchangelog&#x2F;dbchangelog-3.5.xsd&quot;&gt; &lt;property name&#x3D;&quot;now&quot; value&#x3D;&quot;now()&quot; dbms&#x3D;&quot;mysql&quot;&#x2F;&gt; &lt;property name&#x3D;&quot;autoIncrement&quot; value&#x3D;&quot;true&quot;&#x2F;&gt; &lt;changeSet id&#x3D;&quot;00000000000001&quot; author&#x3D;&quot;ehzyil&quot;&gt; &lt;sqlFile dbms&#x3D;&quot;mysql&quot; endDelimiter&#x3D;&quot;;&quot; encoding&#x3D;&quot;UTF-8&quot; path&#x3D;&quot;liquibase&#x2F;data&#x2F;init-schema.sql&quot;&#x2F;&gt; &lt;&#x2F;changeSet&gt; &lt;changeSet id&#x3D;&quot;00000000000002&quot; author&#x3D;&quot;ehzyil&quot;&gt; &lt;sqlFile dbms&#x3D;&quot;mysql&quot; endDelimiter&#x3D;&quot;;&quot; encoding&#x3D;&quot;UTF-8&quot; path&#x3D;&quot;liquibase&#x2F;data&#x2F;init-schema-1.sql&quot;&#x2F;&gt; &lt;&#x2F;changeSet&gt; &lt;changeSet id&#x3D;&quot;00000000000003&quot; author&#x3D;&quot;ehzyil&quot;&gt; &lt;sqlFile dbms&#x3D;&quot;mysql&quot; endDelimiter&#x3D;&quot;;&quot; encoding&#x3D;&quot;UTF-8&quot; path&#x3D;&quot;liquibase&#x2F;data&#x2F;init-data.sql&quot;&#x2F;&gt; &lt;&#x2F;changeSet&gt; &lt;!-- 可以添加更多的changeSet来定义其他表结构和初始数据 --&gt; &lt;&#x2F;databaseChangeLog&gt; 说明：●changeSet 标签，id必须唯一，不能出现冲突●sqlFile 里面的path，对应的可以是标准的sql文件，也可以是xml格式的数据库表定义、数据库操作文件●一旦写上去，changeSet的顺序不要调整 init-schema.sql CREATE TABLE &#96;user&#96; ( &#96;id&#96; int unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;, &#96;third_account_id&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;第三方用户ID&#39;, &#96;user_name&#96; varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户名&#39;, &#96;password&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;密码&#39;, &#96;login_type&#96; tinyint NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;登录方式: 0-微信登录，1-账号密码登录&#39;, &#96;deleted&#96; tinyint NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;是否删除&#39;, &#96;create_time&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;, &#96;update_time&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;最后更新时间&#39;, PRIMARY KEY (&#96;id&#96;), KEY &#96;key_third_account_id&#96; (&#96;third_account_id&#96;), KEY &#96;user_name&#96; (&#96;user_name&#96;) ) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8mb4 COMMENT&#x3D;&#39;用户登录表&#39;; 项目演示项目启动之后，一切正常的话，直接连上数据库可以看到库表创建成功，数据也初始化完成，当然也可以直接观察控制台的输出 注意事项非常重要的一个点是，上面的每个ChangeSet只会执行一次，因此当执行完毕之后发现不对，要回滚怎么办？或者又需要修改怎么办？ liquibase 提供了回滚的机制，当ChangeSet执行完毕之后，对应的sql文件&#x2F;xml文件（即path定义的文件）不允许再修改，因为db中会记录这个文件的md5，当修改这个文件之后，这个md5也会随之发生改变 因此两个解决方案：新增一个changeSet 删除 DATABASECHANGELOG 表中 changeSet id对应的记录，然后重新走一遍 DataSourcelnitializer首次初始化方案 如何使用DataSourceInitializer来实现自主可控的数据初始化 项目搭建依赖首先搭建一个标准的SpringBoot项目工程，相关版本以及依赖如下 &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;version&gt;8.0.31&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; 配置注意实现初始化数据库表操作的核心配置就在下面，重点关注 配置文件： resources/application.yml # 默认的数据库名 database: name: story spring: datasource: url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;$&#123;database.name&#125;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai username: root password: 666666 logging: level: root: info org: springframework: jdbc: core: debug resources/init_data/init-schema.sql 对应的初始化ddl CREATE TABLE &#96;user&#96; ( &#96;id&#96; int unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;, &#96;third_account_id&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;第三方用户ID&#39;, &#96;user_name&#96; varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户名&#39;, &#96;password&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;密码&#39;, &#96;login_type&#96; tinyint NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;登录方式: 0-微信登录，1-账号密码登录&#39;, &#96;deleted&#96; tinyint NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;是否删除&#39;, &#96;create_time&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;, &#96;update_time&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;最后更新时间&#39;, PRIMARY KEY (&#96;id&#96;), KEY &#96;key_third_account_id&#96; (&#96;third_account_id&#96;), KEY &#96;user_name&#96; (&#96;user_name&#96;) ) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8mb4 COMMENT&#x3D;&#39;用户登录表&#39;; resources/init_data/init-data.sql 对用的初始化dml INSERT INTO &#96;user&#96; (id, third_account_id, &#96;user_name&#96;, &#96;password&#96;, login_type, deleted) VALUES (1, &#39;a7cb7228-0f85-4dd5-845c-7c5df3746e92&#39;, &#39;admin&#39;, &#39;admin&#39;, 0, 0); 初始化初始化配置 @Slf4j @Configuration public class DataSourceInit &#123; //需要初始化的表结构 @Value(\"classpath:init_data/init-schema.sql\") private Resource initDataSource; //初始化数据 @Value(\"classpath:init_data/init-data.sql\") private Resource initData; //数据库名 @Value(\"$&#123;database.name&#125;\") private String dataBaseName; @Bean public DataSourceInitializer dataSourceInitializer(final DataSource dataSource) &#123; final DataSourceInitializer initializer = new DataSourceInitializer(); // 设置数据源 initializer.setDataSource(dataSource); // 设置数据库Populator initializer.setDatabasePopulator(databasePopulator()); // true表示需要执行，false表示不需要初始化 initializer.setEnabled(needInit(dataSource)); return initializer; &#125; /** * 设置数据源 * &lt;span>创建了一个ResourceDatabasePopulator对象，并添加了两个SQL脚本文件到其中，用分号作为分隔符。最后将这个populator对象返回。&lt;/span> * * @return */ private DatabasePopulator databasePopulator() &#123; final ResourceDatabasePopulator populator = new ResourceDatabasePopulator(); populator.addScripts(initDataSource); populator.addScripts(initData); populator.setSeparator(\";\"); return populator; &#125; &#125; 我们这里主要是借助 DataSourceInitializer 来实现初始化，其核心有两个配置 DatabasePopulator: 通过addScripts来指定对应的sql文件 DataSourceInitializer#setEnabled: 判断是否需要执行初始化 接下来重点需要看的就是needInit方法，我们再这个方法里面，需要判断数据库是否存在，若不存在时，则创建数据库；然后再判断表是否存在，以此来决定是否需要执行初始化方法 /** * 判断是否需要初始化 * * @param dataSource * @return */ private boolean needInit(DataSource dataSource) &#123; if (autoInitDatabase()) &#123; return true; &#125; // 根据是否存在表来判断是否需要执行sql操作 JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); List&lt;Map&lt;String, Object>> list = jdbcTemplate.queryForList(\"SELECT table_name FROM information_schema.TABLES where table_name = 'user' and table_schema = '\" + dataBaseName + \"'\"); boolean init = CollectionUtils.isEmpty(list); if (init) &#123; log.info(\"库表不存在，执行建表及数据初始化\"); &#125; else &#123; log.info(\"表结构已存在，无需初始化\"); &#125; return init; &#125; /** * 数据库不存在时，尝试创建数据库 * * @return */ private boolean autoInitDatabase() &#123; // 查询失败，可能是数据库不存在，尝试创建数据库之后再次测试 //jdbc:mysql://127.0.0.1:3306/story?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai //mysql://127.0.0.1:3306/story?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai URI url = URI.create(SpringUtil.getConfig(\"spring.datasource.url\").substring(5)); String uname = SpringUtil.getConfig(\"spring.datasource.username\"); String pwd = SpringUtil.getConfig(\"spring.datasource.password\"); try (Connection connection = DriverManager.getConnection(\"jdbc:mysql://\" + url.getHost() + \":\" + url.getPort() + \"?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false\", uname, pwd); Statement statement = connection.createStatement()) &#123; ResultSet set = statement.executeQuery(\"select schema_name from information_schema.schemata where schema_name='\" + dataBaseName + \"'\"); if (!set.next()) &#123; String createDb = \"create database if not exists \" + dataBaseName; connection.setAutoCommit(false); statement.execute(createDb); connection.commit(); log.info(\"创建数据库（&#123;&#125;）成功\", createDb); if (set.isClosed()) &#123; set.close(); &#125; return true; &#125; set.close(); log.info(\"数据库已存在，无需初始化\"); return false; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; 上面的数据库判断是否存在以及初始化的过程相对基础，直接使用了基础的Connection进行操作；这里借助了SpringUtil来获取配置信息，对应的类源码如下 @Component public class SpringUtil implements ApplicationContextAware, EnvironmentAware &#123; private static ApplicationContext context; private static Environment environment; /** * 获取bean * * @param bean * @param &lt;T> * @return */ public static &lt;T> T getBean(Class&lt;T> bean) &#123; return context.getBean(bean); &#125; public static Object getBean(String beanName) &#123; return context.getBean(beanName); &#125; /** * 获取配置 * * @param key * @return */ public static String getConfig(String key) &#123; return environment.getProperty(key); &#125; /** * 发布事件消息 * * @param event */ public static void publishEvent(ApplicationEvent event) &#123; context.publishEvent(event); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; SpringUtil.context = applicationContext; &#125; @Override public void setEnvironment(Environment environment) &#123; SpringUtil.environment = environment; &#125; &#125; Springboot启动类配置如下： @Slf4j @SpringBootApplication public class LiquibaseApplication implements ApplicationRunner &#123; @Autowired private JdbcTemplate jdbcTemplate; public static void main(String[] args) &#123; SpringApplication.run(LiquibaseApplication.class); &#125; @Override public void run(ApplicationArguments args) throws Exception &#123; List list &#x3D; jdbcTemplate.queryForList(&quot;select * from user limit 2&quot;); log.info(&quot;启动成功，初始化数据: &#123;&#125;\\n&#123;&#125;&quot;, list.size(), list); &#125; &#125; 项目演示删除原有的story数据库，启动项目，成功执行结果如下 两种初始化方式结合的实践方案 第一次启动项目时选择未开启liquibase，第二次开启liquibase时会报错，因为 databasechangelog表未创建，因此请选准一种启动方式。 库初始化/** * 数据库不存在时，尝试创建数据库&lt;br> * &lt;span> * autoInitDatabase方法用于自动创建数据库。在方法内部，首先从配置文件中获取数据库连接URL、用户名和密码，并通过DriverManager创建数据库连接和Statement对象。 * 然后通过执行查询语句判断数据库是否存在，如果不存在则执行创建数据库的sql语句，并打印相应日志。 * &lt;/span> * * @return 是否成功创建数据库 */ private boolean autoInitDatabase() &#123; // 查询失败，可能是数据库不存在，尝试创建数据库之后再次测试 //jdbc:mysql://127.0.0.1:3306/story?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai //mysql://127.0.0.1:3306/story?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai URI url = URI.create(SpringUtil.getConfig(\"spring.datasource.url\").substring(5)); String uname = SpringUtil.getConfig(\"spring.datasource.username\"); String pwd = SpringUtil.getConfig(\"spring.datasource.password\"); try (Connection connection = DriverManager.getConnection(\"jdbc:mysql://\" + url.getHost() + \":\" + url.getPort() + \"?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false\", uname, pwd); Statement statement = connection.createStatement()) &#123; ResultSet set = statement.executeQuery(\"select schema_name from information_schema.schemata where schema_name='\" + database + \"'\"); if (!set.next()) &#123; String createDb = \"create database if not exists \" + database; connection.setAutoCommit(false); statement.execute(createDb); connection.commit(); log.info(\"创建数据库（&#123;&#125;）成功\", createDb); if (set.isClosed()) &#123; set.close(); &#125; return true; &#125; set.close(); log.info(\"数据库已存在，无需初始化\"); return false; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; 上面的实现比较清晰了，首先是判断库是否存在，autoInitDatabase方法用于自动创建数据库。在方法内部，首先从配置文件中获取数据库连接URL、用户名和密码，并通过DriverManager创建数据库连接和Statement对象。然后通过执行查询语句判断数据库是否存在，如果不存在则执行创建数据库的sql语句，并打印相应日志。 为什么不直接使用 spring.datasource.url 来创建连接？因为库不存在时，直接使用下面这个url进行连接会抛连接异常 表初始化表的初始化，其实可以理解为项目启动之后执行一些sql，这时主要借助的就是 initializer.setDatabasePopulator核心知识点我们使用DbChangeSetLoader 类来实现初始化sql的加载，但实际上，若你完全抛开Liquibase，单纯的希望项目启动后执行某些sql，可以非常简单的实现，直接用DataSourcelnitializer首次初始化方案中写的通过 @Value 来加载需要初始化的sql文件，直接通过 ResourceDatabasePoplulator 添加sql资源就可以了 /** * 检测一下数据库中表是否存在，若存在则不初始化； * * @param dataSource * @return true 表示需要初始化； false 表示无需初始化 */ private boolean needInit(DataSource dataSource) &#123; if (autoInitDatabase()) &#123; return true; //不存在且已创建 &#125; //已存在的执行逻辑 // 根据是否存在表来判断是否需要执行sql操作 JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); if (!liquibaseEnable) &#123; // 非liquibase做数据库版本管理的，根据用户来判断是否有初始化 List list = jdbcTemplate.queryForList(\"SELECT table_name FROM information_schema.TABLES where table_name = 'user_info' and table_schema = '\" + database + \"';\"); return CollectionUtils.isEmpty(list); &#125; // 对于liquibase做数据版本管控的场景，若使用的不是默认的pai_coding，则需要进行修订 List&lt;Map&lt;String, Object>> record = jdbcTemplate.queryForList(\"select * from DATABASECHANGELOG where ID='00000000000020' limit 1;\"); if (CollectionUtils.isEmpty(record)) &#123; // 首次启动，需要初始化库表，直接返回 return true; &#125; // 非首次启动时，判断记录对应的md5是否准确 if (Objects.equals(record.get(0).get(\"MD5SUM\"), \"8:a1a2d9943b746acf58476ae612c292fc\")) &#123; jdbcTemplate.update(\"update DATABASECHANGELOG set MD5SUM='8:bb81b67a5219be64eff22e2929fed540' where ID='00000000000020'\"); &#125; return false; &#125; needInit方法用于判断是否需要初始化数据库。该方法的参数是一个DataSource对象，表示数据源。在方法内部，先判断是否需要自动创建数据库，如果需要则返回true。然后通过JdbcTemplate查询是否存在表，如果不存在则需要初始化数据库，并打印相应日志，否则不需要初始化并打印相应日志。 核心知识点Liquibase兼容方案dataSourceInitializer(final DataSource dataSource)用于初始化数据源，返回一个DataSourceInitializer的Bean。该方法的参数是一个DataSource对象，表示数据源。在方法内部，创建了一个DataSourceInitializer对象，设置数据源为传入的参数，并根据是否需要初始化数据库设置启用状态和数据库结构初始化的Populator。 databasePopulator方法用于创建DatabasePopulator对象，用于数据库结构初始化。该方法的参数是一个是否需要初始化的标志，根据该标志进行不同的操作。如果不需要初始化且不使用Liquibase管理数据库，则创建一个ResourceDatabasePopulator对象，并通过addScripts方法添加需要执行的sql脚本，通过setSeparator方法设置sql语句的分隔符。 @Value(\"$&#123;database.name&#125;\") private String database; // 从配置文件中读取数据库名称 @Value(\"$&#123;spring.liquibase.enabled:true&#125;\") private Boolean liquibaseEnable; // 从配置文件中读取是否使用Liquibase管理数据库的配置 @Value(\"$&#123;spring.liquibase.change-log&#125;\") private String liquibaseChangeLog; // 从配置文件中读取Liquibase的change-log配置 /** * 初始化数据源，返回DataSourceInitializer Bean&lt;br> * * * @param dataSource 数据源 * @return DataSourceInitializer */ @Bean public org.springframework.jdbc.datasource.init.DataSourceInitializer dataSourceInitializer(final DataSource dataSource) &#123; final org.springframework.jdbc.datasource.init.DataSourceInitializer initializer = new org.springframework.jdbc.datasource.init.DataSourceInitializer(); // 设置数据源 initializer.setDataSource(dataSource); boolean enable = needInit(dataSource); initializer.setEnabled(enable); initializer.setDatabasePopulator(databasePopulator(enable)); return initializer; &#125; /** * 创建DatabasePopulator对象，用于数据库结构初始化&lt;br> * @param initEnable 是否需要初始化 * @return DatabasePopulator */ private DatabasePopulator databasePopulator(boolean initEnable) &#123; final ResourceDatabasePopulator populator = new ResourceDatabasePopulator(); if (!liquibaseEnable &amp;&amp; initEnable) &#123; // fixme: 首次启动时, 对于不支持liquibase的数据库，如mariadb，采用主动初始化 // fixme 这种方式不支持后续动态的数据表结构更新、数据变更 populator.addScripts(XmlParserUtils.loadDbChangeSetResources(liquibaseChangeLog).toArray(new ClassPathResource[]&#123;&#125;)); populator.setSeparator(\";\"); log.info(\"非Liquibase管理数据库，请手动执行数据库表初始化!\"); &#125; return populator; &#125; XmlParserUtils.loadDbChangeSetResources(liquibaseChangeLog).toArray(new ClassPathResource[]&#123;&#125;)用于读取配置文件中的change-log: classpath:liquibase/master.xml来获取liquibase的ChangeLog从而获取到所有的sql脚本。 注意上面的实现：我们依然借助了Liquibase 的xml文件来解析来加载对应的数据库表变更历史sql。但是需要注意的是，采用DataSourceInitializer初始化方案，只会执行一次；当你从github上拉了代码本地执行之后，后续再拉新的代码，有新的变更时，这些新的变更都不会被执行，需要我们删除数据库或删除 DATABASECHANGELOG 表中 changeSet id对应的记录，然后重新走一遍。 执行结果 未创建数据库的情况 已创建数据库的情况 不启用liquibase 未建库 spring: liquibase: change-log: classpath:liquibase&#x2F;master.xml enabled: false # 当实际使用的数据库不支持liquibase，如 mariadb 时，将这个参数设置为false 附上主要类的代码 @Slf4j @Configuration public class ForumDataSourceInitializer &#123; @Value(&quot;$&#123;database.name&#125;&quot;) private String database; &#x2F;&#x2F; 从配置文件中读取数据库名称 @Value(&quot;$&#123;spring.liquibase.enabled:true&#125;&quot;) private Boolean liquibaseEnable; &#x2F;&#x2F; 从配置文件中读取是否使用Liquibase管理数据库的配置 @Value(&quot;$&#123;spring.liquibase.change-log&#125;&quot;) private String liquibaseChangeLog; &#x2F;&#x2F; 从配置文件中读取Liquibase的change-log配置 &#x2F;** * 初始化数据源，返回DataSourceInitializer Bean&lt;br&gt; * &lt;span&gt;用于初始化数据源，返回一个DataSourceInitializer的Bean。 * 该方法的参数是一个DataSource对象，表示数据源。在方法内部，创建了一个DataSourceInitializer对象， * 设置数据源为传入的参数，并根据是否需要初始化数据库设置启用状态和数据库结构初始化的Populator。 &lt;&#x2F;span&gt; * * @param dataSource 数据源 * @return DataSourceInitializer *&#x2F; @Bean public org.springframework.jdbc.datasource.init.DataSourceInitializer dataSourceInitializer(final DataSource dataSource) &#123; final org.springframework.jdbc.datasource.init.DataSourceInitializer initializer &#x3D; new org.springframework.jdbc.datasource.init.DataSourceInitializer(); &#x2F;&#x2F; 设置数据源 initializer.setDataSource(dataSource); boolean enable &#x3D; needInit(dataSource); initializer.setEnabled(enable); initializer.setDatabasePopulator(databasePopulator(enable)); return initializer; &#125; &#x2F;** * 创建DatabasePopulator对象，用于数据库结构初始化&lt;br&gt; * &lt;span&gt;databasePopulator方法用于创建DatabasePopulator对象，用于数据库结构初始化。该方法的参数是一个是否需要初始化的标志，根据该标志进行不同的操作。 * 如果不需要初始化且不使用Liquibase管理数据库，则创建一个ResourceDatabasePopulator对象，并通过addScripts方法添加需要执行的sql脚本， * 通过setSeparator方法设置sql语句的分隔符。&lt;&#x2F;span&gt; * * @param initEnable 是否需要初始化 * @return DatabasePopulator *&#x2F; private DatabasePopulator databasePopulator(boolean initEnable) &#123; final ResourceDatabasePopulator populator &#x3D; new ResourceDatabasePopulator(); if (!liquibaseEnable &amp;&amp; initEnable) &#123; &#x2F;&#x2F; fixme: 首次启动时, 对于不支持liquibase的数据库，如mariadb，采用主动初始化 &#x2F;&#x2F; fixme 这种方式不支持后续动态的数据表结构更新、数据变更 populator.addScripts(XmlParserUtils.loadDbChangeSetResources(liquibaseChangeLog).toArray(new ClassPathResource[]&#123;&#125;)); populator.setSeparator(&quot;;&quot;); log.info(&quot;非Liquibase管理数据库，请手动执行数据库表初始化!&quot;); &#125; return populator; &#125; &#x2F;** * 判断是否需要初始化数据库&lt;br&gt; * * &lt;span&gt; * needInit方法用于判断是否需要初始化数据库。该方法的参数是一个DataSource对象，表示数据源。在方法内部，先判断是否需要自动创建数据库，如果需要则返回true。 * 然后通过JdbcTemplate查询是否存在表，如果不存在则需要初始化数据库，并打印相应日志，否则不需要初始化并打印相应日志。 * &lt;&#x2F;span&gt; * * @param dataSource 数据源 * @return 是否需要初始化 *&#x2F; private boolean needInit(DataSource dataSource) &#123; &#x2F;&#x2F; 创建数据库 if (autoInitDatabase()) &#123; return true; &#125; &#x2F;&#x2F; 根据是否存在表来判断是否需要执行sql操作 JdbcTemplate jdbcTemplate &#x3D; new JdbcTemplate(dataSource); List&lt;Map&lt;String, Object&gt;&gt; list &#x3D; jdbcTemplate.queryForList(&quot;SELECT table_name FROM information_schema.TABLES where table_name &#x3D; &#39;user&#39; and table_schema &#x3D; &#39;&quot; + database + &quot;&#39;&quot;); boolean init &#x3D; CollectionUtils.isEmpty(list); if (init) &#123; log.info(&quot;库表不存在，即将执行建表及数据初始化&quot;); &#125; else &#123; log.info(&quot;表结构已存在，无需初始化&quot;); &#125; return init; &#125; &#x2F;** * 数据库不存在时，尝试创建数据库&lt;br&gt; * &lt;span&gt; * autoInitDatabase方法用于自动创建数据库。在方法内部，首先从配置文件中获取数据库连接URL、用户名和密码，并通过DriverManager创建数据库连接和Statement对象。 * 然后通过执行查询语句判断数据库是否存在，如果不存在则执行创建数据库的sql语句，并打印相应日志。 * &lt;&#x2F;span&gt; * * @return 是否成功创建数据库 *&#x2F; private boolean autoInitDatabase() &#123; &#x2F;&#x2F; 查询失败，可能是数据库不存在，尝试创建数据库之后再次测试 &#x2F;&#x2F;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;story?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai &#x2F;&#x2F;mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;story?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai URI url &#x3D; URI.create(SpringUtil.getConfig(&quot;spring.datasource.url&quot;).substring(5)); String uname &#x3D; SpringUtil.getConfig(&quot;spring.datasource.username&quot;); String pwd &#x3D; SpringUtil.getConfig(&quot;spring.datasource.password&quot;); try (Connection connection &#x3D; DriverManager.getConnection(&quot;jdbc:mysql:&#x2F;&#x2F;&quot; + url.getHost() + &quot;:&quot; + url.getPort() + &quot;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&quot;, uname, pwd); Statement statement &#x3D; connection.createStatement()) &#123; ResultSet set &#x3D; statement.executeQuery(&quot;select schema_name from information_schema.schemata where schema_name&#x3D;&#39;&quot; + database + &quot;&#39;&quot;); if (!set.next()) &#123; String createDb &#x3D; &quot;create database if not exists &quot; + database; connection.setAutoCommit(false); statement.execute(createDb); connection.commit(); log.info(&quot;创建数据库（&#123;&#125;）成功&quot;, createDb); if (set.isClosed()) &#123; set.close(); &#125; return true; &#125; set.close(); log.info(&quot;数据库已存在，无需初始化&quot;); return false; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; public class XmlParserUtils &#123; private static final Log logger &#x3D; LogFactory.getLog(XmlParserUtils.class); &#x2F;&#x2F; 私有化getInstance方法，用于获取XMLReader实例 private static XMLReader xmlReader; private XmlParserUtils() &#123; &#x2F;&#x2F; 防止实例化 &#125; public static List&lt;ClassPathResource&gt; loadDbChangeSetResources(String source) &#123; try &#123; XMLReader reader &#x3D; getXMLReader(); ChangeHandler logHandler &#x3D; new ChangeHandler(&quot;include&quot;, &quot;file&quot;); reader.setContentHandler(logHandler); Path path &#x3D; new ClassPathResource(source.replace(&quot;classpath:&quot;, &quot;&quot;)).getFile().toPath(); reader.parse(path.toString()); List&lt;String&gt; changeSetFiles &#x3D; logHandler.getSets(); List&lt;ClassPathResource&gt; result &#x3D; new ArrayList&lt;&gt;(); ChangeHandler setHandler &#x3D; new ChangeHandler(&quot;sqlFile&quot;, &quot;path&quot;); for (String set : changeSetFiles) &#123; reader.setContentHandler(setHandler); Path setPath &#x3D; new ClassPathResource(set).getFile().toPath(); reader.parse(setPath.toString()); result.addAll(setHandler.getSets().stream().map(ClassPathResource::new).collect(Collectors.toList())); setHandler.reset(); &#125; return result; &#125; catch (Exception e) &#123; throw new IllegalStateException(&quot;加载初始化脚本异常!&quot;, e); &#125; &#125; private static XMLReader getXMLReader() throws ParserConfigurationException, SAXException &#123; if (xmlReader &#x3D;&#x3D; null) &#123; SAXParserFactory factory &#x3D; SAXParserFactory.newInstance(); xmlReader &#x3D; factory.newSAXParser().getXMLReader(); &#125; return xmlReader; &#125; public static class ChangeHandler extends DefaultHandler &#123; private final String tag; private final String attr; private List&lt;String&gt; sets &#x3D; new ArrayList&lt;&gt;(); &#x2F;** * 构造函数 * * @param tag 标签 * @param attr 属性 *&#x2F; public ChangeHandler(String tag, String attr) &#123; this.tag &#x3D; tag; this.attr &#x3D; attr; &#125; @Override public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException &#123; if (tag.equals(qName)) &#123; sets.add(attributes.getValue(attr)); &#125; &#125; &#x2F;** * 获取变更脚本列表 * * @return 变更脚本列表 *&#x2F; public List&lt;String&gt; getSets() &#123; return sets; &#125; &#x2F;** * 重置变更脚本列表 *&#x2F; public void reset() &#123; sets.clear(); &#125; &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"}],"author":"ehzyil"},{"title":"Docker指令报错的解决方法'permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:'","slug":"2023/Docker指令报错的解决方法：'permission denied while trying to connect to the Docker...'","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/12/26/2023/Docker指令报错的解决方法：'permission denied while trying to connect to the Docker...'/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/Docker%E6%8C%87%E4%BB%A4%E6%8A%A5%E9%94%99%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%9A'permission%20denied%20while%20trying%20to%20connect%20to%20the%20Docker...'/","excerpt":"","text":"使用azure的服务器查看docker容器内的进程的时候出现一下错误， 意思是试图连接unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock:，但权限不够。 原因分析：这是因为你当前的用户没有这个权限。默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。即我们当前的用户不是root用户。 解决办法：把我们当前的用户添加到docker组中就可以了 第一步： sudo gpasswd -a username docker #将普通用户username加入到docker组中，username这个字段也可以直接换成$USER。 第二步：更新docker组 newgrp docker #更新docker组 第三步：再执行你报错的命令，此时就不会报错了。 ehzyil@AzureVM:~$ docker ps permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get \"http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json\": dial unix /var/run/docker.sock: connect: permission denied ehzyil@AzureVM:~$ sudo gpasswd -a ehzyil docker Adding user ehzyil to group docker ehzyil@AzureVM:~$ newgrp docker ehzyil@AzureVM:~$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ehzyil.xyz/tags/Docker/"},{"name":"linux","slug":"linux","permalink":"https://blog.ehzyil.xyz/tags/linux/"}],"author":"ehzyil"},{"title":"JS常用日期函数","slug":"2023/JS常用日期函数","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/12/26/2023/JS常用日期函数/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/JS%E5%B8%B8%E7%94%A8%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/","excerpt":"","text":"JS常用日期函数 &#x2F;&#x2F;获取完整的日期 var date&#x3D;new Date; var year&#x3D;date.getFullYear(); var month&#x3D;date.getMonth()+1; month &#x3D;(month&lt;10 ? &quot;0&quot;+month:month); var mydate &#x3D; (year.toString()+month.toString()); 注意，year.toString()+month.toString()不能写成year+month。不然如果月份大于等于10，则月份为数字，会和年份相加，如201210，则会变为2022，需要加.toString() 以下是搜到的有用内容： var myDate &#x3D; new Date(); myDate.getYear(); &#x2F;&#x2F;获取当前年份(2位) myDate.getFullYear(); &#x2F;&#x2F;获取完整的年份(4位,1970-????) myDate.getMonth(); &#x2F;&#x2F;获取当前月份(0-11,0代表1月) myDate.getDate(); &#x2F;&#x2F;获取当前日(1-31) myDate.getDay(); &#x2F;&#x2F;获取当前星期X(0-6,0代表星期天) myDate.getTime(); &#x2F;&#x2F;获取当前时间(从1970.1.1开始的毫秒数) myDate.getHours(); &#x2F;&#x2F;获取当前小时数(0-23) myDate.getMinutes(); &#x2F;&#x2F;获取当前分钟数(0-59) myDate.getSeconds(); &#x2F;&#x2F;获取当前秒数(0-59) myDate.getMilliseconds(); &#x2F;&#x2F;获取当前毫秒数(0-999) myDate.toLocaleDateString(); &#x2F;&#x2F;获取当前日期 var mytime&#x3D;myDate.toLocaleTimeString(); &#x2F;&#x2F;获取当前时间 myDate.toLocaleString( ); &#x2F;&#x2F;获取日期与时间 &lt;script language&#x3D;&quot;JavaScript&quot;&gt;function monthnow()&#123; var now &#x3D; new Date(); var monthn &#x3D; now.getMonth(); var yearn &#x3D; now.getYear(); window.location.href&#x3D;&quot;winnNamelist.jsp?getMonth&#x3D;&quot;+monthn+&quot;&amp;getYear&#x3D;&quot;+yearn; &#125;&lt;&#x2F;script&gt;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java Script","slug":"Java-Script","permalink":"https://blog.ehzyil.xyz/tags/Java-Script/"}],"author":"ehzyil"},{"title":"Java String hashCode生成负值","slug":"2023/Java String hashCode生成负值","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/12/26/2023/Java String hashCode生成负值/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/Java%20String%20hashCode%E7%94%9F%E6%88%90%E8%B4%9F%E5%80%BC/","excerpt":"","text":"转载 java String hashCode遇到的坑 在进行数据交换时，如果主键不是整型，需要对字符串，或联合主键拼接为字符串，进行hash，再进行取模分片，使用的是String自带的hashCode()方法，本来是件很方便的事，但是有些字符串取hashCode竟然是负数，使得分片为负数，找不到对应的分片，我们先看一下String 生成hashCode的代码： /** * Returns a hash code for this string. The hash code for a * &#123;@code String&#125; object is computed as * &lt;blockquote>&lt;pre> * s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1] * &lt;/pre>&lt;/blockquote> * using &#123;@code int&#125; arithmetic, where &#123;@code s[i]&#125; is the * &lt;i>i&lt;/i>th character of the string, &#123;@code n&#125; is the length of * the string, and &#123;@code ^&#125; indicates exponentiation. * (The hash value of the empty string is zero.) * * @return a hash code value for this object. */ public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length > 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125; 主要是根据字符串中字符的ascii码值来计算的，即 31 * hash + 字符的ASCII码值，int型的值取值范围为Integer.MIN_VALUE(-2147483648)～Integer.MAX_VALUE(2147483647)，所以如果字符串比较长，计算的数值就可能超出Integer.MAX_VALUE，造成数值溢出，值变成负数 几种比较极端的字符串hashCode值： String hashStr0 = \"35953305172933/\"; System.out.println(hashStr0.hashCode()); // 2147483647 Integer.MAX_VALUE System.out.println(Math.abs(hashStr0.hashCode())); // 2147483647 Integer.MAX_VALUE System.out.println(\"-------------------\"); String hashStr = \"359533051729330\"; System.out.println(hashStr.hashCode()); // -2147483648 Integer.MIN_VALUE System.out.println(Math.abs(hashStr.hashCode())); // -2147483648 Integer.MIN_VALUE System.out.println(\"-------------------\"); String hashStr2 = \"56800004874\"; System.out.println(hashStr2.hashCode()); // -2082984168 System.out.println(Math.abs(hashStr2.hashCode())); // 2082984168 System.out.println(\"-------------------\"); String hashStr3 = \"\"; System.out.println(hashStr3.hashCode()); // 0 System.out.println(Math.abs(hashStr3.hashCode())); // 0 System.out.println(\"-------------------\"); 当 key.hashCode() 值为 Interger.MIN_VALUE时候Maths.abs(key.hashCode()) 取 hash值为负。 对于字符串“359533051729330”的hashCode为Integer.MIN_VALUE，我们使用取绝对值还是超出Integer.MAX_VALUE，还是Integer.MIN_VALUE，所以针对这种极端情况是不可用的 要想利用hashCode为非负数，可以Integer.MAX_VALUE和与操作，这样最大正整数的符号位为0，与任何数与操作都是0，即是正数 int hash &#x3D; str.hashCode() &amp; Integer.MAX_VALUE;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"}],"author":"ehzyil"},{"title":"Java 实现 AES 加密和解密完整示例","slug":"2023/Java 实现 AES 加密和解密完整示例","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/12/26/2023/Java 实现 AES 加密和解密完整示例/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/Java%20%E5%AE%9E%E7%8E%B0%20AES%20%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B/","excerpt":"","text":"Java 实现 AES 加密和解密完整示例 遇到需求需要给已AES加密的用户姓名解密，并给出了python代码，网上找了个很全的Java 实现 AES 加密和解密完整示例，记录以下方便以后查阅。 转载Java 实现 AES 加密和解密完整示例 其他详细资料 1、简介AES，全称为 Advanced Encryption Standard，是一种分组密码算法，用于保护敏感数据的传输和存储。AES 分为 128 位和 256 位两种密钥长度，可以对数据进行加密和解密，保证数据的安全性和完整性。AES 主要应用于电子商务、移动支付、网络安全等领域，被广泛运用于现代社会的各个方面。AES 算法被设计为高度安全，可以在理论上保证其分组密码的安全性。然而，由于其复杂性和密钥长度，AES 算法的实现和应用也具有一定的技术难度。因此，在应用 AES算法时，需要注意加强密钥管理和安全性保障。 这个标准用来替代原先的 DES（Data Encryption Standard），已经被多方分析且广为全世界所使用。 AES 算法具有很多优点，例如快速、安全、可靠等。它可以加密大量数据，而不会因为加密过程中的数据量过大而变得缓慢。此外，AES 算法还支持块大小的自动调整，可以处理不同大小的数据块。 2、AES 加密模式2.1、加密方式ECB（Electronic Codebook）模式：这种模式是将整个明文分成若干段相同的小段，然后对每一小段进行加密。加密时，使用一个密钥，将明文中的每个字符与密钥中对应位置的字符进行异或运算，得到密文。 CBC（Cipher Block Chaining）模式：这种模式是先将明文切分成若干小段，然后每一小段与初始块或者上一段的密文段进行异或运算后，再与密钥进行加密。加密时，使用一个密钥和一个初始化向量（IV），初始化向量是一个16字节的向量，包含了加密算法所需的所有信息。 CFB（Cipher Feedback）模式：这种模式是一种较为复杂的加密模式，它结合了CBC和CTR两种模式的优点。在CFB模式中，加密过程中使用一个密钥和一个随机生成的初始化向量（IV），然后对明文进行加密。在加密完成后，通过对明文进行非对称加密来生成密文的向量。随后，通过对密文进行反向操作，将密文的向量与明文的向量进行异或运算，得到解密所需的密钥。 需要注意的是，ECB、CBC、CFB等模式都是对称加密算法，加密和解密使用相同的密钥。在使用这些算法时，需要注意保护密钥的安全，避免被恶意获取。 2.2、安全性ECB 不够安全，只适合于短数据的加密，而 CBC 和 CFB 相较于 ECB 更加安全，因为前一个密文块会影响当前明文块，使攻击者难以预测密文的结构。 2.3、速度ECB 是最简单的加密方式，速度最快，但由于安全性差不建议使用，CBC 因为每个明文块都要与前一个密文块进行异或操作，比 ECB 要慢一些，CFB 因为需要反复加密和解密，速度可能会更慢。 总的来说，选择 AES 的算法模式需要根据加密需要的安全性和速度来进行选择，通常推荐使用CBC 或 CFB 模式，而不是 ECB 模式。 3、Java 实现完整示例在 Java 中，可以使用 javax.crypto 包中的 Cipher 类来实现 AES 加密和解密。完整代码如下： import javax.crypto.Cipher; import javax.crypto.spec.IvParameterSpec; import javax.crypto.spec.SecretKeySpec; import java.nio.charset.StandardCharsets; import java.util.Base64; import java.util.Random; /** * &lt;h1>AES 加密和解密示例代码&lt;/h1> * Created by woniu * */ public class AESExample &#123; /** 加密模式之 ECB，算法/模式/补码方式 */ private static final String AES_ECB = \"AES/ECB/PKCS5Padding\"; /** 加密模式之 CBC，算法/模式/补码方式 */ private static final String AES_CBC = \"AES/CBC/PKCS5Padding\"; /** 加密模式之 CFB，算法/模式/补码方式 */ private static final String AES_CFB = \"AES/CFB/PKCS5Padding\"; /** AES 中的 IV 必须是 16 字节（128位）长 */ private static final Integer IV_LENGTH = 16; /*** * &lt;h2>空校验&lt;/h2> * @param str 需要判断的值 */ public static boolean isEmpty(Object str) &#123; return null == str || \"\".equals(str); &#125; /*** * &lt;h2>String 转 byte&lt;/h2> * @param str 需要转换的字符串 */ public static byte[] getBytes(String str)&#123; if (isEmpty(str)) &#123; return null; &#125; try &#123; return str.getBytes(StandardCharsets.UTF_8); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /*** * &lt;h2>初始化向量（IV），它是一个随机生成的字节数组，用于增加加密和解密的安全性&lt;/h2> */ public static String getIV()&#123; // String str = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"; // Random random = new Random(); // StringBuffer sb = new StringBuffer(); // for(int i = 0 ; i &lt; IV_LENGTH ; i++)&#123; // int number = random.nextInt(str.length()); // sb.append(str.charAt(number)); // &#125; // return sb.toString(); return \"1234567876543210\"; &#125; /*** * &lt;h2>获取一个 AES 密钥规范&lt;/h2> */ public static SecretKeySpec getSecretKeySpec(String key)&#123; SecretKeySpec secretKeySpec = new SecretKeySpec(getBytes(key), \"AES\"); return secretKeySpec; &#125; /** * &lt;h2>加密 - 模式 ECB&lt;/h2> * @param text 需要加密的文本内容 * @param key 加密的密钥 key * */ public static String encrypt(String text, String key)&#123; if (isEmpty(text) || isEmpty(key)) &#123; return null; &#125; try &#123; // 创建AES加密器 Cipher cipher = Cipher.getInstance(AES_ECB); SecretKeySpec secretKeySpec = getSecretKeySpec(key); cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec); // 加密字节数组 byte[] encryptedBytes = cipher.doFinal(getBytes(text)); // 将密文转换为 Base64 编码字符串 return Base64.getEncoder().encodeToString(encryptedBytes); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /** * &lt;h2>解密 - 模式 ECB&lt;/h2> * @param text 需要解密的文本内容 * @param key 解密的密钥 key * */ public static String decrypt(String text, String key)&#123; if (isEmpty(text) || isEmpty(key)) &#123; return null; &#125; // 将密文转换为16字节的字节数组 byte[] textBytes = Base64.getDecoder().decode(text); try &#123; // 创建AES加密器 Cipher cipher = Cipher.getInstance(AES_ECB); SecretKeySpec secretKeySpec = getSecretKeySpec(key); cipher.init(Cipher.DECRYPT_MODE, secretKeySpec); // 解密字节数组 byte[] decryptedBytes = cipher.doFinal(textBytes); // 将明文转换为字符串 return new String(decryptedBytes, StandardCharsets.UTF_8); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /** * &lt;h2>加密 - 自定义加密模式&lt;/h2> * @param text 需要加密的文本内容 * @param key 加密的密钥 key * @param iv 初始化向量 * @param mode 加密模式 * */ public static String encrypt(String text, String key, String iv, String mode)&#123; if (isEmpty(text) || isEmpty(key) || isEmpty(iv)) &#123; return null; &#125; try &#123; // 创建AES加密器 Cipher cipher = Cipher.getInstance(mode); SecretKeySpec secretKeySpec = getSecretKeySpec(key); cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec, new IvParameterSpec(getBytes(iv))); // 加密字节数组 byte[] encryptedBytes = cipher.doFinal(getBytes(text)); // 将密文转换为 Base64 编码字符串 return Base64.getEncoder().encodeToString(encryptedBytes); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /** * &lt;h2>解密 - 自定义加密模式&lt;/h2> * @param text 需要解密的文本内容 * @param key 解密的密钥 key * @param iv 初始化向量 * @param mode 加密模式 * */ public static String decrypt(String text, String key, String iv, String mode)&#123; if (isEmpty(text) || isEmpty(key) || isEmpty(iv)) &#123; return null; &#125; // 将密文转换为16字节的字节数组 byte[] textBytes = Base64.getDecoder().decode(text); try &#123; // 创建AES加密器 Cipher cipher = Cipher.getInstance(mode); SecretKeySpec secretKeySpec = getSecretKeySpec(key); cipher.init(Cipher.DECRYPT_MODE, secretKeySpec, new IvParameterSpec(getBytes(iv))); // 解密字节数组 byte[] decryptedBytes = cipher.doFinal(textBytes); // 将明文转换为字符串 return new String(decryptedBytes, StandardCharsets.UTF_8); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public static void main(String[] args) &#123; String text = \"411025200102175014\"; String key = \"rHx3pZwRTAb33psX\"; // 16字节的密钥 String iv = getIV(); String encryptTextEBC = encrypt(text, key); System.out.println(\"EBC 加密后内容：\" + encryptTextEBC); System.out.println(\"EBC 解密后内容：\" + decrypt(encryptTextEBC, key)); System.out.println(); String encryptTextCBC = encrypt(text, key, iv, AES_CBC); System.out.println(\"CBC 加密IV：\" + iv); System.out.println(\"CBC 加密后内容：\" + encryptTextCBC); System.out.println(\"CBC 解密后内容：\" + decrypt(encryptTextCBC, key, iv, AES_CBC)); System.out.println(); String encryptTextCFB = encrypt(text, key, iv, AES_CFB); System.out.println(\"CFB 加密IV：\" + iv); System.out.println(\"CFB 加密后内容：\" + encryptTextCFB); System.out.println(\"CFB 解密后内容：\" + decrypt(encryptTextCFB, key, iv, AES_CFB)); &#125; &#125; public static String decryptAES(String text) &#123; if (StringUtils.isEmpty(text)) return \"\"; text = text.substring(4); System.out.println(text); String mode = \"AES/CBC/PKCS5Padding\"; String iv = \"1234567876543210\"; String key = \"rHx3pZwRTAb33psX\"; // 16字节的密钥 // 将密文转换为16字节的字节数组 byte[] textBytes = Base64.getDecoder().decode(text); try &#123; // 创建AES加密器 Cipher cipher = Cipher.getInstance(mode); SecretKeySpec secretKeySpec = getSecretKeySpec(key); cipher.init(Cipher.DECRYPT_MODE, secretKeySpec, new IvParameterSpec(getBytes(iv))); // 解密字节数组 byte[] decryptedBytes = cipher.doFinal(textBytes); // 将明文转换为字符串 return new String(decryptedBytes, StandardCharsets.UTF_8); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; 需求中给出的python代码 AesEncryption.py import base64 # 导入base64模块 from Crypto.Cipher import AES # 从Crypto模块中导入AES加密算法 import StringUtil # 导入一个自定义的StringUtil模块 class AesEncryption: __AES_IV = '1234567876543210' # 初始化一个AES IV向量 def __init__(self, password: str = 'rHx3pZwRTAb33psX', prefix: str = 'AES:', encoding_protocol: str = 'ASCII'): self.__password = password # 初始化密码 self.__encoding_protocol = encoding_protocol # 初始化编码协议 self.__prefix = prefix # 初始化前缀 # AES加密方法 def aes_encrypt(self, text: str): block_size = 16 # 定义块大小为16 # 数据进行 PKCS5Padding 的填充 pad = lambda s: (s + (block_size - len(s) % block_size) * chr(block_size - len(s) % block_size)) # 定义填充函数 data = pad(text) # 对文本进行填充 # 创建加密对象 cipher = AES.new(self.__password.encode(), AES.MODE_CBC, self.__AES_IV.encode()) # 创建AES加密对象 # 得到加密后的字节码 encrypted_text = cipher.encrypt(bytes(data, self.__encoding_protocol)) # 进行加密 # base64 编码 encode_text = base64.b64encode(encrypted_text).decode(self.__encoding_protocol) # 进行base64编码 if StringUtil.is_str_not_null(self.__prefix): # 判断前缀是否不为空 encode_text = self.__prefix + encode_text # 如果前缀不为空，则添加前缀 return encode_text # 返回加密后的文本 # AES解密方法 def aes_decrypt(self, text: str): # 去掉 PKCS5Padding 的填充 un_pad = lambda s: s[:-ord(s[len(s) - 1:])] # 定义去除填充的函数 # 创建加密对象 cipher = AES.new(self.__password.encode(), AES.MODE_CBC, self.__AES_IV.encode()) # 创建AES解密对象 # base64 解码 text = StringUtil.split_by_first_str(text, self.__prefix) # 通过前缀分割文本 decode_text = base64.b64decode(str(text).encode()) # 进行base64解码 decrypt_text = un_pad(cipher.decrypt(decode_text)).decode(self.__encoding_protocol) # 进行解密 return decrypt_text # 返回解密后的文本 # 类方法：AES加密 @classmethod def aes_encrypt_cls(cls, text: str, password: str = 'rHx3pZwRTAb33psX', prefix: str = 'AES:', encoding_protocol: str = 'ASCII'): aes_en = AesEncryption(password=password, prefix=prefix, encoding_protocol=encoding_protocol) # 创建AesEncryption实例 return aes_en.aes_encrypt(text) # 调用实例方法进行加密 # 类方法：AES解密 @classmethod def aes_decrypt_cls(cls, text: str, password: str = 'rHx3pZwRTAb33psX', prefix: str = 'AES:', encoding_protocol: str = 'ASCII'): aes_de = AesEncryption(password=password, prefix=prefix, encoding_protocol=encoding_protocol) # 创建AesEncryption实例 return aes_de.aes_decrypt(text) # 调用实例方法进行解密 # 要加密的文本 text_to_encrypt = \"411025200102175014\" # 使用类方法进行加密 encrypted_text = AesEncryption.aes_encrypt_cls(text_to_encrypt) # 输出加密后的文本 print(\"Encrypted Text:\", encrypted_text) # 使用类方法进行解密 decrypted_text = AesEncryption.aes_decrypt_cls(encrypted_text) # 输出解密后的文本 print(\"Decrypted Text:\", decrypted_text) #StringUtil.py def is_str_not_null(text): if text is None: return False else: if type(text) == str: if text.strip() == '': return False else: return True else: raise Exception('text需为字符串') def split_by_first_str(text, prefix): if is_str_not_null(text) and is_str_not_null(prefix): sub_arr = text.split(prefix, 1) if len(sub_arr) > 1: return sub_arr[1] else: return text else: return text","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"},{"name":"AES","slug":"AES","permalink":"https://blog.ehzyil.xyz/tags/AES/"}],"author":"ehzyil"},{"title":"Java将list转字符串的方法","slug":"2023/Java将list转字符串的方法","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/12/26/2023/Java将list转字符串的方法/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/Java%E5%B0%86list%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"","text":"第一种：join()String.join(&quot;,&quot;, strList) 第二种：循环插入逗号public static &lt;T&gt; String parseListToStr(List&lt;T&gt; list)&#123; StringBuffer sb &#x3D; new StringBuffer(); if(listIsNotNull(list)) &#123; for(int i&#x3D;0;i&lt;&#x3D;list.size()-1;i++)&#123; if(i&lt;list.size()-1)&#123; sb.append(list.get(i) + &quot;,&quot;); &#125;else &#123; sb.append(list.get(i)); &#125; &#125; &#125; return sb.toString(); &#125; 第三种：stream流public static &lt;T&gt; String parseListToStr3(List&lt;T&gt; list)&#123; String result &#x3D; list.stream().map(String::valueOf).collect(Collectors.joining(&quot;,&quot;)); 第四种：使用谷歌Joiner方法import com.google.common.base.Joiner; public static &lt;T&gt; String parseListToStr(List&lt;T&gt; list)&#123; String result &#x3D; Joiner.on(&quot;,&quot;).join(list); return result; &#125; 导入com.google.common.base.Joiner; public static String strategy（String strategy）&#123; String result &#x3D; Joiner.on（“，”）.join（list）; 返回结果; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"}],"author":"ehzyil"},{"title":"Java循环删除List中元素的正确方式","slug":"2023/Java循环删除List中元素","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/12/26/2023/Java循环删除List中元素/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/Java%E5%BE%AA%E7%8E%AF%E5%88%A0%E9%99%A4List%E4%B8%AD%E5%85%83%E7%B4%A0/","excerpt":"","text":"Java循环删除List中元素的正确方式There are a few different ways to correctly delete elements from a List in Java. Here are some common methods: Using an Iterator: You can use an Iterator to loop through the List and remove elements based on a condition. This is the safest way to modify a List while iterating over it. List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;(); list.add(&quot;A&quot;); list.add(&quot;B&quot;); list.add(&quot;C&quot;); Iterator&lt;String&gt; iterator &#x3D; list.iterator(); while (iterator.hasNext()) &#123; String element &#x3D; iterator.next();&#x2F;&#x2F;删除之前必须显示调用 if (element.equals(&quot;B&quot;)) &#123; iterator.remove(); &#125; &#125; System.out.println(list); &#x2F;&#x2F; Output: [A, C] Using the removeIf() method: Java 8 introduced the removeIf() method in the List interface, which allows you to remove elements based on a specified condition using a Predicate. List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;(); list.add(&quot;A&quot;); list.add(&quot;B&quot;); list.add(&quot;C&quot;); list.removeIf(element -&gt; element.equals(&quot;B&quot;)); System.out.println(list); &#x2F;&#x2F; Output: [A, C] Using the removeAll() method: You can also use the removeAll() method to remove all occurrences of a specific element from the List. List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;(); list.add(&quot;A&quot;); list.add(&quot;B&quot;); list.add(&quot;C&quot;); list.removeAll(Collections.singleton(&quot;B&quot;)); System.out.println(list); &#x2F;&#x2F; Output: [A, C] Using a for loop in reverse order:You can iterate through the List in reverse order and remove elements that meet a certain condition. This approach is useful when you want to avoid using an Iterator. List&lt;String> list = new ArrayList&lt;>(); list.add(\"A\"); list.add(\"B\"); list.add(\"C\"); for (int i = list.size() - 1; i >= 0; i--) &#123; if (list.get(i).equals(\"B\")) &#123; list.remove(i); &#125; &#125; System.out.println(list); // Output: [A, C] Using the subList() method:You can utilize the subList() method to create a sub-list and then remove elements from it. This approach is helpful when you want to remove a range of elements from the List. List&lt;String> list = new ArrayList&lt;>(); list.add(\"A\"); list.add(\"B\"); list.add(\"C\"); list.subList(1, 2).clear(); System.out.println(list); // Output: [A, C] Using the Apache Commons Collections library:If you are open to using external libraries, the Apache Commons Collections library provides a CollectionUtils class with various methods for manipulating collections, including removing elements based on conditions. List&lt;String> list = new ArrayList&lt;>(); list.add(\"A\"); list.add(\"B\"); list.add(\"C\"); CollectionUtils.filter(list, object -> !object.equals(\"B\")); System.out.println(list); // Output: [A, C] 题外话其他方法 通过for循环删除（错误） 使用foreach循环删除（错误） 原因见: Java循环删除List中元素的正确方式","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"}],"author":"ehzyil"},{"title":"Java数组转List的三种方式","slug":"2023/Java数组转List的三种方式","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/12/26/2023/Java数组转List的三种方式/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/Java%E6%95%B0%E7%BB%84%E8%BD%ACList%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"Java数组转List的三种方式 需求中常用到数组转集合的操作,为了避免不出错并使用高效方法去网上找了篇非常不错的文章。 转载 Java数组转List的三种方式及对比 一.最常见方式（未必最佳）通过 Arrays.asList(strArray) 方式,将数组转换List后，不能对List增删，只能查改，否则抛异常。 关键代码： List list &#x3D; Arrays.asList(strArray); private void testArrayCastToListError() &#123; String[] strArray &#x3D; new String[2]; List list &#x3D; Arrays.asList(strArray); &#x2F;&#x2F;对转换后的list插入一条数据 list.add(&quot;1&quot;); System.out.println(list); &#125; 执行结果： Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) at com.darwin.junit.Calculator.testArrayCastToList(Calculator.java:19) at com.darwin.junit.Calculator.main(Calculator.java:44) 程序在list.add(“1”)处，抛出异常：UnsupportedOperationException。 原因解析：Arrays.asList(strArray)返回值是java.util.Arrays类中一个私有静态内部类java.util.Arrays.ArrayList，它并非java.util.ArrayList类。java.util.Arrays.ArrayList类具有 set()，get()，contains()等方法，但是不具有添加add()或删除remove()方法,所以调用add()方法会报错。 使用场景：Arrays.asList(strArray)方式仅能用在将数组转换为List后，不需要增删其中的值，仅作为数据源读取使用。 二.数组转为List后，支持增删改查的方式通过ArrayList的构造器，将Arrays.asList(strArray)的返回值由java.util.Arrays.ArrayList转为java.util.ArrayList。 关键代码：ArrayList list &#x3D; new ArrayList(Arrays.asList(strArray)) ; private void testArrayCastToListRight() &#123; String[] strArray &#x3D; new String[2]; ArrayList&lt;String&gt; list &#x3D; new ArrayList&lt;String&gt;(Arrays.asList(strArray)) ; list.add(&quot;1&quot;); System.out.println(list); &#125; 执行结果：成功追加一个元素“1”。 使用场景：需要在将数组转换为List后，对List进行增删改查操作，在List的数据量不大的情况下，可以使用。 三.通过集合工具类Collections.addAll()方法(最高效)通过Collections.addAll(arrayList, strArray)方式转换，根据数组的长度创建一个长度相同的List，然后通过Collections.addAll()方法，将数组中的元素转为二进制，然后添加到List中，这是最高效的方法。 关键代码： ArrayList&lt; String&gt; arrayList &#x3D; new ArrayList&lt;String&gt;(strArray.length); Collections.addAll(arrayList, strArray); 测试： private void testArrayCastToListEfficient()&#123; String[] strArray &#x3D; new String[2]; ArrayList&lt; String&gt; arrayList &#x3D; new ArrayList&lt;String&gt;(strArray.length); Collections.addAll(arrayList, strArray); arrayList.add(&quot;1&quot;); System.out.println(arrayList); &#125; 执行结果：同样成功追加一个元素“1”。 [null, null, 1] 使用场景：需要在将数组转换为List后，对List进行增删改查操作，在List的数据量巨大的情况下，优先使用，可以提高操作速度。 四.Java8可通过stream流将3种基本类型数组转为List如果JDK版本在1.8以上，可以使用流stream来将下列3种数组快速转为List，分别是int[]、long[]、double[]，其他数据类型比如short[]、byte[]、char[]，在JDK1.8中暂不支持。由于这只是一种常用方法的封装，不再纳入一种崭新的数组转List方式，暂时算是java流送给我们的常用工具方法吧。 转换代码示例如下： List&lt;Integer&gt; intList&#x3D; Arrays.stream(new int[] &#123; 1, 2, 3, &#125;).boxed().collect(Collectors.toList()); List&lt;Long&gt; longList&#x3D; Arrays.stream(new long[] &#123; 1, 2, 3 &#125;).boxed().collect(Collectors.toList()); List&lt;Double&gt; doubleList&#x3D; Arrays.stream(new double[] &#123; 1, 2, 3 &#125;).boxed().collect(Collectors.toList()); 如果是String数组，可以使用Stream流这样转换： String[] arrays &#x3D; &#123;&quot;tom&quot;, &quot;jack&quot;, &quot;kate&quot;&#125;; List&lt;String&gt; stringList&#x3D; Stream.of(arrays).collect(Collectors.toList()); 题外话下列代码为什么会报错？ String[] strArray &#x3D; new String[2]; Arrays.stream(strArray).boxed().collect(Collectors.toList()); 这段代码会报错是因为在将String数组转换为Stream后，使用boxed()方法将基本数据类型的Stream转换为包装类型的Stream。然而，String本身并不是基本数据类型，因此不需要使用boxed()方法。应该直接使用Arrays.stream(strArray).collect(Collectors.toList())即可将String数组转换为List。","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"}],"author":"ehzyil"},{"title":"Spring读取Resource下文件的几种方式","slug":"2023/Spring读取Resource下文件的几种方式","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.199Z","comments":true,"path":"2023/12/26/2023/Spring读取Resource下文件的几种方式/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/Spring%E8%AF%BB%E5%8F%96Resource%E4%B8%8B%E6%96%87%E4%BB%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"Spring读取Resource下文件的几种方式第一种：通过当前线程的类加载器获取资源文件； InputStream inputStream &#x3D; Thread.currentThread().getContextClassLoader().getResourceAsStream(&quot;excleTemplate&#x2F;test.xlsx&quot;); 第二种：通过当前类的类加载器获取资源文件 InputStream inputStream &#x3D; this.getClass().getResourceAsStream(&quot;&#x2F;excleTemplate&#x2F;test.xlsx&quot;); 前两种方式都是相对路径，需要注意资源文件的位置和调用代码的位置。 第三种：ClassPathResource这是使用Spring框架提供的方式，通过ClassPathResource来读取资源文件。它提供了更多的灵活性和功能，比如可以直接获取输入流。 ClassPathResource classPathResource &#x3D; new ClassPathResource(&quot;excleTemplate&#x2F;test.xlsx&quot;); InputStream inputStream &#x3D;classPathResource.getInputStream(); 第四种：ResourceUtils这种方式使用了ResourceUtils的getFile方法，但是需要注意的是ResourceUtils的getFile方法在生产环境中可能会出现问题。因为它使用了classpath:前缀，而这种方式在生产环境中并不适用。 File file &#x3D; ResourceUtils.getFile(&quot;classpath:excleTemplate&#x2F;test.xlsx&quot;); InputStream inputStream &#x3D; new FileInputStream(file); 应用实例：spring读取json文件public static com.alibaba.fastjson.JSONObject getProblemType() throws IOException &#123; &#x2F;&#x2F; 使用 ResourceUtils 工具类获取类路径下的 problemType.json 文件 File file &#x3D; ResourceUtils.getFile(&quot;classpath:data&#x2F;problemType.json&quot;); &#x2F;&#x2F; 使用 FileUtils 工具类将文件内容读取为字符串 String json &#x3D; FileUtils.readFileToString(file, &quot;UTF-8&quot;); &#x2F;&#x2F; 使用 fastjson 库将字符串解析为 JSONObject 对象 com.alibaba.fastjson.JSONObject jsonObject &#x3D; JSON.parseObject(json); &#x2F;&#x2F; 返回解析后的 JSONObject 对象 return jsonObject; &#125; 这段代码的作用是从类路径中读取一个名为 problemType.json 的文件，并将其内容解析为 JSONObject 对象，然后返回该对象。以下是注释的详细解释： public static com.alibaba.fastjson.JSONObject getProblemType() throws IOException &#123;: 这是一个公共的静态方法，返回类型为 com.alibaba.fastjson.JSONObject，并且可能会抛出 IOException 异常。 File file = ResourceUtils.getFile(&quot;classpath:data/problemType.json&quot;);: 使用 Spring 框架的 ResourceUtils 工具类获取类路径下的 problemType.json 文件。classpath: 前缀表示文件位于类路径下的 data 目录中。 String json = FileUtils.readFileToString(file, &quot;UTF-8&quot;);: 使用 Apache Commons IO 工具类 FileUtils 将文件内容读取为字符串。这里指定了文件编码为 UTF-8。 com.alibaba.fastjson.JSONObject jsonObject = JSON.parseObject(json);: 使用阿里巴巴的 fastjson 库将字符串解析为 JSONObject 对象。 return jsonObject;: 返回解析后的 JSONObject 对象。 替换成更保险的方法 public static com.alibaba.fastjson.JSONObject getProblemType() throws IOException &#123; &#x2F;&#x2F; 使用 ClassPathResource 工具类获取类路径下的 problemType.json 文件 ClassPathResource resource &#x3D; new ClassPathResource(&quot;data&#x2F;problemType.json&quot;); &#x2F;&#x2F; 使用 IOUtils 工具类将文件内容读取为字符串 String json &#x3D; IOUtils.toString(resource.getInputStream(), &quot;UTF-8&quot;); &#x2F;&#x2F; 使用 fastjson 库将字符串解析为 JSONObject 对象 com.alibaba.fastjson.JSONObject jsonObject &#x3D; JSON.parseObject(json); &#x2F;&#x2F; 返回解析后的 JSONObject 对象 return jsonObject; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.ehzyil.xyz/tags/Spring/"}],"author":"ehzyil"},{"title":"一条SQL更新语句是如何执行的？ to connect to the Docker daemon socket at unix:///var/run/docker.sock:'","slug":"2023/一条SQL更新语句是如何执行的？","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/12/26/2023/一条SQL更新语句是如何执行的？/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E4%B8%80%E6%9D%A1SQL%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/","excerpt":"","text":"一条SQL更新语句是如何执行的？ 转载MySQL实战45讲| 02 | 日志系统：一条SQL更新语句是如何执行的？ 从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c： mysql&gt; create table T(ID int primary key, c int); 如果要将 ID&#x3D;2 这一行的值加 1，SQL 语句就会这么写： mysql&gt; update T set c&#x3D;c+1 where ID&#x3D;2; 从前面的一条SQL查询语句是如何执行的？可以知道更新语句也会走一遍相同的流程。 执行语句前要先连接数据库，这是连接器的工作。 前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。 接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。 与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到你自己的程序里。 重要的日志模块：redo log不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。 如果有人要赊账或者还账的话，掌柜一般有两种做法： 一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉； 另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。 在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。 这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？ 同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。 而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。 如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。 与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。 重要的日志模块：binlog前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。 我想你肯定会问，为什么会有两份日志呢？ 因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。 这两种日志有以下三点不同。 redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 update T set c=c+1 where ID=2; 执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。 你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。 两阶段提交为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从怎样让数据库恢复到半个月内任意一秒的状态？说起。 前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。 当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做： 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库； 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。 这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。 好了，说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。 由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。 仍然用前面的 update 语句来做例子。假设当前 ID&#x3D;2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？ 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。 可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？ 其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。 简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 小结redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 我还跟你介绍了与 MySQL 日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。 思考题前面说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？ 好处是“最长恢复时间”更短。 在一天一备的模式里，最坏情况下需要应用一天的 binlog。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。 一周一备最坏情况就要应用一周的 binlog 了。 系统的对应指标就是RTO（恢复目标时间）。 当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间，所以这个 RTO 是成本换来的，就需要你根据业务重要性来评估了。","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"}],"author":"ehzyil"},{"title":"一条SQL查询语句是如何执行的？","slug":"2023/一条SQL查询语句是如何执行的？","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/12/26/2023/一条SQL查询语句是如何执行的？/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E4%B8%80%E6%9D%A1SQL%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/","excerpt":"","text":"一条SQL查询语句是如何执行的？ 转载MySQL实战45讲| 01 | 基础架构：一条SQL查询语句是如何执行的？ 平时我们使用数据库，看到的通常都是一个整体。比如，你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时： mysql> update T set c=c+1 where ID=2; 我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。 今天来把 MySQL 拆解一下，看看里面都有哪些“零件”，希望借由这个拆解过程，让我们对MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。 下面是 MySQL 的基本架构示意图，从中可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。 大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。 也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table 语句中使用 engine&#x3D;memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。 从图中不难看出，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。 连接器第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的： mysql -h$ip -P$port -u$user -p 输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。 连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。 如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 常见的有远程连接不上mysql(host为 % 表示不限制ip localhost表示本机使用 )，这时就需要修改root的权限 mysql&gt; select host,user,plugin,authentication_string from mysql.user; mysql&gt; alter user &#39;root&#39;@&#39;%&#39; identified with mysql_native_password by &#39;123456&#39;; mysql&gt; FLUSH PRIVILEGES; 连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。 客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。 如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。 数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。 但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。 怎么解决这个问题呢？你可以考虑以下两种方案。 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。 MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。 但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。 好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样： mysql&gt; select SQL_CACHE * from T where ID&#x3D;10； 需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。 分析器如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。 MySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。 做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。 mysql&gt; elect * from t where ID&#x3D;1; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;elect * from t where ID&#x3D;1&#39; at line 1 一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。 优化器经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join： mysql&gt; select * from t1 join t2 using(ID) where t1.c&#x3D;10 and t2.d&#x3D;20; 既可以先从表 t1 里面取出 c&#x3D;10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。 也可以先从表 t2 里面取出 d&#x3D;20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。 这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。 优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。 执行器MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。 mysql&gt; select * from T where ID&#x3D;10; ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39; 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的： 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 至此，这个语句就执行完成了。 对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。 你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。 在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。 课后问题如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k&#x3D;1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？ 分析器阶段，在分析器阶段主要会进行两项事，一是语法分析，根据mysql的关键字进行验证和解析；二是词法分析，会在词法解析的基础上进一步做表名和字段名称的验证和解析，判断你输入的这个 SQL 语句是否满足 MySQL 语法。因为没有k这一列所以在语法分析时会报错。","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"}],"author":"ehzyil"},{"title":"事务隔离：为什么你改了我还看不见？","slug":"2023/事务隔离：为什么你改了我还看不见？","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/12/26/2023/事务隔离：为什么你改了我还看不见？/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81%EF%BC%9F/","excerpt":"","text":"事务隔离：为什么你改了我还看不见？ 转载MySQL实战45讲| 03 | 事务隔离：为什么你改了我还看不见？ 提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。 转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。 简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。 今天的文章里，我将会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议，希望这些案例能加深你对 MySQL 事务原理的理解。 隔离性与隔离级别提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是“隔离性”。 当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。 在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释： 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。 mysql&gt; create table T(c int) engine&#x3D;InnoDB; insert into T(c) values(1); 我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。 配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。 mysql&gt; show variables like &#39;transaction_isolation&#39;; +-----------------------+----------------+ | Variable_name | Value | +-----------------------+----------------+ | transaction_isolation | READ-COMMITTED | +-----------------------+----------------+ 总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。 假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。 这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。 事务隔离的实现理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC)。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。 你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。 什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。 基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。 事务的启动方式如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种： 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。 set autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。 有些客户端连接框架会默认连接成功后先执行一个 set autocommit&#x3D;0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。 因此，我会建议你总是使用 set autocommit&#x3D;1, 通过显式语句的方式来启动事务。 但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。 在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 复制代码 小结这篇文章里面，介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。 课后题你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？ 这个问题，我们可以从应用开发端和数据库端来看。 首先，从应用开发端来看： 确认是否使用了 set autocommit&#x3D;0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin&#x2F;commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例） 其次，从数据库端来看： 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 &#x2F; 或者 kill； Percona 的 pt-kill 这个工具不错，推荐使用； 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题； 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"}],"author":"ehzyil"},{"title":"开启 Azure 虚拟机的 root 账户","slug":"2023/开启 Azure 虚拟机的 root 账户","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/12/26/2023/开启 Azure 虚拟机的 root 账户/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E5%BC%80%E5%90%AF%20Azure%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%20root%20%E8%B4%A6%E6%88%B7/","excerpt":"","text":"使用finalshell连接白嫖的azure虚拟服务器发现root账号忘了，于是查询得知下面的教程。 默认情况微软 Azure 云是没有开启 root 账户的，root 账户是禁用状态。 首先执行：sudo passwd root 命令初始化root用户密码 sudo passwd root 修改 sshd_config 文件 开启 root 访问权限 sudo vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config 在 sshd_config 文件里的 Authentication 部分加上以下内容： PermitRootLogin yes 编辑完毕后，重启 ssh 服务，执行如下命令： sudo systemctl restart sshd # 重启 ssh 服务以应用更改 最后尝试以 root 用户登陆，显示登陆成功，并且用户为root账户。 执行的代码和结果如下： ehzyil@AzureVM:~&#x2F;data&#x2F;script$ sudo passwd root New password: Retype new password: passwd: password updated successfully ehzyil@AzureVM:~&#x2F;data&#x2F;script$ sudo vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config ehzyil@AzureVM:~&#x2F;data&#x2F;script$ sudo systemctl restart sshd ehzyil@AzureVM:~&#x2F;data&#x2F;script$ su Password: root@AzureVM:&#x2F;home&#x2F;ehzyil&#x2F;data&#x2F;script# bash &lt;(curl -L https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;v2fly&#x2F;fhs-install-v2ray&#x2F;master&#x2F;install-release.sh) 相似系统启用Root用户 ​ Ubuntu 及 Ubuntu SSH 启用 Root 用户 - 欧尼酱的小屋","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://blog.ehzyil.xyz/tags/linux/"},{"name":"Azure","slug":"Azure","permalink":"https://blog.ehzyil.xyz/tags/Azure/"}],"author":"ehzyil"},{"title":"深入浅出索引（上）","slug":"2023/深入浅出索引（上）","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/12/26/2023/深入浅出索引（上）/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%8A%EF%BC%89/","excerpt":"","text":"深入浅出索引（上） 转载MySQL实战45讲| 04 | 深入浅出索引（上） 提到数据库索引，我想你并不陌生，在日常工作中会经常接触到。比如某一个 SQL 查询比较慢，分析完原因之后，你可能就会说“给某个字段加个索引吧”之类的解决方案。但到底什么是索引，索引又是如何工作的呢？今天就让我们一起来聊聊这个话题吧。 数据库索引的内容比较多，我分成了上下两篇文章。索引是数据库系统里面最重要的概念之一，所以我希望你能够耐心看完。在后面的实战文章中，我也会经常引用这两篇文章中提到的知识点，加深你对数据库索引的理解。 一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。 索引的常见模型索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。 下面我主要从使用的角度，为你简单分析一下这三种模型的区别。 哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。 不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。 假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示： 图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。 需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。 你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。 所以，哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。 而有序数组在等值查询和范围查询场景中的性能就都非常优秀。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示： 这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。 同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。 如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。 二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示： 二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&gt; UserC -&gt; UserF -&gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。 当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。 树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。 你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。 以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。 N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。 不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。 你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。 截止到这里，我用了半篇文章的篇幅和你介绍了不同的数据结构，以及它们的适用场景，你可能会觉得有些枯燥。但是，我建议你还是要多花一些时间来理解这部分内容，毕竟这是数据库处理数据的核心概念之一，在分析问题的时候会经常用到。当你理解了索引的模型后，就会发现在分析问题的时候会有一个更清晰的视角，体会到引擎设计的精妙之处。 现在，我们一起进入相对偏实战的内容吧。 在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。 InnoDB 的索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。 每一个索引在 InnoDB 里面对应一棵 B+ 树。 假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。 这个表的建表语句是： mysql&gt; create table T( id int primary key, k int not null, name varchar(16), index (k))engine&#x3D;InnoDB; 表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。 从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。 根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？ 如果语句是 select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树； 如果语句是 select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。 也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 索引维护B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。 而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。 除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。 当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。 基于上面的索引维护过程说明，我们来讨论一个案例： 你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。 自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。 插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。 也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。 除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？ 由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。 显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的： 只有一个索引； 该索引必须是唯一索引。 你一定看出来了，这就是典型的 KV 场景。 由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。 这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。 小结今天，我跟你分析了数据库引擎可用的数据结构，介绍了 InnoDB 采用的 B+ 树结构，以及为什么 InnoDB 要这么选择。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。 由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。 课后题对于上面例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写： alter table T drop index k; alter table T add index(k); 如果你要重建主键索引，也可以这么写： alter table T drop primary key; alter table T add primary key(id); 我的问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？ 为什么要重建索引。我们文章里面有提到，索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。 重建索引 k 的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine&#x3D;InnoDB。","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"}],"author":"ehzyil"},{"title":"深入浅出索引（下）","slug":"2023/深入浅出索引（下）","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/12/26/2023/深入浅出索引（下）/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%8B%EF%BC%89/","excerpt":"","text":"转载MySQL实战45讲 | 05 | 深入浅出索引（下） 在上一篇文章中，我和你介绍了 InnoDB 索引的数据结构模型，今天我们再继续聊聊跟 MySQL 索引有关的概念。 在开始这篇文章之前，我们先来看一下这个问题： 在下面这个表 T 中，如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？ 下面是这个表的初始化语句。 mysql&gt; create table T ( ID int primary key, k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT &#39;&#39;, index k(k)) engine&#x3D;InnoDB; insert into T values(100,1, &#39;aa&#39;),(200,2,&#39;bb&#39;),(300,3,&#39;cc&#39;),(500,5,&#39;ee&#39;),(600,6,&#39;ff&#39;),(700,7,&#39;gg&#39;); 现在，我们一起来看看这条 SQL 查询语句的执行流程： 在 k 索引树上找到 k&#x3D;3 的记录，取得 ID &#x3D; 300； 再到 ID 索引树查到 ID&#x3D;300 对应的 R3； 在 k 索引树取下一个值 k&#x3D;5，取得 ID&#x3D;500； 再回到 ID 索引树查到 ID&#x3D;500 对应的 R4； 在 k 索引树取下一个值 k&#x3D;6，不满足条件，循环结束。 在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。 在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？ 覆盖索引如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。 备注：关于如何查看扫描行数的问题，我将会在第 16 文章《如何正确地显示随机消息？》中，和你详细讨论。 基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？ 假设这个市民表的定义是这样的： CREATE TABLE &#96;tuser&#96; ( &#96;id&#96; int(11) NOT NULL, &#96;id_card&#96; varchar(32) DEFAULT NULL, &#96;name&#96; varchar(32) DEFAULT NULL, &#96;age&#96; int(11) DEFAULT NULL, &#96;ismale&#96; tinyint(1) DEFAULT NULL, PRIMARY KEY (&#96;id&#96;), KEY &#96;id_card&#96; (&#96;id_card&#96;), KEY &#96;name_age&#96; (&#96;name&#96;,&#96;age&#96;) ) ENGINE&#x3D;InnoDB 我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？ 如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。 当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。 最左前缀原则看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？ 这里，我先和你说结论吧。B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。 为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。 可以看到，索引项是按照索引定义里面出现的字段顺序排序的。 当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。 如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。 可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。 基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。 这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。 那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。 这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。 索引下推上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？ 我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： mysql&gt; select * from tuser where name like &#39;张 %&#39; and age&#x3D;10 and ismale&#x3D;1; 复制代码 你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。 然后呢？ 当然是判断其他条件是否满足。 在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 图 3无索引下推执行流程 和图 4索引下推执行流程，是这两个过程的执行流程图。 在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。 图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。 图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。 小结今天这篇文章，我和你继续讨论了数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。你可以看到，在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。 课后题实际上主键索引也是可以使用多个字段的。DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的： CREATE TABLE &#96;geek&#96; ( &#96;a&#96; int(11) NOT NULL, &#96;b&#96; int(11) NOT NULL, &#96;c&#96; int(11) NOT NULL, &#96;d&#96; int(11) NOT NULL, PRIMARY KEY (&#96;a&#96;,&#96;b&#96;), KEY &#96;c&#96; (&#96;c&#96;), KEY &#96;ca&#96; (&#96;c&#96;,&#96;a&#96;), KEY &#96;cb&#96; (&#96;c&#96;,&#96;b&#96;) ) ENGINE&#x3D;InnoDB; 公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。 但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？ 同事告诉他，是因为他们的业务里面有这样的两种语句： select * from geek where c&#x3D;N order by a limit 1; select * from geek where c&#x3D;N order by b limit 1; 我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？ 表记录–a–|–b–|–c–|–d–1 2 3 d1 3 2 d1 4 3 d2 1 3 d2 2 2 d2 3 4 d主键 a，b 的聚簇索引组织顺序相当于 order by a,b ，也就是先按 a 排序，再按 b 排序，c 无序。 索引 ca 的组织是先按 c 排序，再按 a 排序，同时记录主键–c–|–a–|–主键部分b– （注意，这里不是 ab，而是只有 b）2 1 32 2 23 1 23 1 43 2 14 2 3这个跟索引 c 的数据是一模一样的。 索引 cb 的组织是先按 c 排序，在按 b 排序，同时记录主键–c–|–b–|–主键部分a– （同上）2 2 22 3 13 1 23 2 13 4 14 3 2 所以，结论是 ca 可以去掉，cb 需要保留。","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"}],"author":"ehzyil"},{"title":"Java线程池","slug":"2023/线程池","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/12/26/2023/线程池/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"构造方法我们在构造线程池的时候，使用了ThreadPoolExecutor的构造方法： public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable> workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; 先来看看几个参数的含义： corePoolSize: 核心线程数 maximumPoolSize:允许的最大线程数（核心线程数+非核心线程数） workQueue:线程池任务队列 用来保存等待执行的任务的阻塞队列，常见阻塞队列有 ArrayBlockingQueue：一个基于数组结构的有界阻塞队列 LinkedBlockingQueue：基于链表结构的阻塞队列 SynchronousQueue：不存储元素的阻塞队列 PriorityBlockingQueue：具有优先级的无限阻塞队列 handler: 线程池饱和拒绝策略 JDK线程池框架提供了四种策略： 也可以根据自己的应用场景，实现RejectedExecutionHandler接口来自定义策略。 AbortPolicy：直接抛出异常，默认策略。 CallerRunsPolicy：用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃任务队列里最老的任务 DiscardPolicy:不处理，丢弃当前任务 上面四个是和线程池工作流程息息相关的参数，我们再来看看剩下三个参数。 keepAliveTime:非核心线程闲置下来最多存活的时间 unit：线程池中非核心线程保持存活的时间 threadFactory:创建一个新线程时使用的工厂，可以用来设定线程名等(不指定使用默认线程工厂) 线程池工作流程 向线程池提交任务的时候： 如果当前运行的线程少于核心线程数corePoolSize，则创建新线程来执行任务 如果运行的线程等于或多于核心线程数corePoolSize，则将任务加入任务队列workQueue 如果任务队列workQueue已满，创建新的线程来处理任务 如果创建新线程使当前总线程数超过最大线程数maximumPoolSize，任务将被拒绝，线程池拒绝策略handler执行 线程池工作源码分析提交线程（execute）线程池执行任务的方法如下： public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); //获取当前线程池的状态+线程个数变量的组合值 int c = ctl.get(); //1.如果正在运行线程数少于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &#123; //开启新线程运行 if (addWorker(command, true)) return; c = ctl.get(); &#125; //2. 判断线程池是否处于运行状态，是则添加任务到阻塞队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; //二次检查 int recheck = ctl.get(); //如果当前线程池不是运行状态，则从队列中移除任务，并执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //如若当前线程池为空，则添加一个新线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //最后尝试添加线程，如若添加失败，执行拒绝策略 else if (!addWorker(command, false)) reject(command); &#125; 我们来看一下execute()的详细流程图： 新增线程 (addWorker)在execute方法代码里，有个关键的方法private boolean addWorker(Runnable firstTask, boolean core)，这个方法主要完成两部分工作：增加线程数、添加任务，并执行。 我们先来看第一部分增加线程数： retry: for (;;) &#123; int c &#x3D; ctl.get(); int rs &#x3D; runStateOf(c); &#x2F;&#x2F; 1.检查队列是否只在必要时为空（判断线程状态，且队列不为空） if (rs &gt;&#x3D; SHUTDOWN &amp;&amp; ! (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp; firstTask &#x3D;&#x3D; null &amp;&amp; ! workQueue.isEmpty())) return false; &#x2F;&#x2F;2.循环CAS增加线程个数 for (;;) &#123; int wc &#x3D; workerCountOf(c); &#x2F;&#x2F;2.1 如果线程个数超限则返回 false if (wc &gt;&#x3D; CAPACITY || wc &gt;&#x3D; (core ? corePoolSize : maximumPoolSize)) return false; &#x2F;&#x2F;2.2 CAS方式增加线程个数，同时只有一个线程成功，成功跳出循环 if (compareAndIncrementWorkerCount(c)) break retry; &#x2F;&#x2F;2.3 CAS失败，看线程池状态是否变化，变化则跳到外层，尝试重新获取线程池状态，否则内层重新CAS c &#x3D; ctl.get(); &#x2F;&#x2F; Re-read ctl if (runStateOf(c) !&#x3D; rs) continue retry; &#125; &#125; &#x2F;&#x2F;3. 到这说明CAS成功了 boolean workerStarted &#x3D; false; boolean workerAdded &#x3D; false; 接着来看第二部分添加任务，并执行 Worker w &#x3D; null; try &#123; &#x2F;&#x2F;4.创建worker w &#x3D; new Worker(firstTask); final Thread t &#x3D; w.thread; if (t !&#x3D; null) &#123; &#x2F;&#x2F;4.1、加独占锁 ，为了实现workers同步，因为可能多个线程调用了线程池的excute方法 final ReentrantLock mainLock &#x3D; this.mainLock; mainLock.lock(); try &#123; &#x2F;&#x2F;4.2、重新检查线程池状态，以避免在获取锁前调用了shutdown接口 int rs &#x3D; runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp; firstTask &#x3D;&#x3D; null)) &#123; if (t.isAlive()) &#x2F;&#x2F; precheck that t is startable throw new IllegalThreadStateException(); &#x2F;&#x2F;4.3添加任务 workers.add(w); int s &#x3D; workers.size(); if (s &gt; largestPoolSize) largestPoolSize &#x3D; s; workerAdded &#x3D; true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; &#x2F;&#x2F;4.4、添加成功之后启动任务 if (workerAdded) &#123; t.start(); workerStarted &#x3D; true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; 我们来看一下整体的流程： 执行线程(runWorker)用户线程提交到线程池之后，由Worker执行，Worker是线程池内部一个继承AQS、实现Runnable接口的自定义类，它是具体承载任务的对象。 先看一下它的构造方法： Worker(Runnable firstTask) &#123; setState(-1); &#x2F;&#x2F; 在调用runWorker之前禁止中断 this.firstTask &#x3D; firstTask; this.thread &#x3D; getThreadFactory().newThread(this); &#x2F;&#x2F;创建一个线程 &#125; 在构造函数内 首先设置 state&#x3D;-1,现了简单不可重入独占锁，state&#x3D;0表示锁未被获取状态，state&#x3D;1表示锁已被获取状态，设置状态大小为-1，是为了避免线程在运行runWorker()方法之前被中断 firstTask记录该工作线程的第一个任务 thread是具体执行任务的线程 它的run方法直接调用runWorker，真正地执行线程就是在我们的runWorker 方法里： final void runWorker(Worker w) &#123; Thread wt &#x3D; Thread.currentThread(); Runnable task &#x3D; w.firstTask; w.firstTask &#x3D; null; w.unlock(); &#x2F;&#x2F; 允许中断 boolean completedAbruptly &#x3D; true; try &#123; &#x2F;&#x2F;获取当前任务，从队列中获取任务 while (task !&#x3D; null || (task &#x3D; getTask()) !&#x3D; null) &#123; w.lock(); ………… try &#123; &#x2F;&#x2F;执行任务前做一些类似统计之类的事情 beforeExecute(wt, task); Throwable thrown &#x3D; null; try &#123; &#x2F;&#x2F;执行任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown &#x3D; x; throw x; &#125; catch (Error x) &#123; thrown &#x3D; x; throw x; &#125; catch (Throwable x) &#123; thrown &#x3D; x; throw new Error(x); &#125; finally &#123; &#x2F;&#x2F; 执行任务完毕后干一些些事情 afterExecute(task, thrown); &#125; &#125; finally &#123; task &#x3D; null; &#x2F;&#x2F; 统计当前Worker 完成了多少个任务 w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly &#x3D; false; &#125; finally &#123; &#x2F;&#x2F;执行清理工作 processWorkerExit(w, completedAbruptly); &#125; &#125; 代码看着多，其实砍掉枝蔓，最核心的点就是task.run()让线程跑起来。 获取任务(getTask)我们在上面的执行任务runWorker里看到，这么一句while (task != null || (task = getTask()) != null),执行的任务是要么当前传入的firstTask，或者还可以通过getTask()获取，这个getTask的核心目的就是从队列中获取任务。 private Runnable getTask() &#123; &#x2F;&#x2F;poll()方法是否超时 boolean timedOut &#x3D; false; &#x2F;&#x2F;循环获取 for (;;) &#123; int c &#x3D; ctl.get(); int rs &#x3D; runStateOf(c); &#x2F;&#x2F; 1.线程池未终止，且队列为空，返回null if (rs &gt;&#x3D; SHUTDOWN &amp;&amp; (rs &gt;&#x3D; STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; &#x2F;&#x2F;工作线程数 int wc &#x3D; workerCountOf(c); boolean timed &#x3D; allowCoreThreadTimeOut || wc &gt; corePoolSize; &#x2F;&#x2F;2.判断工作线程数是否超过最大线程数 &amp;&amp; 超时判断 &amp;&amp; 工作线程数大于0或队列为空 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; &#x2F;&#x2F;从任务队列中获取线程 Runnable r &#x3D; timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); &#x2F;&#x2F;获取成功 if (r !&#x3D; null) return r; timedOut &#x3D; true; &#125; catch (InterruptedException retry) &#123; timedOut &#x3D; false; &#125; &#125; &#125; 总结一下，Worker执行任务的模型如下： 线程池的关闭线程池提供了 shutdown 和 shutdownNow 两个⽅法来关闭线程池。 shutdown() /** * 启动⼀次顺序关闭，在这次关闭中，执⾏器不再接受新任务，但会继续处理队列中的已存在任务。 * 当所有任务都完成后，线程池中的线程会逐渐退出。 */ public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; // ThreadPoolExecutor的主锁 mainLock.lock(); // 加锁以确保独占访问 try &#123; checkShutdownAccess(); // 检查是否有关闭的权限 advanceRunState(SHUTDOWN); // 将执⾏器的状态更新为SHUTDOWN interruptIdleWorkers(); // 中断所有闲置的⼯作线程 onShutdown(); // ScheduledThreadPoolExecutor中的挂钩⽅法，可供⼦类᯿写以进⾏额外操作 &#125; finally &#123; mainLock.unlock(); // ⽆论try块如何退出都要释放锁 &#125; tryTerminate(); // 如果条件允许，尝试终⽌执⾏器 &#125; 就是将线程池的状态修改为 SHUTDOWN，然后尝试打断空闲的线程（如何判断空闲，上⾯在说 Worker 继承 AQS 的时候说过），也就是在阻塞等待任务的线程 shutdownNow () &#x2F;** * 尝试停⽌所有正在执⾏的任务，停⽌处理等待的任务， * 并返回等待处理的任务列表。 * * @return 从未开始执⾏的任务列表 *&#x2F; public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; &#x2F;&#x2F; ⽤于存储未执⾏的任务的列表 final ReentrantLock mainLock &#x3D; this.mainLock; &#x2F;&#x2F; ThreadPoolExecutor的主锁 mainLock.lock(); &#x2F;&#x2F; 加锁以确保独占访问 try &#123; checkShutdownAccess(); &#x2F;&#x2F; 检查是否有关闭的权限 advanceRunState(STOP); &#x2F;&#x2F; 将执⾏器的状态更新为STOP interruptWorkers(); &#x2F;&#x2F; 中断所有⼯作线程 tasks &#x3D; drainQueue(); &#x2F;&#x2F; 清空队列并将结果放⼊任务列表中 &#125; finally &#123; mainLock.unlock(); &#x2F;&#x2F; ⽆论try块如何退出都要释放锁 &#125; tryTerminate(); &#x2F;&#x2F; 如果条件允许，尝试终⽌执⾏器 return tasks; &#x2F;&#x2F; 返回队列中未被执⾏的任务列表 &#125; 就是将线程池的状态修改为 STOP，然后尝试打断所有的线程，从阻塞队列中移除剩余的任务，这也是为什么 shutdownNow 不能执⾏剩余任务的原因。 所以也可以看出 shutdown ⽅法和 shutdownNow ⽅法的主要区别就是，shutdown 之后还能处理在队列中的任 务，shutdownNow 直接就将任务从队列中移除，线程池⾥的线程就不再处理了。 线程池的监控如果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根据线程池的使用状况快速定位问题。 可以通过线程池提供的参数和方法来监控线程池： getActiveCount() ：线程池中正在执行任务的线程数量 getCompletedTaskCount() ：线程池已完成的任务数量，该值小于等于 taskCount getCorePoolSize() ：线程池的核心线程数量 getLargestPoolSize()：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过，也就是达到了 maximumPoolSize getMaximumPoolSize()：线程池的最大线程数量 getPoolSize() ：线程池当前的线程数量 getTaskCount() ：线程池已经执行的和未执行的任务总数 还可以通过扩展线程池来进行监控： 通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法， 也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。例如，监控任务的平均执行时间、最大执行时间和最小执行时间等。 小结到这，了解了execute和worker的一些流程，可以说其实ThreadPoolExecutor 的实现就是一个生产消费模型。 当用户添加任务到线程池时相当于生产者生产元素，workers 线程工作集中的线程直接执行任务或者从任务队列里面获取任务时则相当于消费者消费元素。 线程池生命周期线程池状态表示在ThreadPoolExecutor里定义了一些状态，同时利用高低位的方式，让ctl这个参数能够保存状态，又能保存线程数量，非常巧妙！[6] &#x2F;&#x2F;记录线程池状态和线程数量 private final AtomicInteger ctl &#x3D; new AtomicInteger(ctlOf(RUNNING, 0)); &#x2F;&#x2F;29 private static final int COUNT_BITS &#x3D; Integer.SIZE - 3; private static final int CAPACITY &#x3D; (1 &lt;&lt; COUNT_BITS) - 1; &#x2F;&#x2F; 线程池状态 private static final int RUNNING &#x3D; -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN &#x3D; 0 &lt;&lt; COUNT_BITS; private static final int STOP &#x3D; 1 &lt;&lt; COUNT_BITS; private static final int TIDYING &#x3D; 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED &#x3D; 3 &lt;&lt; COUNT_BITS; 高3位表示状态，低29位记录线程数量： 线程池状态流转线程池一共定义了五种状态，来看看这些状态是怎么流转的[6]： RUNNING：运行状态，接受新的任务并且处理队列中的任务。 SHUTDOWN：关闭状态(调用了 shutdown 方法)。不接受新任务，,但是要处理队列中的任务。 STOP：停止状态(调用了 shutdownNow 方法)。不接受新任务，也不处理队列中的任务，并且要中断正在处理的任务。 TIDYING：所有的任务都已终止了，workerCount 为 0，线程池进入该状态后会调terminated() 方法进入 TERMINATED 状态。 TERMINATED：终止状态，terminated() 方法调用结束后的状态。 Executors 构建线程池在上⾯的示例中，我们使⽤了 JDK 内部提供的 Executors ⼯具类来快速创建线程池。 1）固定线程数量的线程池：核⼼线程数与最⼤线程数相等 public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 2）单个线程数量的线程池 public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 3）接近⽆限⼤线程数量的线程池 public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 4）带定时调度功能的线程池 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125; 虽然JDK 提供了快速创建线程池的方法，但其实不推荐使用 Exeutors 来创建线程池，因为从上面构造线程池的代码可以看出，newFixedThreadPool 线程池由于使用了 LinkedBlockingOueue，队列的容量默认无限大，实际使用中出现任务过多时会导致内存溢出; newCachedThreadPool 线程池由于核心线程数无限大，当任务过多的时候会导致创建大量的线程，可能机器负载过高导致服务宕机。 如何合理的⾃定义线程池线程池大小 关于线程池的大小，并没有一个需要严格遵守的“金规铁律”，按照任务性质，大概可以分为CPU密集型任务、IO密集型任务和混合型任务。 CPU密集型任务：CPU密集型任务应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。 IO密集型任务：IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如2*Ncpu。 混合型任务：混合型任务可以按需拆分成CPU密集型任务和IO密集型任务。 当然，这个只是建议，实际上具体怎么配置，还要结合事前评估和测试、事中监控来确定一个大致的线程线程池大小。线程池大小也可以不用写死，使用动态配置的方式，以便调整。 线程工厂一般建议自定义线程工厂，构建线程的时候设置线程的名称，这样在查日志的时候就方便知道是哪个线程执行的代码。 import java.util.concurrent.ThreadFactory; import java.util.concurrent.atomic.AtomicInteger; /** * @author ehyzil * @Description * @create 2023-12-2023/12/26-19:05 */ public class MyThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; /** * 构造函数传入我们想业务需要的线程名字threadName，方便发生异常是追溯 * @param threadName */ public MyThreadFactory(String threadName) &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); if (threadName == null || threadName.isEmpty())&#123; threadName = \"pool\"; &#125; namePrefix = threadName + poolNumber.getAndIncrement() + \"-thread-\"; &#125; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125; //测试类 import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; /** * @author ehyzil * @Description * @create 2023-12-2023/12/26-19:06 */ public class Test &#123; public static void main(String[] args) &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 5, 5, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;>(100), new MyThreadFactory(\"测试自建线程工厂\")); for (int i = 0; i &lt; 100; i++) &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()); &#125; &#125;); &#125; &#125; &#125; 执行结果 测试自建线程工厂1-thread-1 测试自建线程工厂1-thread-2 测试自建线程工厂1-thread-3 测试自建线程工厂1-thread-2 有界队列一般需要设置有界队列的大小，比如 LinkedBlockingOueue 在构造的时候可以传入参数来限制队列中任务数据的大小，这样就不会因为无限往队列中扔任务导致系统的 oom。","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://blog.ehzyil.xyz/tags/%E5%B9%B6%E5%8F%91/"}],"author":"ehzyil"},{"title":"记录需求中写的递归方法","slug":"2023/记录需求中写的递归方法","date":"2023-12-26T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/12/26/2023/记录需求中写的递归方法/","link":"","permalink":"https://blog.ehzyil.xyz/2023/12/26/2023/%E8%AE%B0%E5%BD%95%E9%9C%80%E6%B1%82%E4%B8%AD%E5%86%99%E7%9A%84%E9%80%92%E5%BD%92%E6%96%B9%E6%B3%95/","excerpt":"","text":"记录需求中写的递归方法递归遍历json数据，将其转换成 List&lt;Map&lt;String, Object&gt;&gt;列表public static List&lt;Map&lt;String, Object>> json2List(com.alibaba.fastjson.JSONArray array) &#123; // 创建一个空的列表 List&lt;Map&lt;String, Object>> list = new ArrayList&lt;>(); // 遍历json数组中的每个对象 for (Object obj : array) &#123; // 将对象转换为JSONObject com.alibaba.fastjson.JSONObject object = (com.alibaba.fastjson.JSONObject) obj; // 创建一个空的HashMap HashMap&lt;String, Object> map = new HashMap&lt;>(); // 获取对象中名为\"children\"的数组 com.alibaba.fastjson.JSONArray children = object.getJSONArray(\"children\"); // 如果\"children\"不为空，则将其转换为列表 if (children != null) &#123; List&lt;Map&lt;String, Object>> childrenList = json2List(children); map.put(\"children\", childrenList); &#125; // 将对象中的\"name\"、\"id\"、\"value\"放入map中 map.put(\"name\", object.getString(\"name\")); map.put(\"id\", object.getString(\"id\")); map.put(\"value\", object.getString(\"value\")); // 将map添加到列表中 list.add(map); &#125; // 返回最终的列表 return list; &#125; 递归调用方法处理传入的列表将复合条件的节点添加指定属性/** * 递归设置节点的打开状态 * @param list 待处理的节点列表 * @param target * @return 设置打开状态后的节点列表 */ public static List&lt;Map&lt;String, Object>> recursiveSetopen(List&lt;Map&lt;String, Object>> list, List&lt;String> target) &#123; for (Map&lt;String, Object> map : list) &#123; List&lt;Map&lt;String, Object>> children = (List&lt;Map&lt;String, Object>>) map.get(\"children\"); if (map.get(\"children\") != null) &#123; // 递归设置子节点的打开状态 recursiveSetOpen(children, target); String open = \"\"; for (Map&lt;String, Object> child : children) &#123; open = MapUtils.getString(child, \"open\"); if (StringUtils.isNotEmpty(open)) &#123; // 如果子节点已经打开，则将父节点设置为打开状态 Map&lt;String, Object> objectMap = list.get(list.indexOf(map)); objectMap.put(\"open\", true); list.set(list.indexOf(map), objectMap); break; &#125; &#125; &#125; else &#123; String name = map.get(\"name\").toString(); if (target.contains(name)) &#123; // 如果节点在目标列表中，则设置为打开状态和选中状态 map.put(\"open\", true); map.put(\"checked\", true); &#125; &#125; &#125; return list; &#125; JSON数据： &#123; \"beans\":[ &#123; \"name\":\"沟通技巧类\", \"value\":\"4\", \"id\":\"4\", \"children\":[ &#123; \"name\":\"沟通过于随意或使用不恰当语言\", \"value\":\"401\", \"id\":\"401\" &#125;, &#123; \"name\":\"语音、语调、语速运用不佳\", \"value\":\"402\", \"id\":\"402\" &#125; ] &#125;, &#123; \"name\":\"业务能力类\", \"value\":\"3\", \"id\":\"3\", \"children\":[ &#123; \"name\":\"业务解释或办理差错\", \"value\":\"309\", \"id\":\"309\" &#125;, &#123; \"name\":\"业务不熟练\", \"value\":\"305\", \"id\":\"305\" &#125;, &#123; \"name\":\"承诺未兑现\", \"value\":\"310\", \"id\":\"310\" &#125;, &#123; \"name\":\"未执行公司内部各类流程规范\", \"value\":\"311\", \"id\":\"311\" &#125; ] &#125;, &#123; \"name\":\"服务能力类\", \"value\":\"2\", \"id\":\"2\", \"children\":[ &#123; \"name\":\"抓不住客户重点\", \"value\":\"201\", \"id\":\"201\" &#125;, &#123; \"name\":\"机械化服务、服务不灵活\", \"value\":\"202\", \"id\":\"202\" &#125; ] &#125;, &#123; \"name\":\"服务意识类\", \"value\":\"1\", \"id\":\"1\", \"children\":[ &#123; \"name\":\"敷衍、搪塞、推诿客户\", \"value\":\"107\", \"id\":\"107\" &#125;, &#123; \"name\":\"反问、质问、指责客户\", \"value\":\"102\", \"id\":\"102\" &#125;, &#123; \"name\":\"抢话、插话\", \"value\":\"103\", \"id\":\"103\" &#125;, &#123; \"name\":\"强制转接或挂机\", \"value\":\"104\", \"id\":\"104\" &#125;, &#123; \"name\":\"出现不文明用语\", \"value\":\"105\", \"id\":\"105\" &#125;, &#123; \"name\":\"故意引导客户升级投诉\", \"value\":\"106\", \"id\":\"106\" &#125; ] &#125;, &#123; \"name\":\"服务禁忌类\", \"value\":\"0\", \"id\":\"0\", \"children\":[ &#123; \"name\":\"辱骂客户\", \"value\":\"001\", \"id\":\"001\" &#125;, &#123; \"name\":\"威胁恐吓客户\", \"value\":\"002\", \"id\":\"002\" &#125;, &#123; \"name\":\"恶意骚扰报复客户\", \"value\":\"007\", \"id\":\"007\" &#125;, &#123; \"name\":\"欺瞒、诱导客户\", \"value\":\"010\", \"id\":\"010\" &#125;, &#123; \"name\":\"与客户发生争吵言语过激攻击客户\", \"value\":\"008\", \"id\":\"008\" &#125;, &#123; \"name\":\"违反五条禁令\", \"value\":\"009\", \"id\":\"009\" &#125; ] &#125;, &#123; \"name\":\"无问题\", \"value\":\"5\", \"id\":\"5\" &#125; ] &#125; 递归寻找满足条件的节点-返回子节点到父节点的链路public static StringBuffer recursiveForAllName(List&lt;Map&lt;String, Object>> list, String target, StringBuffer result) &#123; if (CollectionUtils.isEmpty(list)) &#123; return result.append(target); &#125; for (Map&lt;String, Object> map : list) &#123; List&lt;Map&lt;String, Object>> children = (List&lt;Map&lt;String, Object>>) map.get(\"children\"); if (map.get(\"children\") != null) &#123; // Recursively set the open state of the child nodes recursiveForAllName(children, target, result); if (StringUtils.isNotBlank(result)) &#123; result.insert(0, map.get(\"name\") + \"_\"); break; &#125; else &#123; String name = map.get(\"name\").toString(); if (target.contains(name)) &#123; result.insert(0, name); break; &#125; &#125; &#125; &#125; return result; &#125; 调用方法 public static List&lt;Map&lt;String, Object>> handleExportData(List&lt;Map&lt;String, Object>> checkResults, List&lt;Map&lt;String, Object>> exportNeedModels) throws IOException &#123; // MODELS_NM ----> List&lt;Map&lt;String, Object>> control层获取 // problemTypeNm 问题判定 com.alibaba.fastjson.JSONObject problemTypeObj = getProblemTypeObj(); com.alibaba.fastjson.JSONArray beansArray = problemTypeObj.getJSONArray(\"beans\"); List&lt;Map&lt;String, Object>> beans = json2List(beansArray); for (Map&lt;String, Object> map : checkResults) &#123; String problemTypeNm = map.get(\"problemTypeNm\").toString(); if (StringUtils.isNotEmpty(problemTypeNm)) &#123; StringBuffer stringBuffer = new StringBuffer(); String[] split = problemTypeNm.split(\";\"); for (String singleProblemTypeNm : split) &#123; stringBuffer.append(recursiveForAllName(beans, singleProblemTypeNm, new StringBuffer())).append(\",\"); &#125; map.put(\"problemTypeNm\", stringBuffer.toString()); &#125; String checkComment = map.get(\"MODELS_NM\").toString(); if (StringUtils.isNotEmpty(checkComment)) &#123; StringBuffer stringBuffer = new StringBuffer(); String[] split = checkComment.split(\";\"); for (String singleModel : split) &#123; stringBuffer.append(recursiveForAllName(exportNeedModels, singleModel, new StringBuffer())).append(\";\"); &#125; map.put(\"MODELS_NM\", stringBuffer.toString()); &#125; &#125; return checkResults; &#125;","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"}],"author":"ehzyil"},{"title":"CentOS7同步时间","slug":"2023/CentOS 7同步时间","date":"2023-11-11T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/11/11/2023/CentOS 7同步时间/","link":"","permalink":"https://blog.ehzyil.xyz/2023/11/11/2023/CentOS%207%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4/","excerpt":"","text":"问题描述The difference between the request time and the current time is too large。 由于minio部署在centos的docker容器中，虚拟机挂起再启动后时间不会同步，造成上述问题。 解决方法是同步虚拟机的时间。 设置时区（CentOS 7）先执行命令timedatectl status|grep &#39;Time zone&#39;查看当前时区，如果不是中国时区（Asia&#x2F;Shanghai），则需要先设置为中国时区，否则时区不同会存在时差。 #已经是Asia/Shanghai，则无需设置 [root@xiaoz shadowsocks]# timedatectl status|grep 'Time zone' Time zone: Asia/Shanghai (CST, +0800) 执行下面的命令设置时区 #设置硬件时钟调整为与本地时钟一致 timedatectl set-local-rtc 1 #设置时区为上海 timedatectl set-timezone Asia/Shanghai 使用ntpdate同步时间目前比较常用的做法就是使用ntpdate命令来同步时间，使用方法如下： #安装ntpdate yum -y install ntpdate #同步时间 ntpdate -u pool.ntp.org #同步完成后,date命令查看时间是否正确 date","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.ehzyil.xyz/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://blog.ehzyil.xyz/tags/CentOS/"}],"author":"ehzyil"},{"title":"在服务器上搭建Alist文件列表程序","slug":"2023/在服务器上搭建Alist文件列表程序","date":"2023-10-22T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/10/22/2023/在服务器上搭建Alist文件列表程序/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/22/2023/%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%90%AD%E5%BB%BAAlist%E6%96%87%E4%BB%B6%E5%88%97%E8%A1%A8%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"在我们使用网盘的时候，有时候需要搭建一个分享页。但是默认的网盘分享页有些麻烦。在这篇教程中，我们来和大家一起在服务器上使用shell脚本一键搭建Alist文件列表程序 准备材料 服务器一台 部署步骤 SSH进入服务器的控制台，执行以下命令 curl -fsSL &quot;https:&#x2F;&#x2F;alist.nn.ci&#x2F;v3.sh&quot; | bash -s install 2.脚本将会提示访问IP地址、管理员用户名及密码 3.配置服务器安全组的规则 4.如需要更新Alist，则使用以下命令 SHELL 复制成功curl -fsSL &quot;https:&#x2F;&#x2F;alist.nn.ci&#x2F;v3.sh&quot; | bash -s update 5.如需要卸载Alist，则使用以下命令 SHELL curl -fsSL &quot;https:&#x2F;&#x2F;alist.nn.ci&#x2F;v3.sh&quot; | bash -s update 配置Alisthttps://alist.nn.ci/zh/guide/drivers/aliyundrive.html","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"网盘","slug":"网盘","permalink":"https://blog.ehzyil.xyz/tags/%E7%BD%91%E7%9B%98/"}],"author":"ehzyil"},{"title":"小白初遇服务器","slug":"2023/小白初遇服务器","date":"2023-10-22T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/10/22/2023/小白初遇服务器/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/22/2023/%E5%B0%8F%E7%99%BD%E5%88%9D%E9%81%87%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"前言白飘了阿里云服务器，创建实例后一脸懵逼，完全不知道在哪查看密码、选择的宝塔镜像怎么使用、在哪里打开等等，于是就有了本文，用来记录一些配置过程，方便下次创建服务器的时候直接copy配置，现在就开始玩一玩服务器吧，折腾起来！ 0.更新、安装必备软件yum update &amp;&amp; yum install -y wget vim #centos apt-get update &amp;&amp; apt-get install -y wget vim #dibian 1.安装宝塔面板流程本文是以阿里云服务器ECS为例，CentOS操作系统，手动安装宝塔Linux面板，大致流程为：先远程连接到云服务器，执行宝塔面板安装命令，安装完毕后保存好宝塔登录地址、用户名和密码等信息，然后在云服务器安全组开通宝塔面板端口号，最后登录到宝塔面板安装所需的运行环境。操作流程如下： 1、先创建云服务器ECS，云服务器配置选择； 2、远程连接到云服务器； 3、执行宝塔面板安装命令脚本； 4、保存宝塔面板登录地址、账号和密码； 5、在云服务器的安全组中开通宝塔面板所需端口号； 6、登录宝塔面板后台，并安装应用程序环境。 步骤一：阿里云服务器配置选择步骤二：远程连接登录到云服务器阿里云服务器支持多种远程连接方式，可以使用阿里云自带的Workbench远程连接方式，也可以使用第三方SSH远程连接软件如PuTTY、Xshell等。阿里云服务器网使用阿里云自带的远程连接方式： 首先登录到云服务器ECS管理控制台，左侧栏【实例与镜像】&gt;&gt;【实例】，找到目标云服务器ECS实例，然后点击右侧的【远程连接】。 步骤三：执行宝塔面板的安装命令登录到你的云服务器后，执行宝塔面板安装命令，阿里云服务器网使用的CentOS操作系统，命令如下： yum install -y wget &amp;&amp; wget -O install.sh https:&#x2F;&#x2F;download.bt.cn&#x2F;install&#x2F;install_6.0.sh &amp;&amp; sh install.sh ed8484bec 执行宝塔Linux面板安装命令后，会提示如下： Do you want to install Bt-Panel to the &#x2F;www directory now?(y&#x2F;n): y 保持默认，回复个字母“y”。 然后回车，系统会自动安装，大约1分钟左右会自动安装完成。 步骤四：宝塔面板登录地址、账号和密码宝塔面板自动安装完成后，会显示宝塔后台登录地址、username和password，如下： &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; BT-Panel default info! # 注意: 5.x系列Linux面板从2020年1月1日起终止维护，与技术支持，请考虑安装全新的7.x版本 宝塔官网: https:&#x2F;&#x2F;www.bt.cn &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; Bt-Panel: http:&#x2F;&#x2F;IP:8888 username: 08bnpksl password: 89b58de05321 Warning: If you cannot access the panel, release the following port (8888|888|80|443|20|21) in the security group [root@iZ2ze552628d2crm1m97ppZ ~]# bt default cd &#x2F;www&#x2F;server&#x2F;panel &amp;&amp; btpython tools.py panel testpasswd a 步骤五：在阿里云服务器控制台开通宝塔面板端口1、登录到ECS云服务器管理控制台 2、左侧栏找到【实例与镜像】&gt;&gt;【实例】，找到目标ECS实例，点击实例ID进入到实例详情页 3、切换到【安全组】页面，点击右侧【配置规则】，如下图： 关于阿里云安全组开通端口详细教程参考下方文档： 详细教程参考：https://help.aliyun.com/document_detail&#x2F;25471.html 配置成如下： 步骤六：登录到宝塔管理地址并安装LNMP环境登录后会自动弹出此界面，按需求选择软件并安装，也可以到软件管理去安装。 2.安装 Docker、Docker-compose国内机国内机安装 dockercurl -sSL https://get.daocloud.io/docker | sh 国内机安装 docker-composecurl -L https://get.daocloud.io/docker/compose/releases/download/v2.1.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose 卸载 dockersudo apt-get remove docker docker-engine rm -fr /var/lib/docker/ 海外服务器非大陆 Docker 安装BASHwget -qO- get.docker.com | bash 卸载 Dockersudo apt-get purge docker-ce docker-ce-cli containerd.io sudo rm -rf &#x2F;var&#x2F;lib&#x2F;docker sudo rm -rf &#x2F;var&#x2F;lib&#x2F;containerd 非大陆 Docker-compose 安装sudo curl -L &quot;https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;compose&#x2F;releases&#x2F;download&#x2F;1.29.2&#x2F;docker-compose-$(uname -s)-$(uname -m)&quot; -o &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose sudo chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose 查看版本 先进入 docker-compose --version # /usr/local/bin/ 修改 Docker 配置（来自烧饼博客）以下配置会增加一段自定义内网 IPv6 地址，开启容器的 IPv6 功能，以及限制日志文件大小，防止 Docker 日志塞满硬盘（泪的教训）： cat &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json &lt;&lt;EOF &#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;20m&quot;, &quot;max-file&quot;: &quot;3&quot; &#125;, &quot;ipv6&quot;: true, &quot;fixed-cidr-v6&quot;: &quot;fd00:dead:beef:c0::&#x2F;80&quot;, &quot;experimental&quot;:true, &quot;ip6tables&quot;:true &#125; EOF 然后重启 Docker 服务： systemctl restart docker 文件管理强烈建议专门给 Docker 的数据、配置文件新建一个文件夹， mkdir -p data&#x2F;docker_data 常用指令： 查看 Docker 安装版本等信息 docker version 启动 Docker 服务 systemctl start docker 查看 Docker 运行状态 systemctl status docker 将 Docker 服务加入开机自启动 systemctl enable docker Docker 项目卸载（包括卸载 Docker、docker-compose）docker 命令搭建的常用卸载方法docker ps docker stop 容器名字 cd ~ docker rm -f 容器名字 rm -rf 映射出来的路径 docker-compose 搭建的卸载方法cd &#x2F;root&#x2F;data&#x2F;docker_data&#x2F;xxx docker-compose down cd ~ rm -rf &#x2F;root&#x2F;data&#x2F;docker_data&#x2F;xxx # rm -rf 映射出来的路径 卸载 docker 本身yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce sudo rm -rf &#x2F;var&#x2F;lib&#x2F;docker sudo rm -rf &#x2F;var&#x2F;lib&#x2F;containerd 卸载 docker-composecd &#x2F;usr&#x2F;local&#x2F;bin&#x2F; rm -rf docker-compose 3.防火墙CentOS 关闭防火墙systemctl start supervisord systemctl disable firewalld systemctl stop firewalld 4.安装宝塔国际版 aapanel宝塔总是登录不上去于是就换成了dibian系统，从新开始 Debian : wget -O install.sh http:&#x2F;&#x2F;www.aapanel.com&#x2F;script&#x2F;install-ubuntu_6.0_en.sh &amp;&amp; bash install.sh forum aaPanel Internet Address: http://47.93.26.115:7800/7417c54faaPanel Internal Address: http://172.25.138.127:7800/7417c54 附上相关教程：宝塔面板 7.8 无缝转为宝塔国际版 aapanel，附宝塔 7.8 降级为宝塔 7.7 5.安装alist 普通版 docker run -d --restart&#x3D;always -v &#x2F;root&#x2F;data&#x2F;docker_data&#x2F;alist:&#x2F;opt&#x2F;alist&#x2F;data -p 5244:5244 --name&#x3D;&quot;alist&quot; xhofe&#x2F;alist:latest 预装了aria2版 docker run -d --restart=always -v /root/data/docker_data/alist:/opt/alist/data -p 5244:5244 -e PUID=0 -e PGID=0 -e UMASK=022 --name=\"alist\" xhofe/alist-aria2:latest 查看密码 docker logs alist 2f6e1555-20e5-492d-9e26-5e4ce90a0a45.id.repl.co 5.安装MySql1.拉取镜像 sudo docker pull mysql:8.0.23 2.安装 sudo docker run -p 3306:3306 --name mysql8 \\ --restart unless-stopped \\ -v /root/data/docker_data/mysql/mysql-files:/var/lib/mysql-files \\ -v /root/data/docker_data/mysql/conf:/etc/mysql \\ -v /root/data/docker_data/mysql/logs:/var/log/mysql \\ -v /root/data/docker_data/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=666666 \\ -d mysql:8.0.23 3.进入容器内部修改root允许远程登录。 进入容器内部 docker exec -it mysql8 bash 登录mysql，并一次执行下列命令，允许远程访问 mysql -uroot -p use mysql; alter user 'root'@'%' identified with mysql_native_password by 'xxxx' flush privileges; select host,user,plugin,authentication_string from mysql.user 6.安装redis1.一般需要的配置文件 bind 127.0.0.1 #限制redis只能本地访问，若需要其他ip地址访问需要注释 protected-mode yes #是否开启保护模式，默认值为yes，开启后限制为本地访问，修改为no daemonize no #默认no，修改为yes会使docker使用配置文件方式启动redis失败，yes：以守护进程方式启动，可后台运行，除非kill进程 requirepass 666666 #redis密码 appendonly yes #默认yes，开启AOF模式持久化 databases 16 #数据库个数 dir ./ #redis数据库存放文件夹 创建将配置文件改为redis.conf #bind 127.0.0.1 protected-mode no daemonize no requirepass 666666 appendonly no databases 16 dir ./ 2.拉取镜像 docker pull redis 3.以配置文件启动 docker run -p 6379:6379 --name redis -v /root/data/docker_data/redis/redis.conf:/etc/redis/redis.conf -v /root/data/docker_data/redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes 4.一些命令 docker exec -it redis bash #进入容器内部 docker exec -ti redis redis-cli #执行容器内的redis auth xxx #登录 7.安装memosdocker run -d --name memos -p 5230:5230 -v &#x2F;home&#x2F;ehzyil&#x2F;data&#x2F;docker_data&#x2F;memos&#x2F;:&#x2F;var&#x2F;opt&#x2F;memos ghcr.io&#x2F;usememos&#x2F;memos:latest 8.安装 新建docker-compose.yml文件 vi docker-compose.yml version: &quot;3&quot; services: app: image: &#39;jc21&#x2F;nginx-proxy-manager:latest&#39; restart: unless-stopped ports: - &#39;80:80&#39; - &#39;443:443&#39; - &#39;81:81&#39; volumes: - &#x2F;home&#x2F;ehzyil&#x2F;data&#x2F;docker_data&#x2F;ng&#x2F;data:&#x2F;data - &#x2F;home&#x2F;ehzyil&#x2F;data&#x2F;docker_data&#x2F;ng&#x2F;letsencrypt:&#x2F;etc&#x2F;letsencrypt 启动容器 docker-compose up -d 在确保云服务器防火墙已经放行80、81和443端口后即可访问服务器ip:81 进入ngingx_proxy_manager的web管理界面。默认密码为： Email: admin@example.com Password: changeme","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.ehzyil.xyz/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"author":"ehzyil"},{"title":"自建rss聚合阅读工具","slug":"2023/自建rss聚合阅读工具","date":"2023-10-22T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/10/22/2023/自建rss聚合阅读工具/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/22/2023/%E8%87%AA%E5%BB%BArss%E8%81%9A%E5%90%88%E9%98%85%E8%AF%BB%E5%B7%A5%E5%85%B7/","excerpt":"自建rss聚合阅读工具，极其轻量化配合Render⚡️一键部署，还能绑定自定义域名","text":"自建rss聚合阅读工具，极其轻量化配合Render⚡️一键部署，还能绑定自定义域名 前置准备1.一个Render账号Render是一款可以白嫖的Paas提供商，不需要绑卡什么的，可以白嫖😄😄😄。 2.一个GitHub账号 GitHub是一个可以保存自己代码的地方，代码托管。 3.一个托管了域名的CloudFlare 账号(可选) CloudFlare 是一家全球知名的CDN服务商，并且提供了免费的 CDN 套餐，还不限流量，所以我们完全不需要花一分钱就能使用它的 CDN 服务。 开始搭建Fork源代码到自己的仓库项目名字：rss-reader https://github.com/srcrs/rss-reader 进入上方链接进入该源码的Github仓库 Fork到自己仓库。 因为当前的代码配置完全是原作者的，我们可以配置成自己喜欢的rss。具体如何修改README.md中都有教程自己配置。 修改方式有两种，可以自己把代码拉到本地修改完再commit或者直接在自己的代码库修改。 使用Render进行一键部署进入Render的Dashboard点击New，如下图所示 点击Web Service 绑定自己的Github后操作如下： 找到你要部署的分支： 填写部署的项目名称和部署方式，Docker 选择实例类型，方然是Free白嫖了 点击最下方的Create Web Service等待部署完成即可. 部署完成后可以点击蓝色连接即可访问。 至此该项目搭建完成。 自定义域名（可选）Render免费提供部署好的项目的域名🌹，看着太长不好记或者不喜欢可以更改成自己的域名。 进入Render进行以下操作 然后登录CloudFlare去你所要绑定域名的界面进行以下操作，红色框里的内容由上图复制。 红色框里的Type改成CNAME（懒得编辑图片了） 然后回到Render，点击Verify 显示如下，域名就绑定成功了 现在就可以从自己配置的域名访问了。","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"rss","slug":"rss","permalink":"https://blog.ehzyil.xyz/tags/rss/"},{"name":"render","slug":"render","permalink":"https://blog.ehzyil.xyz/tags/render/"}],"author":"ehzyil"},{"title":"通过 BotFather 创建 Telegram 机器人","slug":"2023/通过 BotFather 创建 Telegram 机器人","date":"2023-10-22T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/10/22/2023/通过 BotFather 创建 Telegram 机器人/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/22/2023/%E9%80%9A%E8%BF%87%20BotFather%20%E5%88%9B%E5%BB%BA%20Telegram%20%E6%9C%BA%E5%99%A8%E4%BA%BA/","excerpt":"","text":"在我们使用 Telegram 的时候，有时候我们需要自己创建一个机器人。这时候我们就得从 @BotFather 处进行申请。在这个教程中，我来和大家一起通过 BotFather 在 Telegram 上创建一个属于自己的机器人。 准备材料 Telegram 账户 创建步骤 打开 Telegram，搜索 BotFather （一定要找到有官方认证的 Bot） 输入 /newbot 命令，然后输入机器人名称、用户名（一定要以 bot 或 _bot 结尾） 然后你会得到一个 Bot Token，这样一个 Telegram Bot 就创建成功了","categories":[{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Telegram","slug":"Telegram","permalink":"https://blog.ehzyil.xyz/tags/Telegram/"}],"author":"ehzyil"},{"title":"JVM学习笔记","slug":"2023/JVM学习笔记","date":"2023-10-19T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/10/19/2023/JVM学习笔记/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/19/2023/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"初始JVM什么是JVMJVM 全称是 Java Virtual Machine，中文译名 Java虚拟机。 JVM 本质上是一个运行在计算机上的程序，他的职责是运行Java字节码文件。 JVM 的功能解释和运行 对字节码文件中的指令实时的解释成机器码让计算机执行 内存管理 自动为对象、方法等分配内存 自动的垃圾回收机制，回收不再使用的对象 即时编译 ——主要是为了支持跨平台特性。 对热点代码进行优化提升执行效率 JVM提供了即时编译（Just-In-Time 简称JIT) 进行性能的优化，最终能达到接近C、C++语言的运行性能 甚至在特定场景下实现超越。 常见的JVM常见的JVM有HotSpot、GraalVM、OpenJ9等，另外DragonWell龙井JDK也 提供了一款功能增强版的JVM。其中使用最广泛的是HotSpot虚拟机。 常见的JVM: Java虚拟机规范 《Java虚拟机规范》由Oracle制定，内容主要包含了Java虚拟机在设计和实现时需要遵守的规范，主 要包含class字节码文件的定义、类和接口的加载和初始化、指令集等内容。 《Java虚拟机规范》是对虚拟机设计的要求，而不是对Java设计的要求，也就是说虚拟机可以运行在 其他的语言比如Groovy、Scala生成的class字节码文件之上。 官网地址：https://docs.oracle.com/javase/specs/index.htm 详解字节码文件Java内存区域垃圾回收","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://blog.ehzyil.xyz/tags/JVM/"}],"author":"ehzyil"},{"title":"LeetCode刷题笔记","slug":"数据结构与算法/LeetCode刷题笔记","date":"2023-10-19T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/10/19/数据结构与算法/LeetCode刷题笔记/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/LeetCode%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1、两数之和给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 你可以按任意顺序返回答案。 示例 1： 输入：nums &#x3D; [2,7,11,15], target &#x3D; 9 输出：[0,1] 解释：因为 nums[0] + nums[1] &#x3D;&#x3D; 9 ，返回 [0, 1] 。 示例 2： 输入：nums &#x3D; [3,2,4], target &#x3D; 6 输出：[1,2] 示例 3： 输入：nums &#x3D; [3,3], target &#x3D; 6 输出：[0,1] 提示： 2 &lt;= nums.length &lt;= 104 -109 &lt;= nums[i] &lt;= 109 -109 &lt;= target &lt;= 109 只会存在一个有效答案 解法一 ​ 双重for循环遍历获取两个元素判断两个元素相加是否满足目标值，返回索引值。 class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; // 创建一个长度为2的整型数组，用于存储结果 int[] arr = new int[2]; // 遍历给定的nums数组 for (int i = 0; i &lt; nums.length; i++) &#123; // 内层循环遍历索引范围为0到i之间的元素 for (int j = 0; j &lt; i; j++) &#123; // 如果当前元素nums[i]和nums[j]的和等于目标值target if (nums[i] + nums[j] == target) &#123; // 将当前的i和j作为结果存入数组arr中 arr[0] = i; arr[1] = j; &#125; &#125; &#125; return arr; &#125; &#125; 时间复杂度为O($n^{2}$) 解法二 循环遍历数组元素，计算出target减去arr[i]的值另一个数的值将其存入map，每次循环判断map中是否有可以满足条件的值，若有就返回，否则继续循环。 如何构建map？ map常用于存储键值对，就本题而言，我们可以把数组元素的值当做键，索引当做值。 class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; //map用与存储值-索引 若target-nums[i]的值(map的键在存在说明错在另一个值可以凑成target) // 这样只需要一个for循环 HashMap&lt;Integer, Integer> map = new HashMap&lt;Integer, Integer>(); int[] arr = new int[2]; for (int i = 0; i &lt; nums.length; i++) &#123; // 判断HashMap中是否存在键为target - nums[i]的元素 if (map.containsKey(target - nums[i])) &#123; // 如果存在，则将当前索引i和HashMap中对应的值作为结果存入数组arr中 arr[0] = i; arr[1] = map.get(target - nums[i]); // 跳出循环，结束查找 break; &#125; // 将当前元素nums[i]作为键，将当前索引i作为值，存入HashMap中 map.put(nums[i], i); &#125; return arr; &#125; &#125; 解法三 ​ 现将数组排序,使用二分法思想寻找两边界指向元素值的和于target比较，通过不断缩小边界来寻找目标值， class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Arrays.sort(nums); int left = 0, right = nums.length - 1; int[] arr = new int[2]; while (left &lt; right) &#123; int sum = nums[left] + nums[right]; if (sum &lt; target) &#123; left++; &#125; else if (sum > target) &#123; right--; &#125; else if (sum == target) &#123; arr[0] = left; arr[1] = right; return arr; &#125; &#125; return new int[]&#123;&#125;; &#125; &#125; 2、两数相加给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。 请你将两个数相加，并以相同形式返回一个表示和的链表。 你可以假设除了数字 0 之外，这两个数都不会以 0 开头。 示例 1： 输入：l1 &#x3D; [2,4,3], l2 &#x3D; [5,6,4] 输出：[7,0,8] 解释：342 + 465 &#x3D; 807. 示例 2： 输入：l1 &#x3D; [0], l2 &#x3D; [0] 输出：[0] 示例 3： 输入：l1 &#x3D; [9,9,9,9,9,9,9], l2 &#x3D; [9,9,9,9] 输出：[8,9,9,9,0,0,0,1] 提示： 每个链表中的节点数在范围 [1, 100] 内 0 &lt;= Node.val &lt;= 9 题目数据保证列表表示的数字不含前导零 解法一 class Solution &#123; public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123; ListNode p1 = l1, p2 = l2; //创建一个头结点来作为头节点 可以避免处理初始的空指针情况 ListNode dummy = new ListNode(-1); //p作为指针移动 用来添加元素 ListNode p = dummy; //存放进位的数 int carry = 0; //当有链表不为空或者有进位的数位加入链表 while (p1 != null || p2 != null || carry > 0) &#123; int sum = carry; //加上p1的值并让p1指针后移 if (p1 != null) &#123; sum += p1.val; p1 = p1.next; &#125; //加上p2的值并让p1指针后移 if (p2 != null) &#123; sum += p2.val; p2 = p2.next; &#125; //模10 得到进位的数 carry = sum / 10; //除10 得到余数 sum = sum % 10; //将余数加入链表 链表指针后移 p.next = new ListNode(sum); p = p.next; &#125; return dummy.next; &#125; &#125; 3、无重复字符的最长子串给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。 示例 1: 输入: s &#x3D; &quot;abcabcbb&quot; 输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。 示例 2: 输入: s &#x3D; &quot;bbbbb&quot; 输出: 1 解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。 示例 3: 输入: s &#x3D; &quot;pwwkew&quot; 输出: 3 解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。 提示： 0 &lt;= s.length &lt;= 5 * 104 s 由英文字母、数字、符号和空格组成 解法一 public static int lengthOfLongestSubstring(String s) &#123; int res = 0; // 用于存储最大长度 for (int i = 0; i &lt; s.length(); i++) &#123; // 外层循环，遍历字符串的每个字符 boolean[] book = new boolean[300]; // 用于记录字符是否出现过的数组 for (int j = i; j > 0; j--) &#123; // 内层循环，从当前字符开始向前遍历 if (book[s.charAt(j)]) &#123; // 如果当前字符已经出现过，说明已经找到以当前字符为结尾的最长子串 break; // 结束内层循环 &#125; book[s.charAt(j)] = true; // 将当前字符标记为已出现 res = Math.max(res, i - j + 1); &#125; &#125; return res; // 返回最大长度 &#125; 内层for循环递减的原因: 为了找到以当前字符为结尾的最长子串。如果内层for循环递增，那么每次循环都是从字符串的开头开始，这样就无法找到以当前字符为结尾的最长子串。而递减的话，每次循环都是从当前字符开始，逐渐向前遍历，可以找到以当前字符为结尾的最长子串。 下列代码的意思是获取字符串j索引位置的值，因为是char类型当将其放入数组是会转换层int型比如 a(char)-&gt;99(int) book[s.charAt(j)] &#x3D; true; 解法二 我们知道，题目要我们求解的是一个区间，我们可以考虑设置两个指针，一个指向这个区间的开头，另外一个则指向这个区间的结尾。我们让头指针不动，向后扩展尾指针，直到遇见重复元素 (见下图) public static int lengthOfLongestSubstring(String s) &#123; int res = 0; // 用于存储最大长度 Map&lt;Character, Integer> window = new HashMap&lt;>(); //i是左指针，j是右指针 for (int i = 0, j = 0; j &lt; s.length(); j++) &#123; //若s.charAt(j)已在window中则移动i的值到第一次出现位置的右侧 if (window.containsKey(s.charAt(j))) &#123; i = Math.max(i, window.get(s.charAt(j)) + 1); &#125; res = Math.max(res, j - i + 1); window.put(s.charAt(j), j); &#125; return res; // 返回最大长度 &#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.ehzyil.xyz/tags/Leetcode/"}],"author":"ehzyil"},{"title":"CentOS下的软件","slug":"2023/CentOS下的软件","date":"2023-10-17T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/10/17/2023/CentOS下的软件/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/17/2023/CentOS%E4%B8%8B%E7%9A%84%E8%BD%AF%E4%BB%B6/","excerpt":"","text":"CentOS下MySQLMySQL8.0.27 安装[root@localhost ~]# uname -m x86_64 [root@localhost ~]# cat &#x2F;etc&#x2F;redhat-release CentOS Linux release 7.9.2009 (Core) #解压 tar -zxvf mysql-8.0.27-1.el7.x86_64.rpm-bundle.tar tar -xvf mysql-8.0.27-1.el7.x86_64.rpm-bundle.tar\\ #安装顺序 rpm -ivh mysql-community-common-8.0.27-1.el7.x86_64.rpm rpm -ivh mysql-community-client-plugins-8.0.27-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-8.0.27-1.el7.x86_64.rpm yum install openssl-devel -y rpm -ivh mysql-community-devel-8.0.27-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-compat-8.0.27-1.el7.x86_64.rpm rpm -ivh mysql-community-client-8.0.27-1.el7.x86_64.rpm yum install net-tools yum install -y perl-Module-Install.noarch rpm -ivh mysql-community-server-8.0.27-1.el7.x86_64.rpm MySQL8.0主从复制的配置&#x2F;&#x2F;主机 CREATE USER &#39;ehzyil&#39;@&#39;%&#39; IDENTIFIED BY &#39;Li021712.&#39;; GRANT REPLICATION SLAVE ON *.* TO &#39;ehzyil&#39;@&#39;%&#39;; &#x2F;&#x2F;从机 CHANGE REPLICATION SOURCE TO SOURCE_HOST&#x3D;&#39;192.168.154.141&#39;,SOURCE_PORT&#x3D;3306,SOURCE_USER&#x3D;&#39;ehzyil&#39;,SOURCE_PASSWORD&#x3D;&#39;Li021712.&#39;,SOURCE_LOG_FILE&#x3D;&#39;mysql-bin.000004&#39;,SOURCE_LOG_POS&#x3D;685; start slave; ​ 若查询slave状态，出现以下情况 mysql&gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Connecting to source Master_Host: 192.168.154.141 Master_User: ehzyil Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 685 Relay_Log_File: localhost-relay-bin.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: mysql-bin.000004 Slave_IO_Running: Connecting Slave_SQL_Running: Yes ... Last_IO_Errno: 2061 Last_IO_Error: error connecting to master &#39;ehzyil@192.168.154.141:3306&#39; - retry-time: 60 retries: 1 message: Authentication plugin &#39;caching_sha2_password&#39; reported error: Authentication requires secure connection. ... 分析报错，应该是连接的用户配置有问题。 所以去主库mysql上查询当前用户信息 SELECT plugin FROM user where user &#x3D; ‘ehzyil’; 原来是主库repluser的plugin是caching_sha2_password 导致连接不上，修改为mysql_native_password即可解决。 ALTER USER ‘ehzyil‘@’%’ IDENTIFIED WITH mysql_native_password BY ‘Li021712.’; mysql&gt; use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql&gt; SELECT plugin FROM &#96;user&#96; where user &#x3D; &#39;ehzyil&#39;; +-----------------------+ | plugin | +-----------------------+ | caching_sha2_password | +-----------------------+ 1 row in set (0.00 sec) mysql&gt; ALTER USER &#39;ehzyil&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;Li021712.&#39;; Query OK, 0 rows affected (0.00 sec) 修改后，重新配置从库binlog位置后重启状态展示如下： Slave_IO_State: Waiting for source to send event Slave_IO_Running: Yes Slave_SQL_Running: Yes 看到以上三行配置相同，则主从连接成功。 MySQL清除主从复制关系mysql主从复制中，需要将主从复制关系清除，需要取消其从库角色。这可通过执行RESET SLAVE ALL清除从库的同步复制信息、包括连接信息和二进制文件名、位置。从库上执行这个命令后，使用show slave status将不会有输出。reset slave是各版本Mysql都有的功能，在stop slave之后使用。主要做：删除master.info和relay-log.info文件；删除所有的relay log（包括还没有应用完的日志），创建一个新的relay log文件；从Mysql 5.5开始，多了一个all参数。如果不加all参数，那么所有的连接信息仍然保留在内存中，包括主库地址、端口、用户、密码等。这样可以直接运行start slave命令而不必重新输入change master to命令，而运行show slave status也仍和没有运行reset slave一样，有正常的输出。但如果加了all参数，那么这些内存中的数据也会被清除掉，运行show slave status就输出为空了。 mysql&gt; stop slave; Query OK, 0 rows affected, 2 warnings (0.00 sec) mysql&gt; reset slave all; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql&gt; show slave status\\G Empty set, 1 warning (0.00 sec) nginxCentOS下Nginx的安装安装 nginx 编译需要依赖 gcc 环境: yum install gcc-c++ 安装两个安装包pcre和pcre-devel： yum install -y pcre pcre-devel 安装zlib，Nginx的各种模块中需要使用gzip压缩： yum install -y zlib zlib-devel 如果使用了 https，需要安装 OpenSSL 库。安装指令如下： yum install -y openssl openssl-devel 一键安装上面四个依赖（追求安装速度可直接用这条指令） yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel 进入usr&#x2F;local 文件路径(路径可自选)创建一个文件夹nginx保存使用wget下载的nginx压缩包 &#x2F;&#x2F;下载nginx压缩包 wget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.24.0.tar.gz tar -zxvf nginx-1.24.0.tar.gz -C &#x2F;usr&#x2F;local&#x2F; cd &#x2F;usr&#x2F;local&#x2F;nginx-1.24.0&#x2F; &#x2F;&#x2F;创建一个文件夹 mkdir &#x2F;usr&#x2F;local&#x2F;nginx &#x2F;&#x2F;安装前检查工作 .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx &#x2F;&#x2F;安装 make &amp;&amp; make install &#x2F;&#x2F;文件目录树状图 nginx ├── conf &lt;-- Nginx配置文件 │ ├── fastcgi.conf │ ├── fastcgi.conf.default │ ├── fastcgi_params │ ├── fastcgi_params.default │ ├── koi-utf │ ├── koi-win │ ├── mime.types │ ├── mime.types.default │ ├── nginx.conf &lt;-- 这个文件我们经常操作 │ ├── nginx.conf.default │ ├── scgi_params │ ├── scgi_params.default │ ├── uwsgi_params │ ├── uwsgi_params.default │ └── win-utf ├── html &lt;-- 存放静态文件，我们后期部署项目，就要将静态文件放在这 │ ├── 50x.html │ └── index.html &lt;-- 提供的默认的页面 ├── logs └── sbin └── nginx &lt;-- 启动文件 配置环境变量 使用vim /etc/profile命令打开配置文件，并配置环境变量，保存并退出 之后重新加载配置文件，使用source /etc/profile命令，然后我们在任意位置输入nginx即可启动服务，nginx -s stop即可停止服务 Nginx常用命令 启动Nginx： nginx 启动Nginx服务器。 停止Nginx： nginx -s stop 停止正在运行的Nginx服务器。 重新加载Nginx配置： nginx -s reload 重新加载Nginx的配置文件，使新的配置生效，而无需停止服务器。 检查Nginx配置是否正确： nginx -t 检查Nginx的配置文件语法是否正确，如果有错误，它会显示错误信息。 查看Nginx版本：nginx -v 或 nginx -V 第一个命令会显示Nginx的版本号，第二个命令会显示编译时的详细配置信息。 查看Nginx进程状态： nginx -s status 显示Nginx进程的状态，包括正在运行的进程数量和其它相关信息。 重新打开日志文件： nginx -s reopen 重新打开Nginx的日志文件，可以用于实现日志文件的切割和归档。 CentOS 7CentOS 7上防火墙设置在CentOS 7上设置防火墙可以使用firewalld服务进行管理。 以下是在CentOS 7上设置防火墙的一些常用操作： 检查防火墙状态： sudo firewall-cmd --state 这将显示防火墙的当前状态，如果防火墙已启用，它会显示”running”。 查看防火墙规则： sudo firewall-cmd --list-all 这将显示防火墙的当前规则列表。 启动防火墙服务： sudo systemctl start firewalld 停止防火墙服务： sudo systemctl stop firewalld 设置防火墙开机启动： sudo systemctl enable firewalld 停用防火墙开机启动： sudo systemctl disable firewalld 开放端口： sudo firewall-cmd --zone&#x3D;public --add-port&#x3D;&lt;port&gt;&#x2F;tcp --permanent 将&lt;port&gt;替换为要开放的端口号。此命令会永久性地在防火墙中开放指定的端口。 移除已开放的端口： sudo firewall-cmd --zone&#x3D;public --remove-port&#x3D;&lt;port&gt;&#x2F;tcp --permanent 将&lt;port&gt;替换为要移除的端口号。此命令会永久性地从防火墙中移除指定的端口。 重新加载防火墙配置： sudo firewall-cmd --reload 在修改防火墙规则后，使用此命令重新加载配置，使更改生效。 10.验证规则是否生效： sudo firewall-cmd --zone&#x3D;public --list-all 检查规则列表以确认添加或删除的规则已正确应用。 查看yum已安装的包在linux下如何使用yum查看安装了哪些软件包 列出所有已安装的软件包yum list installed yum针对软件包操作常用命令： 1.使用 yum 查找软件包命令：yum search 2.列出所有可安装的软件包命令： yum list 3.列出所有可更新的软件包命令： yum list updates 4.列出所有已安装的软件包命令： yum list installed yum 语法yum [options] [command] [package ...] options 可选，选项包括 -h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。 command 要进行的操作。 package 操作的对象。 其它的例子就不列举了，这里说一下查看yum安装了哪些软件包 查看 yum 已安装 docker 的包 yum list installed docker 查看 yum 已安装 docker相关的包 yum list installed docker* [root@iZ2ze552628d2crm1m97ppZ ~]# yum list installed docker* 已加载插件：fastestmirror Loading mirror speeds from cached hostfile 已安装的软件包 docker-buildx-plugin.x86_64 0.11.2-1.el7 @docker-ce-stable docker-ce.x86_64 3:24.0.6-1.el7 @docker-ce-stable docker-ce-cli.x86_64 1:24.0.6-1.el7 @docker-ce-stable docker-ce-rootless-extras.x86_64 24.0.6-1.el7 @docker-ce-stable docker-compose-plugin.x86_64 2.21.0-1.el7 @docker-ce-stable [root@iZ2ze552628d2crm1m97ppZ ~]#","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.ehzyil.xyz/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://blog.ehzyil.xyz/tags/CentOS/"},{"name":"软件","slug":"软件","permalink":"https://blog.ehzyil.xyz/tags/%E8%BD%AF%E4%BB%B6/"}],"author":"ehzyil"},{"title":"SpringBoot项目中集成第三方登录功能","slug":"2023/SpringBoot项目中集成第三方登录功能","date":"2023-10-17T00:00:00.000Z","updated":"2024-01-06T04:54:46.199Z","comments":true,"path":"2023/10/17/2023/SpringBoot项目中集成第三方登录功能/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/17/2023/SpringBoot%E9%A1%B9%E7%9B%AE%E4%B8%AD%E9%9B%86%E6%88%90%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD/","excerpt":"","text":"TODO！！！","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"}],"author":"ehzyil"},{"title":"基于@ControllerAdvice实现全局异常处理","slug":"2023/基于@ControllerAdvice实现全局异常处理","date":"2023-10-17T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/10/17/2023/基于@ControllerAdvice实现全局异常处理/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/17/2023/%E5%9F%BA%E4%BA%8E@ControllerAdvice%E5%AE%9E%E7%8E%B0%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","excerpt":"","text":"RestControllerAdvice注解与全局异常处理1.前置知识@RestControllerAdvice 和 @ExceptionHandler 是 Spring 框架中用于处理全局异常的注解。 @RestControllerAdvice: @RestControllerAdvice 是一个组合注解，结合了 @ControllerAdvice 和 @ResponseBody。它用于全局处理控制器层（Controller）抛出的异常，可以将处理结果直接以 JSON 格式返回给客户端。 具体用途包括但不限于： 全局异常处理：捕获所有 Controller 层抛出的异常，统一进行处理，避免异常直接传递到客户端。 全局数据绑定：可以在这里对请求参数进行全局的预处理或校验。 全局数据预处理：可以在这里对返回的数据进行统一处理。 @ExceptionHandler: @ExceptionHandler 是一个局部异常处理的注解，它可以用在控制器层的方法上，用于处理指定类型的异常。 具体用途包括但不限于： 处理特定类型的异常：将指定类型的异常捕获，然后执行相应的处理逻辑。 提供自定义的异常处理逻辑：可以根据业务需求编写特定的异常处理代码。 2.举例 举例： @RestControllerAdvice public class GlobalExceptionHandler &#123; @ExceptionHandler(Exception.class) public ResponseEntity&lt;String> handleException(Exception e) &#123; return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body(\"Internal Server Error\"); &#125; @ExceptionHandler(UserNotFoundException.class) public ResponseEntity&lt;String> handleUserNotFoundException(UserNotFoundException e) &#123; return ResponseEntity.status(HttpStatus.NOT_FOUND).body(\"User Not Found\"); &#125; &#125; 在上面的例子中，GlobalExceptionHandler 类使用 @RestControllerAdvice 注解来指示它是一个全局异常处理器。然后，使用 @ExceptionHandler 注解来定义处理特定类型异常的方法。例如，handleException 方法处理所有类型的异常，而 handleUserNotFoundException 方法只处理 UserNotFoundException 类型的异常。 总的来说，@RestControllerAdvice 和 @ExceptionHandler 的组合允许你在应用程序中建立一套全局的异常处理机制，提高了代码的可维护性和健壮性。 3.代码实现自定义业务异常类ServiceException package com.ehzyil.exception; import lombok.Getter; import static com.ehzyil.enums.StatusCodeEnum.FAIL; /** * 业务异常 **/ @Getter public final class ServiceException extends RuntimeException &#123; /** * 返回失败状态码 */ private Integer code = FAIL.getCode(); /** * 返回信息 */ private final String message; public ServiceException(String message) &#123; this.message = message; &#125; &#125; 全局异常处理类GlobalExceptionHandler.java package com.ehzyil.handler; import cn.dev33.satoken.exception.DisableServiceException; import cn.dev33.satoken.exception.NotLoginException; import cn.dev33.satoken.exception.NotPermissionException; import cn.dev33.satoken.exception.NotRoleException; import com.ehzyil.exception.ServiceException; import com.ehzyil.model.vo.Result; import org.springframework.web.bind.MethodArgumentNotValidException; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.RestControllerAdvice; import java.util.Objects; import static com.ehzyil.enums.StatusCodeEnum.*; /** * @author ehyzil * @Description 全局异常处理 * @create 2023-09-2023/9/30-22:47 */ @RestControllerAdvice public class GlobalExceptionHandler &#123; /** * 处理业务异常 * * @param e * @return */ @ExceptionHandler(value = ServiceException.class) public Result&lt;?> handleServiceException(ServiceException e) &#123; return Result.fail(e.getMessage()); &#125; /** * 处理Assert异常 */ @ExceptionHandler(value = IllegalArgumentException.class) public Result&lt;?> handleIllegalArgumentException(IllegalArgumentException e) &#123; return Result.fail(e.getMessage()); &#125; /** * 处理参数校验异常 */ @ExceptionHandler(value = MethodArgumentNotValidException.class) public Result&lt;?> handleMethodArgumentNotValidException(MethodArgumentNotValidException e) &#123; return Result.fail(VALID_ERROR.getCode(), Objects.requireNonNull(e.getBindingResult().getFieldError()).getDefaultMessage()); &#125; /** * 处理权限不足 */ @ExceptionHandler(value = NotPermissionException.class) public Result&lt;?> handleNotPermissionException() &#123; return Result.fail(\"权限不足\"); &#125; /** * 处理账号封禁 */ @ExceptionHandler(value = DisableServiceException.class) public Result&lt;?> handleDisableServiceExceptionException() &#123; return Result.fail(\"此账号已被禁止访问服务\"); &#125; /** * 处理无此角色异常 */ @ExceptionHandler(value = NotRoleException.class) public Result&lt;?> handleNotRoleException() &#123; return Result.fail(\"权限不足\"); &#125; /** * 处理SaToken异常 */ @ExceptionHandler(value = NotLoginException.class) public Result&lt;?> handlerNotLoginException(NotLoginException nle) &#123; // 判断场景值，定制化异常信息 String message; if (nle.getType().equals(NotLoginException.NOT_TOKEN)) &#123; message = \"未提供token\"; &#125; else if (nle.getType().equals(NotLoginException.INVALID_TOKEN)) &#123; message = \"token无效\"; &#125; else if (nle.getType().equals(NotLoginException.TOKEN_TIMEOUT)) &#123; message = \"token已过期\"; &#125; else &#123; message = \"当前会话未登录\"; &#125; // 返回给前端 return Result.fail(UNAUTHORIZED.getCode(), message); &#125; /** * 处理系统异常 */ @ExceptionHandler(value = Exception.class) public Result&lt;?> handleSystemException() &#123; return Result.fail(SYSTEM_ERROR.getCode(), SYSTEM_ERROR.getMsg()); &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"异常","slug":"异常","permalink":"https://blog.ehzyil.xyz/tags/%E5%BC%82%E5%B8%B8/"}],"author":"ehzyil"},{"title":"基于AOP实现访客日志记录","slug":"2023/基于AOP实现访客日志记录","date":"2023-10-17T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/10/17/2023/基于AOP实现访客日志记录/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/17/2023/%E5%9F%BA%E4%BA%8EAOP%E5%AE%9E%E7%8E%B0%E8%AE%BF%E5%AE%A2%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95/","excerpt":"","text":"基于AOP实现访客日志记录1.准备所需的日志表create table t_visit_log ( id int auto_increment comment 'id' primary key, page varchar(50) null comment '访问页面', ip_address varchar(50) null comment '访问ip', ip_source varchar(50) null comment '访问地址', os varchar(50) null comment '操作系统', browser varchar(50) null comment '浏览器', create_time datetime not null comment '访问时间' ); 2.pom依赖… 3.实体/** * 访问日志 */ @Data public class VisitLog &#123; /** * id */ @TableId(type = IdType.AUTO) private Integer id; /** * 访问页面 */ private String page; /** * 访问ip */ private String ipAddress; /** * 访问地址 */ private String ipSource; /** * 操作系统 */ private String os; /** * 浏览器 */ private String browser; /** * 访问时间 */ @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; &#125; 4.自定义日志注解/** * @author ehyzil * @Description 访问日志注解 * @create 2023-10-2023/10/1-20:37 */ @Documented @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface VisitLogger &#123; /** * * @return 访问页面 */ String value() default \"\"; &#125; 5.Spring实例获取工具类// 这是一个实用工具类，用于与Spring容器交互，获取Bean实例等功能。 public final class SpringUtils implements BeanFactoryPostProcessor &#123; private static ConfigurableListableBeanFactory beanFactory; @Override public void postProcessBeanFactory(@NotNull ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; SpringUtils.beanFactory = beanFactory; &#125; /** * 获取指定名称的对象 * @param name 对象的名称 * @return 获取到的对象实例 */ @SuppressWarnings(\"unchecked\") public static &lt;T> T getBean(String name) throws BeansException &#123; return (T) beanFactory.getBean(name); &#125; /** * 获取指定类型的对象 * @param clz 对象的类型 * @return 获取到的对象实例 */ public static &lt;T> T getBean(Class&lt;T> clz) throws BeansException &#123; return beanFactory.getBean(clz); &#125; /** * 获取指定名称的Bean的类型 * @param name Bean的名称 * @return Bean的类型 * @throws NoSuchBeanDefinitionException 如果找不到对应的Bean定义 */ public static Class&lt;?> getType(String name) throws NoSuchBeanDefinitionException &#123; return beanFactory.getType(name); &#125; &#125; 6.IP地址工具类package com.ehzyil.utils; import com.ehzyil.exception.ServiceException; import org.lionsoul.ip2region.xdb.Searcher; import org.springframework.core.io.ClassPathResource; import org.springframework.util.FileCopyUtils; import org.springframework.util.StringUtils; import javax.servlet.http.HttpServletRequest; import java.io.IOException; import java.io.InputStream; import java.net.InetAddress; import java.net.UnknownHostException; import java.util.Objects; /** * IP地址工具类 * * @author ehzyil */ @SuppressWarnings(\"all\") public class IpUtils &#123; private static Searcher searcher; static &#123; // 解决项目打包找不到ip2region.xdb try &#123; InputStream inputStream = new ClassPathResource(\"/ipdb/ip2region.xdb\").getInputStream(); //将 ip2region.db 转为 ByteArray byte[] cBuff = FileCopyUtils.copyToByteArray(inputStream); searcher = Searcher.newWithBuffer(cBuff); &#125; catch (IOException e) &#123; throw new ServiceException(\"ip2region.xdb加载失败\"); &#125; &#125; /** * 在Nginx等代理之后获取用户真实IP地址 */ public static String getIpAddress(HttpServletRequest request) &#123; String ip; try &#123; ip = request.getHeader(\"X-Real-IP\"); if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"x-forwarded-for\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"Proxy-Client-IP\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"WL-Proxy-Client-IP\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"HTTP_CLIENT_IP\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"HTTP_X_FORWARDED_FOR\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getRemoteAddr(); if (\"127.0.0.1\".equals(ip) || \"0:0:0:0:0:0:0:1\".equals(ip)) &#123; //根据网卡取本机配置的IP InetAddress inet = null; try &#123; inet = InetAddress.getLocalHost(); &#125; catch (UnknownHostException e) &#123; throw new UnknownHostException(\"无法确定主机的IP地址\"); &#125; ip = inet.getHostAddress(); &#125; &#125; // 使用代理，则获取第一个IP地址 if (!StringUtils.hasText(ip) &amp;&amp; Objects.requireNonNull(ip).length() > 15) &#123; int idx = ip.indexOf(\",\"); if (idx > 0) &#123; ip = ip.substring(0, idx); &#125; &#125; &#125; catch (Exception e) &#123; ip = \"\"; &#125; return ip; &#125; /** * 根据ip从 ip2region.db 中获取地理位置 * * @param ip * @return */ public static String getIpSource(String ip) &#123; try &#123; String address = searcher.searchByStr(ip); if (StringUtils.hasText(address)) &#123; address = address.replace(\"|0\", \"\"); address = address.replace(\"0|\", \"\"); return address; &#125; return address; &#125; catch (Exception e) &#123; return \"\"; &#125; &#125; &#125; 7.线程池配置ThreadPoolProperties类是一个自定义的属性类，用于配置线程池的相关属性。 package com.ican.config.properties; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; /** * 线程池参数 **/ @Data @Configuration @ConfigurationProperties(prefix = \"thread.pool\") public class ThreadPoolProperties &#123; /** * 核心线程池大小 */ private int corePoolSize; /** * 最大可创建的线程数 */ private int maxPoolSize; /** * 队列最大长度 */ private int queueCapacity; /** * 线程池维护线程所允许的空闲时间 */ private int keepAliveSeconds; &#125; 线程池配置 threadPoolTaskExecutor()方法，使用@Bean注解将其声明为一个Bean。该方法返回了一个ThreadPoolTaskExecutor对象，用于创建线程池。 /** * 线程池配置 **/ @Configuration public class ThreadPoolConfig &#123; @Autowired private ThreadPoolProperties threadPoolProperties; /** * 创建线程池 * * @return 线程池 */ @Bean public ThreadPoolTaskExecutor threadPoolTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); // 核心线程池大小 executor.setCorePoolSize(threadPoolProperties.getCorePoolSize()); // 最大可创建的线程数 executor.setMaxPoolSize(threadPoolProperties.getMaxPoolSize()); // 等待队列最大长度 executor.setQueueCapacity(threadPoolProperties.getQueueCapacity()); // 线程池维护线程所允许的空闲时间 executor.setKeepAliveSeconds(threadPoolProperties.getKeepAliveSeconds()); // 线程池对拒绝任务(无线程可用)的处理策略 executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); return executor; &#125; /** * 执行周期性或定时任务 */ @Bean(name = \"scheduledExecutorService\") protected ScheduledExecutorService scheduledExecutorService() &#123; return new ScheduledThreadPoolExecutor(threadPoolProperties.getCorePoolSize(), new BasicThreadFactory.Builder().namingPattern(\"schedule-pool-%d\").daemon(true).build(), new ThreadPoolExecutor.CallerRunsPolicy()) &#123; @Override protected void afterExecute(Runnable r, Throwable t) &#123; super.afterExecute(r, t); ThreadUtils.printException(r, t); &#125; &#125;; &#125; &#125; 使用了ThreadPoolExecutor.CallerRunsPolicy()，表示当线程池无法接受新任务时，将任务回退到调用者线程中执行。 8.异步任务配置package com.ehzyil.manager; import com.ehzyil.utils.SpringUtils; import com.ehzyil.utils.ThreadUtils; import java.util.TimerTask; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; /** * 异步任务管理器 * * @author ehzyil */ public class AsyncManager &#123; /** * 单例模式，确保类只有一个实例 */ private AsyncManager() &#123; &#125; /** * 饿汉式，在类加载的时候立刻进行实例化 */ private static final AsyncManager INSTANCE = new AsyncManager(); public static AsyncManager getInstance() &#123; return INSTANCE; &#125; /** * 异步操作任务调度线程池 */ private final ScheduledExecutorService executor = SpringUtils.getBean(\"scheduledExecutorService\"); /** * 执行任务 * * @param task 任务 */ public void execute(TimerTask task) &#123; executor.schedule(task, 10, TimeUnit.MILLISECONDS); &#125; /** * 停止任务线程池 */ public void shutdown() &#123; ThreadUtils.shutdownAndAwaitTermination(executor); &#125; &#125; 线程工具类ThreadUtils package com.ehzyil.utils; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.util.concurrent.*; /** * 线程工具类 * * @author ehzyil */ public class ThreadUtils &#123; private static final Logger logger = LoggerFactory.getLogger(ThreadUtils.class); private static final long OVERTIME = 120; /** * 停止线程池 * 先使用shutdown, 停止接收新任务并尝试完成所有已存在任务. * 如果超时, 则调用shutdownNow, 取消在workQueue中Pending的任务,并中断所有阻塞函数. * 如果仍然超時，則強制退出. * 另对在shutdown时线程本身被调用中断做了处理. */ public static void shutdownAndAwaitTermination(ExecutorService pool) &#123; if (pool != null &amp;&amp; !pool.isShutdown()) &#123; pool.shutdown(); try &#123; if (!pool.awaitTermination(OVERTIME, TimeUnit.SECONDS)) &#123; pool.shutdownNow(); if (!pool.awaitTermination(OVERTIME, TimeUnit.SECONDS)) &#123; logger.info(\"Pool did not terminate\"); &#125; &#125; &#125; catch (InterruptedException ie) &#123; pool.shutdownNow(); Thread.currentThread().interrupt(); &#125; &#125; &#125; /** * 打印线程异常信息 */ public static void printException(Runnable r, Throwable t) &#123; if (t == null &amp;&amp; r instanceof Future&lt;?>) &#123; try &#123; Future&lt;?> future = (Future&lt;?>) r; if (future.isDone()) &#123; future.get(); &#125; &#125; catch (CancellationException ce) &#123; t = ce; &#125; catch (ExecutionException ee) &#123; t = ee.getCause(); &#125; catch (InterruptedException ie) &#123; Thread.currentThread().interrupt(); &#125; &#125; if (t != null) &#123; logger.error(t.getMessage(), t); &#125; &#125; &#125; 9.任务工厂配置/** * 异步工厂（产生任务用） */ public class AsyncFactory &#123; /** * 记录访问日志 * * @param visitLog 访问日志信息 * @return 任务task */ public static TimerTask recordVisit(VisitLog visitLog) &#123; return new TimerTask() &#123; @Override public void run() &#123; SpringUtils.getBean(VisitLogService.class).saveVisitLog(visitLog); &#125; &#125;; &#125; &#125; 核心切面配置/** * AOP记录访问日志 **/ @Aspect @Component public class VisitLogAspect &#123; @Pointcut(\"@annotation(com.ehzyil.annotation.VisitLogger)\") public void visitLogPointCut() &#123; &#125; /** * 连接点正常返回通知，拦截用户操作日志，正常执行完成后执行， 如果连接点抛出异常，则不会执行 * * @param joinPoint 切面方法的信息 * @param result 返回结果 */ @AfterReturning(value = \"visitLogPointCut()\", returning = \"result\") public void doAfterReturning(JoinPoint joinPoint, Object result) &#123; // 从切面织入点处通过反射机制获取织入点处的方法 MethodSignature signature = (MethodSignature) joinPoint.getSignature(); // 获取切入点所在的方法 Method method = signature.getMethod(); // 获取操作 VisitLogger visitLogger = method.getAnnotation(VisitLogger.class); // 获取request ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = Objects.requireNonNull(attributes).getRequest(); VisitLog visitLog = new VisitLog(); String ipAddress = IpUtils.getIpAddress(request); String ipSource = IpUtils.getIpSource(ipAddress); // 解析browser和os Map&lt;String, String> userAgentMap = UserAgentUtils.parseOsAndBrowser(request.getHeader(\"User-Agent\")); visitLog.setIpAddress(ipAddress); visitLog.setIpSource(ipSource); visitLog.setOs(userAgentMap.get(\"os\")); visitLog.setBrowser(userAgentMap.get(\"browser\")); visitLog.setPage(visitLogger.value()); // 保存到数据库 AsyncManager.getInstance().execute(AsyncFactory.recordVisit(visitLog)); &#125; &#125; 日志Service层/** * 访问业务接口 */ public interface VisitLogService extends IService&lt;VisitLog> &#123; /** * 保存访问日志 * * @param visitLog 访问日志信息 */ void saveVisitLog(VisitLog visitLog); &#125; @Service public class VisitLogServiceImpl extends ServiceImpl&lt;VisitLogMapper, VisitLog> implements VisitLogService &#123; @Autowired private VisitLogMapper visitLogMapper; @Override public void saveVisitLog(VisitLog visitLog) &#123; // 保存访问日志 visitLogMapper.insert(visitLog); &#125; 控制器测试/** * 查看首页文章列表 * * @return &#123;@link Result&lt;ArticleHomeVO>&#125; */ @VisitLogger(value = \"首页\") @ApiOperation(value = \"查看首页文章列表\") @GetMapping(\"/article/list\") public Result&lt;PageResult&lt;ArticleHomeVO>> listArticleHomeVO() &#123; return Result.success(articleService.listArticleHomeVO()); &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"AOP","slug":"AOP","permalink":"https://blog.ehzyil.xyz/tags/AOP/"},{"name":"日志","slug":"日志","permalink":"https://blog.ehzyil.xyz/tags/%E6%97%A5%E5%BF%97/"}],"author":"ehzyil"},{"title":"基于策略模式实现图片上传","slug":"2023/基于策略模式实现图片上传","date":"2023-10-17T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/10/17/2023/基于策略模式实现图片上传/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/17/2023/%E5%9F%BA%E4%BA%8E%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0/","excerpt":"","text":"基于策略模式实现图片上传1.前置准备-策略接口的编写新建一个名称为 strategy 的文件夹（在代码规范中，使用设计模式要明确的体现出来，便于后期维护） public interface UploadStrategy &#123; /** * 上传文件 * * @param file 文件 * @param path 上传路径 * @return &#123;@link String&#125; 文件地址 */ String uploadFile(MultipartFile file, String path); &#125; 完善配置文件 在编写对象存储实现类之前，我门会发现一个问题。我们需要去对应的云服务厂商开通对象存储服务，然后获取到accessKey、accessKeySecret、endpoint、bucket、domainUrl等必须的参数。因为这些信息基本是不会发生改变，所以我们可以将这些信息存储在配置文件中。除此之外我们还需要对文件上传进行配置，设置为最大文件为100MB spring: servlet: multipart: max-file-size: 100MB max-request-size: 100MB # 文件上传策略 local、oss、cos upload: strategy: qiniu local: # nginx映射本地文件路径 url: https://你的文件上传子域名/ # 本地文件存储路径 path: /usr/local/upload/ # oss存储 oss: url: http://Bucket域名/ endpoint: OSS配置endpoint bucketName: OSS配置bucketName accessKeyId: OSS配置accessKeyId accesskeySecret: OSS配置accesskeySecret # cos存储 cos: url: https://Bucket域名/ secretId: COS配置secretId secretKey: COS配置secretKey region: COS配置region bucketName: COS配置bucketName # qiniu存储(七牛云) qiniu: url: http://s14jjz3r5.hb-bkt.clouddn.com/ # 访问域名(给存储桶绑定的二级域名) bucketName: ehzyil-blog # 空间名称bucketName region: huabei # 存储区域 华南(huanan) 华北(huabei)... accessKey: CSOFmR7_70ThEOZqlgTdbe2HnvOjbjPdCHt8CZrb #accessKey secretKey: _D-S6V1rBT2jjnZrX-Z_s30Aw6SNO1ydOFYHnUoC #secretKey 引入自定义配置依赖 以及 云服务依赖 &lt;!-- 腾讯云cos --> &lt;dependency> &lt;groupId>com.qcloud&lt;/groupId> &lt;artifactId>cos_api&lt;/artifactId> &lt;version>$&#123;cos.version&#125;&lt;/version> &lt;/dependency> &lt;!--七牛云qiniu--> &lt;dependency> &lt;groupId>com.qiniu&lt;/groupId> &lt;artifactId>qiniu-java-sdk&lt;/artifactId> &lt;version>[7.2.0, 7.2.99]&lt;/version> &lt;/dependency> &lt;!-- 阿里云oss --> &lt;dependency> &lt;groupId>com.aliyun.oss&lt;/groupId> &lt;artifactId>aliyun-sdk-oss&lt;/artifactId> &lt;version>$&#123;oss.version&#125;&lt;/version> &lt;/dependency> 编写properties实体类，通过@ConfigurationProperties()注解可以将配置文件中的内容读取到实体类中。 @Data @Configuration @ConfigurationProperties(prefix = \"upload.oss\") public class OssProperties &#123; /** * oss域名 */ private String url; /** * 终点 */ private String endpoint; /** * 访问密钥id */ private String accessKeyId; /** * 访问密钥密码 */ private String accessKeySecret; /** * bucket名称 */ private String bucketName; &#125; @Data @Configuration @ConfigurationProperties(prefix = \"upload.qiniu\") public class QiniuProperties &#123; private String url;//url 或者 域名 private String bucketName; //存储桶名字 private String region;//区域 如huanan hubei private String accessKey;//accessKey private String secretKey;//secretKey /** * 配置空间的存储区域 */ @Bean public com.qiniu.storage.Configuration qiNiuConfig() &#123; switch (region) &#123; case \"huadong\": return new com.qiniu.storage.Configuration(Zone.huadong()); case \"huabei\": return new com.qiniu.storage.Configuration(Zone.huabei()); case \"huanan\": return new com.qiniu.storage.Configuration(Zone.huanan()); case \"beimei\": return new com.qiniu.storage.Configuration(Zone.beimei()); default: throw new RuntimeException(\"存储区域配置错误\"); &#125; &#125; /** * 构建一个七牛上传工具实例 */ @Bean public UploadManager uploadManager() &#123; return new UploadManager(qiNiuConfig()); &#125; /** * 认证信息实例 */ @Bean public Auth auth() &#123; return Auth.create(accessKey, secretKey); &#125; /** * 构建七牛空间管理实例 */ @Bean public BucketManager bucketManager() &#123; return new BucketManager(auth(), qiNiuConfig()); &#125; &#125; 本地上传配置信息完善 本地上传目前不需要进行配置，项目上线可以进行域名配置域名配制 上传策略枚举 @Getter @AllArgsConstructor public enum UploadModeEnum &#123; /** * 本地 */ LOCAL(\"local\", \"localUploadStrategyImpl\"), /** * oss */ OSS(\"oss\", \"ossUploadStrategyImpl\"), /** * cos */ COS(\"cos\", \"cosUploadStrategyImpl\"), /** * qiniu */ QINIU(\"qiniu\", \"qiniuUploadStrategyImpl\"); /** * 模式 */ private final String mode; /** * 策略 */ private final String strategy; /** * 获取策略 * * @param mode 模式 * @return 搜索策略 */ public static String getStrategy(String mode) &#123; for (UploadModeEnum value : UploadModeEnum.values()) &#123; if (value.getMode().equals(mode)) &#123; return value.getStrategy(); &#125; &#125; return null; &#125; &#125; 2.策略实现类内部实现-模板设计模式我们在进行具体文件上传策略实现之前总结一下所涉及到的功能。 初始化客户端 文件是否已经存在 文件上传 获取访问路径 我们会发现无论是通过哪个平台进行文件的上传，基本上都会使用到上述的步骤，也就是说都会使用到上述的方法。所以在这里我们定义一个抽象类来规定具体所需要使用的方法，然后各个具体实现来继承我们的抽象类即可。 public abstract class AbstractUploadStrategyImpl implements UploadStrategy &#123; @Override public String uploadFile(MultipartFile file, String path) &#123; try &#123; // 判断文件大小是否超过2MB（2MB=2*1024*1024 bytes） if (file.getSize() > 2 * 1024 * 1024) &#123; // 抛出文件大小超过限制的异常 throw new ServiceException(\"文件大小不能超出2MB！\"); &#125; //获取文件md5值 String md5 = FileUtils.getMd5(file.getInputStream()); //获取拓展名 String extName = FileUtils.getExtension(file); // 重新生成文件名 String fileName = md5 + \".\" + extName; //region 初始化 initClient(); //endregion // 判断文件是否已存在 if (!exists(path + fileName)) &#123; // 不存在则继续上传 upload(path, fileName, file.getInputStream()); &#125; // 返回文件访问路径 String url=getFileAccessUrl(path + fileName); uploadToDB(file, path, md5, extName, url); return url; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new ServiceException(\"文件上传失败\"); &#125; &#125; /** * 初始化客户端 */ public abstract void initClient(); /** * 判断文件是否存在 * * @param filePath 文件路径 * @return &#123;@link Boolean&#125; */ public abstract Boolean exists(String filePath); /** * 上传 * * @param path 路径 * @param fileName 文件名 * @param inputStream 输入流 * @throws IOException io异常 */ public abstract void upload(String path, String fileName, InputStream inputStream) throws IOException; /** * 获取文件访问url * * @param filePath 文件路径 * @return &#123;@link String&#125; 文件url */ public abstract String getFileAccessUrl(String filePath); public abstract void uploadToDB(MultipartFile file, String path, String md5, String extName, String url); &#125; 3.Oss上传策略具体实现Oss上传策略具体实现 @Slf4j @Service(\"ossUploadStrategyImpl\") public class OssUploadStrategyImpl extends AbstractUploadStrategyImpl &#123; @Autowired private OssProperties ossProperties; @Autowired @Lazy private IBlogFileService blogFileService; @Override public void initClient() &#123; &#125; @Override public Boolean exists(String filePath) &#123; return getOssClient().doesObjectExist(ossProperties.getBucketName(), filePath); &#125; @Override public void upload(String path, String fileName, InputStream inputStream) &#123; OSS ossClient = getOssClient(); try &#123; // 调用oss方法上传 ossClient.putObject(ossProperties.getBucketName(), path + fileName, inputStream); &#125; catch (OSSException oe) &#123; log.error(\"Error Message:\" + oe.getErrorMessage()); log.error(\"Error Code:\" + oe.getErrorCode()); log.info(\"Request ID:\" + oe.getRequestId()); log.info(\"Host ID:\" + oe.getHostId()); &#125; catch (ClientException ce) &#123; log.error(\"Caught an ClientException, Error Message:\" + ce.getMessage()); &#125; finally &#123; if (ossClient != null) &#123; ossClient.shutdown(); &#125; &#125; &#125; @Override public String getFileAccessUrl(String filePath) &#123; return ossProperties.getUrl() + filePath; &#125; @Override public void uploadToDB(MultipartFile file, String path, String md5, String extName, String url) &#123; blogFileService.uploadToDB(file,path,md5,extName,url); &#125; /** * 获取ossClient * * @return &#123;@link OSS&#125; ossClient */ private OSS getOssClient() &#123; return new OSSClientBuilder().build(ossProperties.getEndpoint(), ossProperties.getAccessKeyId(), ossProperties.getAccessKeySecret()); &#125; &#125; Cos上传策略具体实现 @Slf4j @Service(\"cosUploadStrategyImpl\") public class CosUploadStrategyImpl extends AbstractUploadStrategyImpl &#123; @Autowired private CosProperties cosProperties; @Autowired @Lazy private IBlogFileService blogFileService; @Override public void initClient() &#123; &#125; @Override public Boolean exists(String filePath) &#123; return getCosClient().doesObjectExist(cosProperties.getBucketName(), filePath); &#125; @Override public void upload(String path, String fileName, InputStream inputStream) &#123; COSClient cosClient = getCosClient(); try &#123; ObjectMetadata objectMetadata = new ObjectMetadata(); // 上传的流如果能够获取准确的流长度，则推荐一定填写 content-length objectMetadata.setContentLength(inputStream.available()); // 调用cos方法上传 cosClient.putObject(cosProperties.getBucketName(), path + fileName, inputStream, objectMetadata); &#125; catch (CosServiceException e) &#123; log.error(\"Error Message:\" + e.getErrorMessage()); log.error(\"Error Code:\" + e.getErrorCode()); log.info(\"Request ID:\" + e.getRequestId()); &#125; catch (CosClientException e) &#123; log.error(\"Caught an CosClientException, Error Message:\" + e.getMessage()); &#125; catch (IOException e) &#123; log.error(\"Caught an IOException, Error Message:\" + e.getMessage()); &#125; finally &#123; cosClient.shutdown(); &#125; &#125; @Override public String getFileAccessUrl(String filePath) &#123; return cosProperties.getUrl() + filePath; &#125; @Override public void uploadToDB(MultipartFile file, String path, String md5, String extName, String url) &#123; blogFileService.uploadToDB(file,path,md5,extName,url); &#125; /** * 获取cosClient * * @return &#123;@link COSClient&#125; cosClient */ private COSClient getCosClient() &#123; // 1 初始化用户身份信息（secretId, secretKey）。 COSCredentials cred = new BasicCOSCredentials(cosProperties.getSecretId(), cosProperties.getSecretKey()); // 2 设置 bucket 的地域, COS 地域的简称请参照 https://cloud.tencent.com/document/product/436/6224 Region region = new Region(cosProperties.getRegion()); ClientConfig clientConfig = new ClientConfig(region); // 这里建议设置使用 https 协议 // 从 5.6.54 版本开始，默认使用了 https clientConfig.setHttpProtocol(HttpProtocol.https); // 3 生成 cos 客户端。 return new COSClient(cred, clientConfig); &#125; &#125; 本地上传策略具体实现-在LocalUploadStrategyImpl实现文件上传至本地 @Slf4j @Getter @Setter @RequiredArgsConstructor @Service(\"localUploadStrategyImpl\") public class LocalUploadStrategyImpl extends AbstractUploadStrategyImpl &#123; /** * 访问url */ @Value(\"$&#123;upload.local.url&#125;\") private String localUrl; /** * 本地路径 */ @Value(\"$&#123;upload.local.path&#125;\") private String localPath; /** * 本地项目端口 */ @Value(\"$&#123;server.port&#125;\") private Integer port; @Autowired @Lazy private IBlogFileService blogFileService; //TODO 本地上传待优化 @Override public void initClient() &#123; //win 本地 // try &#123; // localPath = ResourceUtils.getURL(\"classpath:\").getPath() + \"static/imgs/\"; // &#125; catch (FileNotFoundException e) &#123; // e.printStackTrace(); // throw new ServiceException(\"文件不存在\"); // &#125; // 判断目录是否存在 File directory = new File(localPath); if (!directory.exists()) &#123; if (directory.mkdirs()) &#123; throw new ServiceException(\"创建目录失败\"); &#125; &#125; &#125; @Override public Boolean exists(String filePath) &#123; return new File(localPath + filePath).exists(); &#125; @Override public void upload(String path, String fileName, InputStream inputStream) throws IOException &#123; // 判断上传目录是否存在 File directory = new File(localPath + path); if (!directory.exists()) &#123; if (!directory.mkdirs()) &#123; throw new ServiceException(\"创建目录失败\"); &#125; &#125; // 写入文件 File file = new File(localPath + path + fileName); if (file.createNewFile()) &#123; //使用缓冲流写入本地 try (BufferedInputStream bis = new BufferedInputStream(inputStream); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(file))) &#123; byte[] bytes = new byte[4096]; int length; while ((length = bis.read(bytes)) != -1) &#123; bos.write(bytes, 0, length); &#125; &#125; &#125; &#125; @Override public String getFileAccessUrl(String filePath) &#123; return localPath + filePath; &#125; @Override public void uploadToDB(MultipartFile file, String path, String md5, String extName, String url) &#123; blogFileService.uploadToDB(file,path,md5,extName,url); &#125; &#125; 4.策略上下文实现我们通过策略上下文来选择使用哪种上传方式。注意点： 当Map集合的Value为接口类型时，Spring会自动对Map集合进行注入。 ​ 其中map集合的key为接口对应实现类的BeanName​ 其中map集合的vlaue为接口对应实现类的实例 其中传入的uploadServiceName就是对应策略类所规定的的BeanName，这里的BeanName就作为选择的条件。 @Service public class UploadStrategyContext &#123; /** * 上传模式 */ @Value(\"$&#123;upload.strategy&#125;\") private String uploadStrategy; @Autowired private Map&lt;String, UploadStrategy> uploadStrategyMap; /** * 上传文件 * * @param file 文件 * @param path 路径 * @return &#123;@link String&#125; 文件地址 */ public String executeUploadStrategy(MultipartFile file, String path) &#123; return uploadStrategyMap.get(getStrategy(uploadStrategy)).uploadFile(file, path); &#125; &#125; 5.不同策略上传测试@RestController @RequiredArgsConstructor public class UploadController &#123; private final UploadStrategyContext uploadStrategyContext; @PostMapping(\"/upload\") public ResponseResult&lt;?> upload(MultipartFile file) &#123; return ResponseResult.success(\"文件上传成功！\",uploadStrategyContext.executeUploadStrategy(file,\"/blog/avatar\",\"cosUploadServiceImpl\")); &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"图片上传","slug":"图片上传","permalink":"https://blog.ehzyil.xyz/tags/%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0/"}],"author":"ehzyil"},{"title":"异常之doesn't have a default value","slug":"2023/异常之doesn't have a default value","date":"2023-10-17T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/10/17/2023/异常之doesn't have a default value/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/17/2023/%E5%BC%82%E5%B8%B8%E4%B9%8Bdoesn't%20have%20a%20default%20value/","excerpt":"","text":"MySQL报错Field ‘user_id’ doesn’t have a default value一、问题 执行sql语句时，报错Field ‘user_id’ doesn’t have a default value； ![image-20231017122452384](.&#x2F;images&#x2F;异常之doesn’t have a default value&#x2F;image-20231017122452384.png) 二、解决 1、表结构 CREATE TABLE `sys_user_role` ( `user_id` bigint NOT NULL COMMENT '用户ID', `role_id` bigint NOT NULL COMMENT '角色ID', ) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb3 COMMENT='用户和角色关联表' 2、执行的sql INSERT INTO sys_user_role ( role_id ) VALUES ( ? ) 在插入信息时只插入了’role_id’未插入’user_id’,sql中没有字段且 PRIMARY KEY (user_id,role_id） 因此插入时报异常. 经查找实体类user_role 发现在userId上添加了如下注解 @TableId(\"user_id\")//相当于 @TableId(\"user_id\") 导致无法获取User实体的userId字段。 解决方案 去掉@TableId注解 将注解改为：@TableId(value &#x3D; “user_id”, type &#x3D; IdType.INPUT) 三、延伸 @TableId注解 描述：主键注解 使用位置：实体类主键字段 @TableName(\"sys_user\") public class User &#123; @TableId private Long id; private String name; private Integer age; private String email; &#125; 属性 类型 必须指定 默认值 描述 value String 否 “” 主键字段名 type Enum 否 IdType.NONE 指定主键类型 IdType 值 描述 AUTO 数据库 ID 自增 NONE 无状态，该类型为未设置主键类型（注解里等于跟随全局，全局里约等于 INPUT） INPUT insert 前自行 set 主键值 ASSIGN_ID 分配 ID(主键类型为 Number(Long 和 Integer)或 String)(since 3.3.0),使用接口IdentifierGenerator的方法nextId(默认实现类为DefaultIdentifierGenerator雪花算法) ASSIGN_UUID 分配 UUID,主键类型为 String(since 3.3.0),使用接口IdentifierGenerator的方法nextUUID(默认 default 方法) ID_WORKER 分布式全局唯一 ID 长整型类型(please use ASSIGN_ID) UUID 32 位 UUID 字符串(please use ASSIGN_UUID) ID_WORKER_STR 分布式全局唯一 ID 字符串类型(please use ASSIGN_ID)","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"},{"name":"异常","slug":"异常","permalink":"https://blog.ehzyil.xyz/tags/%E5%BC%82%E5%B8%B8/"}],"author":"ehzyil"},{"title":"Spring Boot整合Quartz实现动态定时任务","slug":"2023/Spring Boot整合Quartz实现动态定时任务","date":"2023-10-16T20:22:46.000Z","updated":"2024-01-06T04:54:46.199Z","comments":true,"path":"2023/10/16/2023/Spring Boot整合Quartz实现动态定时任务/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/16/2023/Spring%20Boot%E6%95%B4%E5%90%88Quartz%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"","text":"本文目的是Spring Boot整合Quartz实现动态任务配置和实现定时清理日志。 Spring Boot整合Quartz 详见 Quartz 使用教程 前置准备/** * 定时任务 */ @Data @Builder @NoArgsConstructor @AllArgsConstructor public class Task &#123; /** * 任务id */ @TableId(type = IdType.AUTO) private Integer id; /** * 任务名称 */ private String taskName; /** * 任务组名 */ private String taskGroup; /** * 调用目标 */ private String invokeTarget; /** * cron执行表达式 */ private String cronExpression; /** * 计划执行错误策略 (1立即执行 2执行一次 3放弃执行) */ private Integer misfirePolicy; /** * 是否并发执行 (0否 1是) */ private Integer concurrent; /** * 任务状态 (0运行 1暂停) */ private Integer status; /** * 任务备注信息 */ private String remark; /** * 创建时间 */ @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; /** * 更新时间 */ @TableField(fill = FieldFill.UPDATE) private LocalDateTime updateTime; &#125; SpringUtils工具类，用于获取bean。 @Component public final class SpringUtils implements BeanFactoryPostProcessor &#123; private static ConfigurableListableBeanFactory beanFactory; @Override public void postProcessBeanFactory(@NotNull ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; SpringUtils.beanFactory = beanFactory; &#125; /** * 获取对象 */ @SuppressWarnings(\"unchecked\") public static &lt;T> T getBean(String name) throws BeansException &#123; return (T) beanFactory.getBean(name); &#125; /** * 获取类型为requiredType的对象 */ public static &lt;T> T getBean(Class&lt;T> clz) throws BeansException &#123; return beanFactory.getBean(clz); &#125; public static Class&lt;?> getType(String name) throws NoSuchBeanDefinitionException &#123; return beanFactory.getType(name); &#125; &#125; 创建定时任务工具类 /** * 定时任务工具类 * * @author ican */ public class ScheduleUtils &#123; /** * 得到quartz任务类 * * @param task 执行计划 * @return 具体执行任务类 */ private static Class&lt;? extends Job> getQuartzJobClass(Task task) &#123; boolean isConcurrent = TRUE.equals(task.getConcurrent()); return isConcurrent ? QuartzJobExecution.class : QuartzDisallowConcurrentExecution.class; &#125; /** * 构建任务触发对象 */ public static TriggerKey getTriggerKey(Integer taskId, String taskGroup) &#123; return TriggerKey.triggerKey(ScheduleConstant.TASK_CLASS_NAME + taskId, taskGroup); &#125; /** * 构建任务键对象 */ public static JobKey getJobKey(Integer taskId, String taskGroup) &#123; return JobKey.jobKey(ScheduleConstant.TASK_CLASS_NAME + taskId, taskGroup); &#125; /** * 创建定时任务 */ public static void createScheduleJob(Scheduler scheduler, Task task) &#123; try &#123; Class&lt;? extends Job> jobClass = getQuartzJobClass(task); // 构建task信息 Integer taskId = task.getId(); String taskGroup = task.getTaskGroup(); JobDetail jobDetail = JobBuilder.newJob(jobClass).withIdentity(getJobKey(taskId, taskGroup)).build(); // 表达式调度构建器 CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(task.getCronExpression()); cronScheduleBuilder = handleCronScheduleMisfirePolicy(task, cronScheduleBuilder); // 按新的cronExpression表达式构建一个新的trigger CronTrigger trigger = TriggerBuilder.newTrigger().withIdentity(getTriggerKey(taskId, taskGroup)) .withSchedule(cronScheduleBuilder).build(); // 放入参数，运行时的方法可以获取 jobDetail.getJobDataMap().put(ScheduleConstant.TASK_PROPERTIES, task); // 判断是否存在 if (scheduler.checkExists(getJobKey(taskId, taskGroup))) &#123; // 防止创建时存在数据问题 先移除，然后在执行创建操作 scheduler.deleteJob(getJobKey(taskId, taskGroup)); &#125; scheduler.scheduleJob(jobDetail, trigger); // 暂停任务 if (task.getStatus().equals(TaskStatusEnum.PAUSE.getStatus())) &#123; scheduler.pauseJob(ScheduleUtils.getJobKey(taskId, taskGroup)); &#125; &#125; catch (ServiceException | SchedulerException e) &#123; throw new ServiceException(e.getMessage()); &#125; &#125; /** * 设置定时任务策略 */ public static CronScheduleBuilder handleCronScheduleMisfirePolicy(Task task, CronScheduleBuilder cb) throws ServiceException &#123; switch (task.getMisfirePolicy()) &#123; case ScheduleConstant.MISFIRE_DEFAULT: return cb; case ScheduleConstant.MISFIRE_IGNORE_MISFIRES: return cb.withMisfireHandlingInstructionIgnoreMisfires(); case ScheduleConstant.MISFIRE_FIRE_AND_PROCEED: return cb.withMisfireHandlingInstructionFireAndProceed(); case ScheduleConstant.MISFIRE_DO_NOTHING: return cb.withMisfireHandlingInstructionDoNothing(); default: throw new ServiceException(\"The task misfire policy '\" + task.getMisfirePolicy() + \"' cannot be used in cron schedule tasks\"); &#125; &#125; &#125; 任务执行工具 /** * 任务执行工具 */ public class TaskInvokeUtils &#123; /** * 执行方法 * * @param task 系统任务 */ public static void invokeMethod(Task task) throws Exception &#123; String invokeTarget = task.getInvokeTarget(); String beanName = getBeanName(invokeTarget); String methodName = getMethodName(invokeTarget); List&lt;Object[]> methodParams = getMethodParams(invokeTarget); if (!isValidClassName(beanName)) &#123; Object bean = SpringUtils.getBean(beanName); invokeMethod(bean, methodName, methodParams); &#125; else &#123; Object bean = Class.forName(beanName).getDeclaredConstructor().newInstance(); invokeMethod(bean, methodName, methodParams); &#125; &#125; /** * 调用任务方法 * * @param bean 目标对象 * @param methodName 方法名称 * @param methodParams 方法参数 */ private static void invokeMethod(Object bean, String methodName, List&lt;Object[]> methodParams) throws NoSuchMethodException, SecurityException, IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123; if (methodParams != null &amp;&amp; methodParams.size() > 0) &#123; Method method = bean.getClass().getDeclaredMethod(methodName, getMethodParamsType(methodParams)); method.invoke(bean, getMethodParamsValue(methodParams)); &#125; else &#123; Method method = bean.getClass().getDeclaredMethod(methodName); method.invoke(bean); &#125; &#125; /** * 校验是否为为class包名 * * @param invokeTarget 调用目标 * @return true是 false否 */ public static boolean isValidClassName(String invokeTarget) &#123; return StringUtils.countMatches(invokeTarget, \".\") > 1; &#125; /** * 获取bean名称 * * @param invokeTarget 调用目标 * @return bean名称 */ public static String getBeanName(String invokeTarget) &#123; String beanName = StringUtils.substringBefore(invokeTarget, \"(\"); return StringUtils.substringBeforeLast(beanName, \".\"); &#125; /** * 获取bean方法 * * @param invokeTarget 调用目标 * @return method方法 */ public static String getMethodName(String invokeTarget) &#123; String methodName = StringUtils.substringBefore(invokeTarget, \"(\"); return StringUtils.substringAfterLast(methodName, \".\"); &#125; /** * 获取method方法参数相关列表 * * @param invokeTarget 调用目标 * @return method方法相关参数列表 */ public static List&lt;Object[]> getMethodParams(String invokeTarget) &#123; String methodStr = StringUtils.substringBetween(invokeTarget, \"(\", \")\"); if (StringUtils.isEmpty(methodStr)) &#123; return null; &#125; String[] methodParams = methodStr.split(\",(?=([^\\\"']*[\\\"'][^\\\"']*[\\\"'])*[^\\\"']*$)\"); List&lt;Object[]> clazz = new LinkedList&lt;>(); for (String methodParam : methodParams) &#123; String str = StringUtils.trimToEmpty(methodParam); // String字符串类型，以'或\"开头 if (StringUtils.startsWithAny(str, \"'\", \"\\\"\")) &#123; clazz.add(new Object[]&#123;StringUtils.substring(str, 1, str.length() - 1), String.class&#125;); &#125; // boolean布尔类型，等于true或者false else if (\"true\".equalsIgnoreCase(str) || \"false\".equalsIgnoreCase(str)) &#123; clazz.add(new Object[]&#123;Boolean.valueOf(str), Boolean.class&#125;); &#125; // long长整形，以L结尾 else if (StringUtils.endsWith(str, \"L\")) &#123; clazz.add(new Object[]&#123;Long.valueOf(StringUtils.substring(str, 0, str.length() - 1)), Long.class&#125;); &#125; // double浮点类型，以D结尾 else if (StringUtils.endsWith(str, \"D\")) &#123; clazz.add(new Object[]&#123;Double.valueOf(StringUtils.substring(str, 0, str.length() - 1)), Double.class&#125;); &#125; // 其他类型归类为整形 else &#123; clazz.add(new Object[]&#123;Integer.valueOf(str), Integer.class&#125;); &#125; &#125; return clazz; &#125; /** * 获取参数类型 * * @param methodParams 参数相关列表 * @return 参数类型列表 */ public static Class&lt;?>[] getMethodParamsType(List&lt;Object[]> methodParams) &#123; Class&lt;?>[] clazz = new Class&lt;?>[methodParams.size()]; int index = 0; for (Object[] os : methodParams) &#123; clazz[index] = (Class&lt;?>) os[1]; index++; &#125; return clazz; &#125; /** * 获取参数值 * * @param methodParams 参数相关列表 * @return 参数值列表 */ public static Object[] getMethodParamsValue(List&lt;Object[]> methodParams) &#123; Object[] clazz = new Object[methodParams.size()]; int index = 0; for (Object[] os : methodParams) &#123; clazz[index] = os[0]; index++; &#125; return clazz; &#125; &#125; cron表达式工具类 /** * cron表达式工具类 */ public class CronUtils &#123; /** * 返回一个布尔值代表一个给定的Cron表达式的有效性 * * @param cronExpression Cron表达式 * @return boolean 表达式是否有效 */ public static boolean isValid(String cronExpression) &#123; return CronExpression.isValidExpression(cronExpression); &#125; /** * 返回下一个执行时间根据给定的Cron表达式 * * @param cronExpression Cron表达式 * @return Date 下次Cron表达式执行时间 */ public static Date getNextExecution(String cronExpression) &#123; try &#123; CronExpression cron = new CronExpression(cronExpression); return cron.getNextValidTimeAfter(new Date(System.currentTimeMillis())); &#125; catch (ParseException e) &#123; throw new IllegalArgumentException(e.getMessage()); &#125; &#125; &#125; 定时任务的配置与实现基本配置1.创建抽象类：AbstractQuartzJob public abstract class AbstractQuartzJob implements Job &#123; private static final Logger log = LoggerFactory.getLogger(AbstractQuartzJob.class); //线程本地变量 用于存储执行开始时间 private static ThreadLocal&lt;Date> threadLocal = new ThreadLocal&lt;>(); @Override public void execute(JobExecutionContext context) &#123; Task task = new Task(); BeanUtils.copyProperties(context.getMergedJobDataMap().get(ScheduleConstant.TASK_PROPERTIES), task); try &#123; before(context, task); doExecute(context, task); after(context, task, null); &#125; catch (Exception e) &#123; log.error(\"任务执行异常 - ：\", e); after(context, task, e); &#125; &#125; /** * 执行后 * * @param context 工作执行上下文对象 * @param task 系统计划任务 */ private void after(JobExecutionContext context, Task task, Exception e) &#123; //获取任务开始时间 Date startTime = threadLocal.get(); threadLocal.remove(); //记录任务日志 final TaskLog taskLog = new TaskLog(); taskLog.setTaskName(task.getTaskName()); taskLog.setTaskGroup(task.getTaskGroup()); taskLog.setInvokeTarget(task.getInvokeTarget()); long runTime = new Date().getTime() - startTime.getTime(); taskLog.setTaskMessage(taskLog.getTaskName() + \" 总共耗时：\" + runTime + \"毫秒\"); //处理异常情况 if (e != null) &#123; taskLog.setStatus(FALSE); //截取异常信息 String errorMsg = StringUtils.substring(e.getMessage(), 0, 2000); taskLog.setErrorInfo(errorMsg); &#125; else &#123; //正常情况 taskLog.setStatus(TRUE); &#125; // 写入数据库当中 SpringUtils.getBean(TaskLogMapper.class).insert(taskLog); &#125; /** * 执行方法，由子类重载 * * @param context 工作执行上下文对象 * @param task 系统计划任务 * @throws Exception 执行过程中的异常 */ protected abstract void doExecute(JobExecutionContext context, Task task) throws Exception; /** * 执行前 * * @param context 工作执行上下文对象 * @param task 系统计划任务 */ private void before(JobExecutionContext context, Task task) &#123; threadLocal.set(new Date()); &#125; &#125; 该抽象类为调用定时任务的模板类，子类通过重载来实现支持并发的任务和默认的任务（非并发）。 其中下列的before()方法用于记录任务开始的执行时间并存入线程局部变量中。 after()方法用来记录任务的执行日志。 /** * 执行前 * * @param context 工作执行上下文对象 * @param task 系统计划任务 */ private void before(JobExecutionContext context, Task task) &#123; ... &#125; /** * 执行后 * * @param context 工作执行上下文对象 * @param task 系统计划任务 */ private void after(JobExecutionContext context, Task task, Exception e) &#123; ... &#125; 抽象类AbstractQuartzJob的实现类 /** * 定时任务处理（禁止并发执行） */ @DisallowConcurrentExecution public class QuartzDisallowConcurrentExecution extends AbstractQuartzJob &#123; @Override protected void doExecute(JobExecutionContext context, Task task) throws Exception &#123; TaskInvokeUtils.invokeMethod(task); &#125; &#125; /** * 定时任务处理（允许并发执行） */ public class QuartzJobExecution extends AbstractQuartzJob &#123; @Override protected void doExecute(JobExecutionContext context, Task task) throws Exception &#123; TaskInvokeUtils.invokeMethod(task); &#125; &#125; 创建执行定时任务类：TimedTask,其中clear用于清除博客访问记录，clearVistiLog()用于 清除一周前的访问日志，clear() 用于执行测试任务。 /** * 执行定时任务 */ @SuppressWarnings(value = \"all\") @Component(\"timedTask\") public class TimedTask &#123; @Autowired private RedisService redisService; @Autowired private VisitLogMapper visitLogMapper; /** * 清除博客访问记录 */ public void clear() &#123; redisService.deleteObject(UNIQUE_VISITOR); &#125; /** * 测试任务 */ public void test() &#123; System.out.println(\"测试任务\"); &#125; /** * 清除一周前的访问日志 */ public void clearVistiLog() &#123; DateTime endTime = DateUtil.beginOfDay(DateUtil.offsetDay(new Date(), -7)); visitLogMapper.deleteVisitLog(endTime); &#125; &#125; 至此只需要实现定时任务的调用即可。由于该项目定时任务技术动态配置和接口接口调用，因此使用手动调用接口实现。 重点1.创建定时任务与调度器 Scheduler 通过查找t_task表查询所有任务 通过ScheduleUtils.createScheduleJob(scheduler, task)创建定时任务 @Autowired private Scheduler scheduler; @Autowired private TaskMapper taskMapper; /** * 项目启动时，初始化定时器 主要是防止手动修改数据库导致未同步到定时任务处理 * 注：不能手动修改数据库ID和任务组名，否则会导致脏数据 */ @PostConstruct public void init() throws SchedulerException &#123; scheduler.clear(); List&lt;Task> taskList = taskMapper.selectList(null); for (Task task : taskList) &#123; // 创建定时任务 ScheduleUtils.createScheduleJob(scheduler, task); &#125; &#125; 2.创建JobDetail实例与构建Trigger实例 public static void createScheduleJob(Scheduler scheduler, Task task) &#123; try &#123; Class&lt;? extends Job> jobClass = getQuartzJobClass(task); // 构建task信息 Integer taskId = task.getId(); String taskGroup = task.getTaskGroup(); JobDetail jobDetail = JobBuilder.newJob(jobClass).withIdentity(getJobKey(taskId, taskGroup)).build(); // 表达式调度构建器 CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(task.getCronExpression()); cronScheduleBuilder = handleCronScheduleMisfirePolicy(task, cronScheduleBuilder); // 按新的cronExpression表达式构建一个新的trigger CronTrigger trigger = TriggerBuilder.newTrigger().withIdentity(getTriggerKey(taskId, taskGroup)) .withSchedule(cronScheduleBuilder).build(); // 放入参数，运行时的方法可以获取 jobDetail.getJobDataMap().put(ScheduleConstant.TASK_PROPERTIES, task); // 判断是否存在 if (scheduler.checkExists(getJobKey(taskId, taskGroup))) &#123; // 防止创建时存在数据问题 先移除，然后在执行创建操作 scheduler.deleteJob(getJobKey(taskId, taskGroup)); &#125; scheduler.scheduleJob(jobDetail, trigger); // 暂停任务 if (task.getStatus().equals(TaskStatusEnum.PAUSE.getStatus())) &#123; scheduler.pauseJob(ScheduleUtils.getJobKey(taskId, taskGroup)); &#125; &#125; catch (ServiceException | SchedulerException e) &#123; throw new ServiceException(e.getMessage()); &#125; &#125; 3.执行，开启调度器 public void runTask(TaskRunDTO taskRun) &#123; Integer taskId = taskRun.getId(); String taskGroup = taskRun.getTaskGroup(); // 查询定时任务 Task task = taskMapper.selectById(taskRun.getId()); // 设置参数 JobDataMap dataMap = new JobDataMap(); dataMap.put(ScheduleConstant.TASK_PROPERTIES, task); try &#123; scheduler.triggerJob(ScheduleUtils.getJobKey(taskId, taskGroup), dataMap); &#125; catch (SchedulerException e) &#123; throw new ServiceException(\"执行定时任务异常\"); &#125; &#125; 业务层服务类ITaskService public interface ITaskService extends IService&lt;Task> &#123; /** * 查看定时任务列表 * * @param condition 条件 * @return 定时任务列表 */ PageResult&lt;TaskBackVO> listTaskBackVO(ConditionDTO condition); /** * 添加定时任务 * * @param task 定时任务 */ void addTask(TaskDTO task); /** * 修改定时任务 * * @param task 定时任务信息 */ void updateTask(TaskDTO task); /** * 删除定时任务 * * @param taskIdList 定时任务id集合 */ void deleteTask(List&lt;Integer> taskIdList); /** * 修改定时任务状态 * * @param taskStatus 定时任务状态 */ void updateTaskStatus(StatusDTO taskStatus); /** * 定时任务立即执行一次 * * @param taskRun 定时任务 */ void runTask(TaskRunDTO taskRun); &#125; 业务层实现实现类TaskServiceImpl @Service public class TaskServiceImpl extends ServiceImpl&lt;TaskMapper, Task> implements ITaskService &#123; @Autowired private Scheduler scheduler; @Autowired private TaskMapper taskMapper; /** * 项目启动时，初始化定时器 主要是防止手动修改数据库导致未同步到定时任务处理 * 注：不能手动修改数据库ID和任务组名，否则会导致脏数据 */ @PostConstruct public void init() throws SchedulerException &#123; scheduler.clear(); List&lt;Task> taskList = taskMapper.selectList(null); for (Task task : taskList) &#123; // 创建定时任务 ScheduleUtils.createScheduleJob(scheduler, task); &#125; &#125; @Override public PageResult&lt;TaskBackVO> listTaskBackVO(ConditionDTO condition) &#123; // 查询定时任务数量 Long count = taskMapper.countTaskBackVO(condition); if (count == 0) &#123; return new PageResult&lt;>(); &#125; // 分页查询定时任务列表 List&lt;TaskBackVO> taskBackVOList = taskMapper.selectTaskBackVO(PageUtils.getLimit(), PageUtils.getSize(), condition); taskBackVOList.forEach(item -> &#123; if (StringUtils.isNotEmpty(item.getCronExpression())) &#123; Date nextExecution = CronUtils.getNextExecution(item.getCronExpression()); item.setNextValidTime(nextExecution); &#125; else &#123; item.setNextValidTime(null); &#125; &#125;); return new PageResult&lt;>(taskBackVOList, count); &#125; @Override public void addTask(TaskDTO task) &#123; Assert.isTrue(CronUtils.isValid(task.getCronExpression()), \"Cron表达式无效\"); Task newTask = BeanCopyUtils.copyBean(task, Task.class); // 新增定时任务 int row = taskMapper.insert(newTask); // 创建定时任务 if (row > 0) &#123; ScheduleUtils.createScheduleJob(scheduler, newTask); &#125; &#125; @Override public void updateTask(TaskDTO task) &#123; Assert.isTrue(CronUtils.isValid(task.getCronExpression()), \"Cron表达式无效\"); Task existTask = taskMapper.selectById(task.getId()); Task newTask = BeanCopyUtils.copyBean(task, Task.class); // 更新定时任务 int row = taskMapper.updateById(newTask); if (row > 0) &#123; try &#123; updateSchedulerJob(newTask, existTask.getTaskGroup()); &#125; catch (SchedulerException e) &#123; throw new ServiceException(\"更新定时任务异常\"); &#125; &#125; &#125; @Override public void deleteTask(List&lt;Integer> taskIdList) &#123; List&lt;Task> taskList = taskMapper.selectList(new LambdaQueryWrapper&lt;Task>().select(Task::getId, Task::getTaskGroup).in(Task::getId, taskIdList)); // 删除定时任务 int row = taskMapper.delete(new LambdaQueryWrapper&lt;Task>().in(Task::getId, taskIdList)); if (row > 0) &#123; taskList.forEach(task -> &#123; try &#123; scheduler.deleteJob(ScheduleUtils.getJobKey(task.getId(), task.getTaskGroup())); &#125; catch (SchedulerException e) &#123; throw new ServiceException(\"删除定时任务异常\"); &#125; &#125;); &#125; &#125; @Override public void updateTaskStatus(StatusDTO taskStatus) &#123; Task task = taskMapper.selectById(taskStatus.getId()); // 相同不用更新 if (task.getStatus().equals(taskStatus.getStatus())) &#123; return; &#125; // 更新数据库中的定时任务状态 Task newTask = Task.builder().id(taskStatus.getId()).status(taskStatus.getStatus()).build(); int row = taskMapper.updateById(newTask); // 获取定时任务状态、id、任务组 Integer status = taskStatus.getStatus(); Integer taskId = task.getId(); String taskGroup = task.getTaskGroup(); if (row > 0) &#123; // 更新定时任务 try &#123; if (TaskStatusEnum.RUNNING.getStatus().equals(status)) &#123; scheduler.resumeJob(ScheduleUtils.getJobKey(taskId, taskGroup)); &#125; if (TaskStatusEnum.PAUSE.getStatus().equals(status)) &#123; scheduler.pauseJob(ScheduleUtils.getJobKey(taskId, taskGroup)); &#125; &#125; catch (SchedulerException e) &#123; throw new ServiceException(\"更新定时任务状态异常\"); &#125; &#125; &#125; @Override public void runTask(TaskRunDTO taskRun) &#123; Integer taskId = taskRun.getId(); String taskGroup = taskRun.getTaskGroup(); // 查询定时任务 Task task = taskMapper.selectById(taskRun.getId()); // 设置参数 JobDataMap dataMap = new JobDataMap(); dataMap.put(ScheduleConstant.TASK_PROPERTIES, task); try &#123; scheduler.triggerJob(ScheduleUtils.getJobKey(taskId, taskGroup), dataMap); &#125; catch (SchedulerException e) &#123; throw new ServiceException(\"执行定时任务异常\"); &#125; &#125; /** * 更新任务 * * @param task 任务对象 * @param taskGroup 任务组名 */ public void updateSchedulerJob(Task task, String taskGroup) throws SchedulerException &#123; Integer taskId = task.getId(); // 判断是否存在 JobKey jobKey = ScheduleUtils.getJobKey(taskId, taskGroup); if (scheduler.checkExists(jobKey)) &#123; // 防止创建时存在数据问题 先移除，然后在执行创建操作 scheduler.deleteJob(jobKey); &#125; ScheduleUtils.createScheduleJob(scheduler, task); &#125; &#125; 接口层创建定时任务接口TaskController。 @Api(tags = \"定时任务模块\") @RestController public class TaskController &#123; @Autowired private ITaskService taskService; /** * 查看定时任务列表 * * @param condition 条件 * @return &#123;@link TaskBackVO&#125; 定时任务列表 */ @ApiOperation(\"查看定时任务列表\") @SaCheckPermission(\"monitor:task:list\") @GetMapping(\"/admin/task/list\") public Result&lt;PageResult&lt;TaskBackVO>> listTaskBackVO(ConditionDTO condition) &#123; return Result.success(taskService.listTaskBackVO(condition)); &#125; /** * 添加定时任务 * * @param task 定时任务信息 * @return &#123;@link Result&lt;>&#125; */ @OptLogger(value = ADD) @ApiOperation(\"添加定时任务\") @SaCheckPermission(\"monitor:task:add\") @PostMapping(\"/admin/task/add\") public Result&lt;?> addTask(@Validated @RequestBody TaskDTO task) &#123; taskService.addTask(task); return Result.success(); &#125; /** * 修改定时任务 * * @param task 定时任务信息 * @return &#123;@link Result&lt;>&#125; */ @OptLogger(value = UPDATE) @ApiOperation(\"修改定时任务\") @SaCheckPermission(value = \"monitor:task:update\") @PutMapping(\"/admin/task/update\") public Result&lt;?> updateTask(@Validated @RequestBody TaskDTO task) &#123; taskService.updateTask(task); return Result.success(); &#125; /** * 删除定时任务 * * @param taskIdList 定时任务id集合 * @return &#123;@link Result&lt;>&#125; */ @OptLogger(value = DELETE) @ApiOperation(\"删除定时任务\") @SaCheckPermission(\"monitor:task:delete\") @DeleteMapping(\"/admin/task/delete\") public Result&lt;?> deleteTask(@RequestBody List&lt;Integer> taskIdList) &#123; taskService.deleteTask(taskIdList); return Result.success(); &#125; /** * 修改定时任务状态 * * @param taskStatus 定时任务状态 * @return &#123;@link Result&lt;>&#125; */ @OptLogger(value = UPDATE) @ApiOperation(\"修改定时任务状态\") @SaCheckPermission(value = &#123;\"monitor:task:update\", \"monitor:task:status\"&#125;, mode = SaMode.OR) @PutMapping(\"/admin/task/changeStatus\") public Result&lt;?> updateTaskStatus(@Validated @RequestBody StatusDTO taskStatus) &#123; taskService.updateTaskStatus(taskStatus); return Result.success(); &#125; /** * 执行定时任务 * * @param taskRun 运行定时任务 * @return &#123;@link Result&lt;>&#125; */ @OptLogger(value = UPDATE) @ApiOperation(\"执行定时任务\") @SaCheckPermission(\"monitor:task:run\") @PutMapping(\"/admin/task/run\") public Result&lt;?> runTask(@RequestBody TaskRunDTO taskRun) &#123; taskService.runTask(taskRun); return Result.success(); &#125; &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"https://blog.ehzyil.xyz/tags/Quartz/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"}],"author":"ehzyil"},{"title":"Git常用操作","slug":"2023/Git常用操作","date":"2023-10-15T18:19:34.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/10/15/2023/Git常用操作/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/15/2023/Git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Git拉取远程分支到本地以https://github.com/houqingying/ChatViewer/tree/main该仓库为例，拉取frontend分支的代码到ChatViewer-frontend文件夹 步骤： 1、新建一个空文件，文件名为ChatViewer-frontend 2、初始化 git init ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-frontend $ git init Initialized empty Git repository in D:/Study/Java/Code/ChatViewer/ChatViewer-frontend/.git/ 3、自己要与origin master建立连接（下划线为远程仓库链接） git remote add origin &#x67;&#x69;&#116;&#64;&#103;&#x69;&#116;&#104;&#117;&#98;&#46;&#99;&#111;&#x6d;:XXXX&#x2F;xxx.git 远程仓库链接在这里，如下图红色框内所示的链接： 输入命令： 4、把远程分支拉到本地 git fetch origin frontend（frontend为远程仓库的分支名） 下图的Branches界面下的均为可使用的分支名 下面拉取远程的frontend分支，命令： ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-frontend (master) $ git remote add origin git@github.com:houqingying/ChatViewer.git ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-frontend (master) $ git fetch origin frontend remote: Enumerating objects: 373, done. remote: Counting objects: 100% (373/373), done. remote: Compressing objects: 100% (331/331), done. remote: Total 373 (delta 26), reused 358 (delta 21), pack-reused 0 Receiving objects: 100% (373/373), 2.66 MiB | 1.04 MiB/s, done. Resolving deltas: 100% (26/26), done. From github.com:houqingying/ChatViewer * branch frontend -> FETCH_HEAD * [new branch] frontend -> origin/frontend 5、切换到该分支 git checkout origin&#x2F;frontend(远程分支名称) 命令： ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-frontend (master) $ git checkout origin/frontend Note: switching to 'origin/frontend'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command. Example: git switch -c &lt;new-branch-name> Or undo this operation with: git switch - Turn off this advice by setting config variable advice.detachedHead to false HEAD is now at f299acd Update README.md ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-frontend ((f299acd...)) $ 可以看到文件夹中已有frontend仓库的文件。 至此，git拉取远程分支到本地已完成。 若需要在本地创建分支并切换到该分支可以执行以下命令(以main分支为例) git checkout -b main(本地新建分支名称) origin&#x2F;main(远程分支名称) ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-admin (master) $ git fetch origin main remote: Enumerating objects: 148, done. remote: Counting objects: 100% (148/148), done. remote: Compressing objects: 100% (121/121), done. remote: Total 148 (delta 23), reused 132 (delta 17), pack-reused 0 Receiving objects: 100% (148/148), 91.02 KiB | 105.00 KiB/s, done. Resolving deltas: 100% (23/23), done. From github.com:houqingying/ChatViewer * branch main -> FETCH_HEAD * [new branch] main -> origin/main ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-admin (master) $ git checkout -b main origin/main Switched to a new branch 'main' branch 'main' set up to track 'origin/main'. ehZyiL@DESKTOP-1H567GC MINGW64 /d/Study/Java/Code/ChatViewer/ChatViewer-admin (main) $ git branch * main 6、拉取远程分支上的最新内容到本地 从远程仓库（origin）的主分支（frontend）拉取最新的代码更新到本地仓库。 git pull origin frontend(远程分支名称) 命令： git pull origin frontend Git提交全部代码 git add . git add xx命令可以将xx文件添加到暂存区，如果有很多改动可以通过 git add -A .来一次添加所有改变的文件。注意 -A 选项后面还有一个句点。 git add -A表示添加所有内容， git add . 表示添加新文件和编辑过的文件不包括删除的文件; git add -u 表示添加编辑或者删除的文件，不包括新添加的文件 git commit -m “提交注释” git push origin 分支名称，一般使用：git push origin master Git删除分支// 删除本地分支 git branch -d localBranchName // 删除远程分支 git push origin --delete remoteBranchName Git 操作——如何删除本地分支和远程分支 Git 如何退出merging如果你想在合并时退出，你可以使用 git merge --abort 来取消合并操作。这会使 Git 回到未合并之前的状态。如果您已经提交了合并，那么可以使用 git reset --hard HEAD 来撤销合并。这将丢弃合并的提交，并回滚到未合并之前的状态。 使用idea 把一个git分支的部分提交记录合并到另一个git分支上 Git cherry-pick合并特定的提交git cherry-pick [&lt;options>] &lt;commit-ish>... 常用options: --quit 退出当前的chery-pick序列 --continue 继续当前的chery-pick序列 --abort 取消当前的chery-pick序列，恢复当前分支 -n, --no-commit 不自动提交 -e, --edit 编辑提交信息 git cherry-pick的使用","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.ehzyil.xyz/tags/git/"}],"author":"ehzyil"},{"title":"Quartz 使用教程","slug":"2023/Quartz使用教程","date":"2023-10-15T00:00:00.000Z","updated":"2024-01-06T04:54:46.199Z","comments":true,"path":"2023/10/15/2023/Quartz使用教程/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/15/2023/Quartz%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"Quartz 介绍Quartz 是目前 Java 领域应用最为广泛的任务调度框架之一，目前很多流行的分布式调度框架，例如 xxl-job 都是基于它衍生出来的，所以了解和掌握 Quartz 的使用，对于平时完成一些需要定时调度的工作会有帮助。 Quartz类似于java.util.Timer。但是相较于Timer， Quartz增加了很多功能： 持久性作业 - 就是保持调度定时的状态; 作业管理 - 对调度作业进行有效的管理; 官方文档： http://www.quartz-scheduler.org/documentation/ http://www.quartz-scheduler.org/ap 快速开始我们通过一个最简单的示例，先快速上手 Quartz 最基本的用法，然后再逐步讲解 Quartz 每个模块的功能点 第一步：添加依赖在 pom.xml 文件添加 Quart 依赖： &lt;!-- 引入 quartz 基础依赖：可取当前最新版本 --> &lt;dependency> &lt;groupId>org.quartz-scheduler&lt;/groupId> &lt;artifactId>quartz&lt;/artifactId> &lt;version>2.3.2&lt;/version> &lt;/dependency> &lt;!-- 引入 quartz 所需的日志依赖：可取当前最新版本 --> &lt;dependency> &lt;groupId>org.slf4j&lt;/groupId> &lt;artifactId>slf4j-api&lt;/artifactId> &lt;version>1.7.26&lt;/version> &lt;scope>compile&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.slf4j&lt;/groupId> &lt;artifactId>slf4j-simple&lt;/artifactId> &lt;version>1.7.26&lt;/version> &lt;scope>compile&lt;/scope> &lt;/dependency> 在SpringBoot项目中只需引入spring-boot-starter-quartz即可 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-quartz&lt;/artifactId> &lt;/dependency> 第二步：配置文件在项目的 classpath 路径下创建 Quartz 默认的 quartz.properties 配置文件，它看起来像这样： # 调度程序的名称 org.quartz.scheduler.instanceName = MyScheduler # 线程数量 org.quartz.threadPool.threadCount = 3 # 内存数据库（推荐刚上手时使用） org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore 第三步：定义任务类实现 Job 接口，然后在覆盖的 execute 函数内定义任务逻辑，如下： package com.ehzyil.quartzStudy.test; import org.quartz.Job; import org.quartz.JobExecutionContext; public class HelloJob implements Job &#123; @Override public void execute(JobExecutionContext context) &#123; System.out.println(\"hello quartz!\"); &#125; &#125; 第四步：任务调度我们简单的使用 main() 方法即可运行 Quartz 任务调度示例： package com.ehzyil.quartzStudy.test; import org.quartz.*; import org.quartz.impl.StdSchedulerFactory; public class QuartzTest &#123; public static void main(String[] args) &#123; try &#123; // 获取默认的调度器实例 Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); // 打开调度器 scheduler.start(); // 定义一个简单的任务 JobDetail job = JobBuilder.newJob(HelloJob.class) .withIdentity(\"job11\", \"group1\") .build(); // 定义一个简单的触发器: 每隔 1 秒执行 1 次，任务永不停止 SimpleTrigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"trigger1\", \"group1\") .startNow() .withSchedule(SimpleScheduleBuilder .simpleSchedule() .withIntervalInSeconds(1) .repeatForever() ).build(); // 开始调度任务 scheduler.scheduleJob(job, trigger); // 等待任务执行一些时间 Thread.sleep(3000); // 关闭调度器 scheduler.shutdown(); &#125; catch (Exception se) &#123; se.printStackTrace(); &#125; &#125; &#125; 最后控制台会输出任务运行的全过程，然后关闭进程，如下： 21:54:58.178 [main] INFO org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor 21:54:58.182 [main] INFO org.quartz.simpl.SimpleThreadPool - Job execution threads will use class loader of thread: main 21:54:58.194 [main] INFO org.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl 21:54:58.194 [main] INFO org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.2 created. 21:54:58.198 [main] INFO org.quartz.simpl.RAMJobStore - RAMJobStore initialized. 21:54:58.198 [main] INFO org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED' Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally. NOT STARTED. Currently in standby mode. Number of jobs executed: 0 Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads. Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered. 21:54:58.198 [main] INFO org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties' 21:54:58.198 [main] INFO org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.2 21:54:58.198 [main] INFO org.quartz.core.QuartzScheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started. 21:54:58.198 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 0 triggers 21:54:58.238 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers 21:54:58.238 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'group1.job11', class=com.ehzyil.quartzStudy.test.HelloJob 21:54:58.242 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers 21:54:58.242 [DefaultQuartzScheduler_Worker-1] DEBUG org.quartz.core.JobRunShell - Calling execute on job group1.job11 hello phoenix 21:54:59.203 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'group1.job11', class=com.ehzyil.quartzStudy.test.HelloJob 21:54:59.204 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers 21:54:59.204 [DefaultQuartzScheduler_Worker-2] DEBUG org.quartz.core.JobRunShell - Calling execute on job group1.job11 hello phoenix 21:55:00.209 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'group1.job11', class=com.ehzyil.quartzStudy.test.HelloJob 21:55:00.209 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers 21:55:00.209 [DefaultQuartzScheduler_Worker-3] DEBUG org.quartz.core.JobRunShell - Calling execute on job group1.job11 hello phoenix 21:55:01.213 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'group1.job11', class=com.ehzyil.quartzStudy.test.HelloJob 21:55:01.213 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers 21:55:01.213 [DefaultQuartzScheduler_Worker-4] DEBUG org.quartz.core.JobRunShell - Calling execute on job group1.job11 hello phoenix 21:55:01.243 [main] INFO org.quartz.core.QuartzScheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED shutting down. 21:55:01.243 [main] INFO org.quartz.core.QuartzScheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED paused. 21:55:01.243 [main] DEBUG org.quartz.simpl.SimpleThreadPool - Shutting down threadpool... 21:55:01.243 [main] DEBUG org.quartz.simpl.SimpleThreadPool - Shutdown of threadpool complete. 21:55:01.243 [main] INFO org.quartz.core.QuartzScheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED shutdown complete. 可以看到，到这里一个最基本简单的 Quartz 使用示例基本就 OK 了，接下来介绍更多核心概念和深入使用的场景。 核心概念触发器和作业基本概念掌握 Quartz 之前，先来了解它框架的 3 个核心组件和概念，如下： Schduler：调度器，主要用于管理作业（JobDetail），触发器（Trigger） JobDetail：作业实例，内部包含作业运行的具体逻辑 Trigger：触发器实例，内部包含作业执行的实践计划 主要关系如下： 工作流程如上所示，使用 Quartz 的工作流程也很简单，大致如下： 首先基于 Job 接口定义你的作业 JobDetail 实例和触发器 Trigger 实例对象 将定义的作业和触发器实例对象通过调度器 scheduleJob，开始调度执行 调度器启动工作线程开始执行 JobDetail 实例的 execute 方法内容 任务运行时所需信息通过，JobExecutionContext 对象传递到工作线程，也可以在多个工作线程中跨线程传递 示意图： 唯一标识关于创建 JobDetail 作业实例和 Trigger 触发器的几个注意事项： 创建作业和触发器都需要通过（JobKey 和 TriggerKey + Group）组合创建唯一标识 你可以通过唯一标识在 Schduler 中获取作业对象，并且管理和维护他们 引入 Group 标识的目的也是了更好的让你管理作业环境：例如：通过不同的 Group 来区分：【测试作业，生产作业】等 JobDetail 的更多细节通过示例可以看到，定义和使用 Job 都非常简单，但是如果要深入使用，你可能需要了解关于 Job 的更多细节 先看看 Quartz 对于 JobDetail 的处理策略： 每次执行任务都会创建一个新的 JobDetail 实例对象，意味每次执行的 JobDetail 都是新对象，JobDetail 对象也是无状态的 JobDetail 实例对象任务完成后 （execute 方法），调度器 Schduler 会将作业实例对象删除，然后进行垃圾回收 JobDetail 实例之间的状态数据，只能通过 JobExecutionContext（实际上是 JobDataMap） 进行跨作业传递 为什么设计成JobDetail + Job，不直接使用Job？ JobDetail 定义的是任务数据，而真正的执行逻辑是在Job中。 这是因为任务是有可能并发执行，如果Scheduler直接使用Job，就会存在对同一个Job实例并发访问的问题。 而JobDetail &amp; Job 方式，Sheduler每次执行，都会根据JobDetail创建一个新的Job实例，这样就可以 规避并发访问 的问题。 JobDataMapjobDataMap 的使用主要分 2 步： 1：在 execute() 函数内，使用 jobDataMap 获取数据 public class HelloJob implements Job &#123; @Override public void execute(JobExecutionContext context) &#123; // 通过 JobDataMap 对象，可以在作业的执行逻辑中，获取参数 JobDataMap jobDataMap = context.getJobDetail().getJobDataMap(); String name = jobDataMap.getString(\"name\"); System.out.println(\"hello \" + name); &#125; &#125; 2：jobDataMao 添加参数 // 定义作业时，通过 usingJobData 将参数放入 JobDataMap JobDetail job = JobBuilder.newJob(HelloJob.class) .withIdentity(\"job11\", \"group1\") .usingJobData(\"name\", \"phoenix\") .build(); 最后运行效果如下： [main] INFO org.quartz.core.QuartzScheduler - Scheduler MyScheduler_$_NON_CLUSTERED started. hello phoenix [main] INFO org.quartz.core.QuartzScheduler - Scheduler MyScheduler_$_NON_CLUSTERED shutting down. # .... 关于 JobDataMap 的使用，需要关注以下的注意事项： 虽然 JobDataMap 可以传递任意类型的数据，对象的反序列化在版本迭代中容易遇到类版本控制的问题 如果从长远的安全性考虑，尽可能的将 jobDataMap 设置为只允许存放基本类型和字符串（通过 jobStore.useProperties 设置） Quartz 会自动通过 Job 类的 setter 方法和 JobDataMap 主键匹配，帮助你自动注入属性到 Job 类中 并发性和持久化Quartz定时任务默认都是并发执行的，不会等待上一次任务执行完毕，只要间隔时间到就会执行, 如果定时任执行太长，会长时间占用资源，导致其它任务堵塞。 Quartz 对于 Job 提供几个注释，合理的使用可以更好的控制 Quartz 的调度行为，具体如下： @DisallowConcurrentExecution：添加到 Job 类中，告诉 Job 防止相同定义的任务并发执行，例如：任务 A 实例未完成任务，则任务 B 实例不会开始执行（Quartz 默认策略是不会等待，启用新线程并发调度） @PersistJobDataAfterExecution：添加到 Job 类中，默认情况下 Job 作业运行逻辑不会影响到 JobDataMap （既每个 JobDetail 拿到的都是初始化的 JobDataMap 内容），开启该注解后，Job 的 execute() 方法完成后，对于 JobDataMap 的更新，将会被持久化到 JobDataMap 中，从而供其他的 JobDetail 使用，这对于任务 B 依赖任务 A 的运行结果的场景下，非常有用，所以强烈建议和 @DisallowConcurrentExecution 注解一起使用，会让任务运行结果更加符合预期 Trigger 的更多细节和 Job 类似，触发器的定义和使用也非常简单，但是如果想充分的利用它来工作，你还需要了解关于触发器的更多细节 在 Quartz 中 Trigger 触发器有很多种类型，但是他们都有几个共同的属性，如下： startTime：触发器首次生效的时间 endTime：触发器失效时间 以上共同属性的值都是 java.util.Date 对象 关于 Trigger 的其他几个概念： Priority 优先权：当调度器遇到多个同时执行的 Trigger 时候，会根据优先权大小排序，然后先后调度 Misfire 错过触发：Trigger 达到触发时间，但因为外部原因无法执行，Trigger 开始计算 Misfire 时间 常见的外部原因有哪些？例如：调度程序被关闭，线程池无可用工作线程等 Calendar 日历（不是 java.util.calendar 对象）：用于排除执行日期非常有用 例如：定义一个每天 9 点执行 Trigger ，但是排除所有法定节假日 示例: Calendar instance = Calendar.getInstance(); Date startTime = instance.getTime(); instance.add(Calendar.MINUTE, 1); Date endTime = instance.getTime(); // 3.构建Trigger实例 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"trigger1\", \"group1\") // 开始时间 .startAt(startTime) // 结束时间 .endAt(endTime) .build(); SimpleTriggerSimpleTrigger 是适用于大多数场景的触发器，它可以指定特定时间，重复间隔，重复次数等简单场景，它主要设定参数如下： 开始时间 结束时间 重复次数 间隔时间 具体的 API 可以参考 Quartz 的 Java Doc 文档，这里就不赘述了 misfire 处理策略： 我们上面说过 Quartz Misfire 的概念，从源码 SimpleScheduleBuilder 类中可以看到 MISFIRE_INSTRUCTION_SMART_POLICY 是默认的触发策略，但是也我们也可以在创建 Trigger 时候设置我们期望的错过触发策略，如下： SimpleTrigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"trigger1\", \"group1\") .withSchedule(SimpleScheduleBuilder .simpleSchedule() .withIntervalInSeconds(1) .repeatForever() // misfireInstruction = SimpleTrigger.MISFIRE_INSTRUCTION_FIRE_NOW; .withMisfireHandlingInstructionFireNow() ).build(); 在 SimpleTrigger 类中的常量可以看到所有错过触发（misfire）处理逻辑： MISFIRE_INSTRUCTION_FIRE_NOW MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNT MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_REMAINING_REPEAT_COUNT MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNT MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_EXISTING_COUNT 关于 misfire 的具体的行为，可以查阅 Quartz 的 Java Doc 文档 CronTrigger相比 SimpleTrigger 可以指定更为复杂的执行计划，CRON 是来自 UNIX 基于时间的任务管理系统，相关内容就不再展开，可以参阅 Cron - (wikipedia.org) 文档进一步了解， Cron 也有类似 SimpleTrigger 的相同属性，设置效果如下： startTime：触发器首次生效的时间 endTime：触发器失效时间 看看 CronTrigger 的使用示例： CronTrigger cronTrigger = TriggerBuilder.newTrigger() .withIdentity(\"trigger1\", \"group1\") .withSchedule(CronScheduleBuilder .cronSchedule(\"0 0/2 8-17 * * ?\") .withMisfireHandlingInstructionFireAndProceed() ) .build(); scheduler.scheduleJob(job, cronTrigger); 上述代码完成以下几件事情： 创建 Cron 表达式：每天上午 8 点到下午 5 点之间每隔一分钟触发一次 指定 MISFIRE_INSTRUCTION_FIRE_NOW 为 CronTrigger 的处理策略 通过 Schduler 对任务开始进行调度 CronTrigger Misfire 策略定义在 CronTrigger 常量中，可以在 Java Doc 文档中查看其具体的行为 Cron 表达式在线生成，反解析的工具：http://www.matools.com/cron Linstener 监听器JobStore 作业存储集群模式配置集群注意事项SpringBoot集成QuartzQuartz 整合 Springboot 非常普遍的场景，整合 Spring 可以带来好处： 更加简洁的配置，开箱即用 和 Spring 的 IOC 容器融合，使用更便捷 添加依赖可以在现有项目上添加 springboot 官方提供的 starter-quartz 依赖，如下： &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-quartz&lt;/artifactId> &lt;/dependency> 因为后面需要写接口测试，因此还需添加 SpringBoot关于web的依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> 启动 Springboot 会发现，无需任何配置就已经整合 Quartz 模块了： 2023-10-15 22:02:04.654 INFO 20840 --- [ main] org.quartz.impl.StdSchedulerFactory : Quartz scheduler &#39;quartzScheduler&#39; initialized from an externally provided properties instance. 2023-10-15 22:02:04.654 INFO 20840 --- [ main] org.quartz.impl.StdSchedulerFactory : Quartz scheduler version: 2.3.2 2023-10-15 22:02:04.654 INFO 20840 --- [ main] org.quartz.core.QuartzScheduler : JobFactory set to: org.springframework.scheduling.quartz.SpringBeanJobFactory@4dc8caa7 2023-10-15 22:02:04.686 INFO 20840 --- [ main] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now 2023-10-15 22:02:04.686 INFO 20840 --- [ main] org.quartz.core.QuartzScheduler : Scheduler quartzScheduler_$_NON_CLUSTERED started. 2023-10-15 22:02:04.694 INFO 20840 --- [ main] c.e.quartzStudy.QuartzStudyApplication : Started QuartzStudyApplication in 0.768 seconds (JVM running for 1.504) 使用示例现在基于整合模式实现刚才的 Demo 示例，首先定义任务，这里不再是实现 Job 类： public class HelloJob extends QuartzJobBean &#123; @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; JobDataMap jobDataMap = context.getJobDetail().getJobDataMap(); String name = jobDataMap.getString(\"name\"); System.out.println(\"Hello :\" + name); &#125; &#125; 这里实现由 Springboot 提供的 QuartzJobBean，实现 executerInternal() 方法，这是一个经过 Spring 容器包装后的任务类，可以在任务类使用 Spring 容器的实例 在 Demo 示例里面，我们调度启动都是在 Main 方法启动，在本地测试没有问题，但在生产环境就不建议了，和 springboot 整合后关于任务执行，现在可以有 2 中选项： 在控制层 Controller 提供接口，手动接收任务指定 监听 Spring 容器，在容器启动后，自动加载任务，并且注册为 Bean 手动执行我们先看看第一种实现方式，我们创建控制器，然后接收参数，创建任务，如下： @RestController public class HelloController &#123; @Autowired private Scheduler scheduler; @GetMapping(\"/hello\") public void helloJob(String name) throws SchedulerException &#123; // 定义一个的任务 JobDetail job = JobBuilder.newJob(HelloJob.class) .withIdentity(\"job11\", \"group1\") .usingJobData(\"name\", name) .build(); // 定义一个简单的触发器: 每隔 1 秒执行 1 次，任务永不停止 SimpleTrigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"trigger1\", \"group1\") .withSchedule(SimpleScheduleBuilder .simpleSchedule() .withIntervalInSeconds(1) .repeatForever() ).build(); // 开始调度 scheduler.scheduleJob(job, trigger); &#125; &#125; 然后启动服务器，使用http-request访问接口传入参数： GET http://localhost:8080/hello?name=phoenix 然后控制台会输出： 2023-10-15 22:15:38.623 INFO 8060 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet' 2023-10-15 22:15:38.623 INFO 8060 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet' 2023-10-15 22:15:38.623 INFO 8060 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 0 ms Hello :phoenix Hello :phoenix Hello :phoenix Hello :phoenix .... 自动执行将 JobDetail 注册 Bean，任务就会随 Spring 启动自动触发执行，这对于需要随程序启动执行的作业非常有效，配置如下： 先创建一个配置类： @Configuration public class QuartzConfig &#123; @Bean public JobDetail jobDetail() &#123; JobDetail job = JobBuilder.newJob(HelloJob.class) .withIdentity(\"job11\", \"group1\") .usingJobData(\"name\", \"springboot\") .storeDurably() .build(); return job; &#125; @Bean public Trigger trigger() &#123; SimpleTrigger trigger = TriggerBuilder.newTrigger() .forJob(jobDetail()) .withIdentity(\"trigger1\", \"group1\") .withSchedule(SimpleScheduleBuilder .simpleSchedule() .withIntervalInSeconds(1) .repeatForever() ).build(); return trigger; &#125; &#125; 然后在 springboot 启动后，任务就自动执行： 2023-10-15 22:16:50.481 INFO 21208 --- [ main] c.e.quartzStudy.QuartzStudyApplication : Started QuartzStudyApplication in 1.349 seconds (JVM running for 2.11) Hello :springboot Hello :springboot Hello :springboot ... 工具类 Folding ScheduleUtils 调度工具类 public class ScheduleUtils &#123; /** * 得到quartz任务类 * * @param job 执行计划 * @return 具体执行任务类 */ private static Class&lt;? extends Job> getQuartzJobClass(QuartzJob job) &#123; boolean isConcurrent = \"0\".equals(job.getConcurrent()); return isConcurrent ? QuartzJobExecution.class : QuartzDisallowConcurrentExecution.class; &#125; /** * 构建任务触发对象 */ public static TriggerKey getTriggerKey(Long jobId, String jobGroup) &#123; return TriggerKey.triggerKey(ScheduleConstants.TASK_CLASS_NAME + jobId, jobGroup); &#125; /** * 构建任务键对象 */ public static JobKey getJobKey(Long jobId, String jobGroup) &#123; return JobKey.jobKey(ScheduleConstants.TASK_CLASS_NAME + jobId, jobGroup); &#125; /** * 创建定时任务 */ public static void createScheduleJob(Scheduler scheduler, QuartzJob job) throws Exception &#123; Class&lt;? extends Job> jobClass = getQuartzJobClass(job); // 构建job信息 Long jobId = job.getJobId(); String jobGroup = job.getJobGroup(); JobDetail jobDetail = JobBuilder.newJob(jobClass).withIdentity(getJobKey(jobId, jobGroup)).build(); // 表达式调度构建器 CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(job.getCronExpression()); cronScheduleBuilder = handleCronScheduleMisfirePolicy(job, cronScheduleBuilder); // 按新的cronExpression表达式构建一个新的trigger CronTrigger trigger = TriggerBuilder.newTrigger().withIdentity(getTriggerKey(jobId, jobGroup)) .withSchedule(cronScheduleBuilder).build(); // 放入参数，运行时的方法可以获取 jobDetail.getJobDataMap().put(ScheduleConstants.TASK_PROPERTIES, job); // 判断是否存在 if (scheduler.checkExists(getJobKey(jobId, jobGroup))) &#123; // 防止创建时存在数据问题 先移除，然后在执行创建操作 scheduler.deleteJob(getJobKey(jobId, jobGroup)); &#125; scheduler.scheduleJob(jobDetail, trigger); // 暂停任务 if (job.getStatus().equals(ScheduleConstants.Status.PAUSE.getValue())) &#123; scheduler.pauseJob(ScheduleUtils.getJobKey(jobId, jobGroup)); &#125; &#125; /** * 设置定时任务策略 */ public static CronScheduleBuilder handleCronScheduleMisfirePolicy(QuartzJob job, CronScheduleBuilder cb) throws Exception &#123; switch (job.getMisfirePolicy()) &#123; case ScheduleConstants.MISFIRE_DEFAULT: return cb; case ScheduleConstants.MISFIRE_IGNORE_MISFIRES: return cb.withMisfireHandlingInstructionIgnoreMisfires(); case ScheduleConstants.MISFIRE_FIRE_AND_PROCEED: return cb.withMisfireHandlingInstructionFireAndProceed(); case ScheduleConstants.MISFIRE_DO_NOTHING: return cb.withMisfireHandlingInstructionDoNothing(); default: throw new Exception(\"The task misfire policy '\" + job.getMisfirePolicy() + \"' cannot be used in cron schedule tasks\"); &#125; &#125; &#125; Folding AbstractQuartzJob 抽象任务 public abstract class AbstractQuartzJob implements Job &#123; private static final Logger log = LoggerFactory.getLogger(AbstractQuartzJob.class); /** * 线程本地变量 */ private static ThreadLocal&lt;Date> threadLocal = new ThreadLocal&lt;>(); @Override public void execute(JobExecutionContext context) throws JobExecutionException &#123; QuartzJob job = new QuartzJob(); BeanUtils.copyBeanProp(job, context.getMergedJobDataMap().get(ScheduleConstants.TASK_PROPERTIES)); try &#123; before(context, job); if (job != null) &#123; doExecute(context, job); &#125; after(context, job, null); &#125; catch (Exception e) &#123; log.error(\"任务执行异常 - ：\", e); after(context, job, e); &#125; &#125; /** * 执行前 * * @param context 工作执行上下文对象 * @param job 系统计划任务 */ protected void before(JobExecutionContext context, QuartzJob job) &#123; threadLocal.set(new Date()); &#125; /** * 执行后 * * @param context 工作执行上下文对象 * @param sysJob 系统计划任务 */ protected void after(JobExecutionContext context, QuartzJob sysJob, Exception e) &#123; &#125; /** * 执行方法，由子类重载 * * @param context 工作执行上下文对象 * @param job 系统计划任务 * @throws Exception 执行过程中的异常 */ protected abstract void doExecute(JobExecutionContext context, QuartzJob job) throws Exception; &#125;这个类将原本 execute 方法执行的任务，下放到了子类重载的 doExecute 方法中同时准备实现，分了允许并发和不允许并发，差别就是一个注解public class QuartzJobExecution extends AbstractQuartzJob &#123; @Override protected void doExecute(JobExecutionContext context, QuartzJob job) throws Exception &#123; JobInvokeUtil.invokeMethod(job); &#125; &#125; @DisallowConcurrentExecution public class QuartzDisallowConcurrentExecution extends AbstractQuartzJob &#123; @Override protected void doExecute(JobExecutionContext context, QuartzJob job) throws Exception &#123; JobInvokeUtil.invokeMethod(job); &#125; &#125; Folding JobInvokeUtil :方法调用 最后由 通过反射，进行实际的方法调用public class JobInvokeUtil &#123; /** * 执行方法 * * @param job 系统任务 */ public static void invokeMethod(QuartzJob job) throws Exception &#123; String invokeTarget = job.getInvokeTarget(); String beanName = getBeanName(invokeTarget); String methodName = getMethodName(invokeTarget); List&lt;Object[]> methodParams = getMethodParams(invokeTarget); if (!isValidClassName(beanName)) &#123; Object bean = SpringUtils.getBean(beanName); invokeMethod(bean, methodName, methodParams); &#125; else &#123; Object bean = Class.forName(beanName).newInstance(); invokeMethod(bean, methodName, methodParams); &#125; &#125; /** * 调用任务方法 * * @param bean 目标对象 * @param methodName 方法名称 * @param methodParams 方法参数 */ private static void invokeMethod(Object bean, String methodName, List&lt;Object[]> methodParams) throws NoSuchMethodException, SecurityException, IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123; if (StringUtils.isNotNull(methodParams) &amp;&amp; methodParams.size() > 0) &#123; Method method = bean.getClass().getDeclaredMethod(methodName, getMethodParamsType(methodParams)); method.invoke(bean, getMethodParamsValue(methodParams)); &#125; else &#123; Method method = bean.getClass().getDeclaredMethod(methodName); method.invoke(bean); &#125; &#125; /** * 校验是否为为class包名 * * @param invokeTarget 名称 * @return true是 false否 */ public static boolean isValidClassName(String invokeTarget) &#123; return StringUtils.countMatches(invokeTarget, \".\") > 1; &#125; /** * 获取bean名称 * * @param invokeTarget 目标字符串 * @return bean名称 */ public static String getBeanName(String invokeTarget) &#123; String beanName = StringUtils.substringBefore(invokeTarget, \"(\"); return StringUtils.substringBeforeLast(beanName, \".\"); &#125; /** * 获取bean方法 * * @param invokeTarget 目标字符串 * @return method方法 */ public static String getMethodName(String invokeTarget) &#123; String methodName = StringUtils.substringBefore(invokeTarget, \"(\"); return StringUtils.substringAfterLast(methodName, \".\"); &#125; /** * 获取method方法参数相关列表 * * @param invokeTarget 目标字符串 * @return method方法相关参数列表 */ public static List&lt;Object[]> getMethodParams(String invokeTarget) &#123; String methodStr = StringUtils.substringBetween(invokeTarget, \"(\", \")\"); if (StringUtils.isEmpty(methodStr)) &#123; return null; &#125; String[] methodParams = methodStr.split(\",\"); List&lt;Object[]> classs = new LinkedList&lt;>(); for (int i = 0; i &lt; methodParams.length; i++) &#123; String str = StringUtils.trimToEmpty(methodParams[i]); // String字符串类型，包含' if (StringUtils.contains(str, \"'\")) &#123; classs.add(new Object[]&#123;StringUtils.replace(str, \"'\", \"\"), String.class&#125;); &#125; // boolean布尔类型，等于true或者false else if (StringUtils.equals(str, \"true\") || StringUtils.equalsIgnoreCase(str, \"false\")) &#123; classs.add(new Object[]&#123;Boolean.valueOf(str), Boolean.class&#125;); &#125; // long长整形，包含L else if (StringUtils.containsIgnoreCase(str, \"L\")) &#123; classs.add(new Object[]&#123;Long.valueOf(StringUtils.replaceIgnoreCase(str, \"L\", \"\")), Long.class&#125;); &#125; // double浮点类型，包含D else if (StringUtils.containsIgnoreCase(str, \"D\")) &#123; classs.add(new Object[]&#123;Double.valueOf(StringUtils.replaceIgnoreCase(str, \"D\", \"\")), Double.class&#125;); &#125; // 其他类型归类为整形 else &#123; classs.add(new Object[]&#123;Integer.valueOf(str), Integer.class&#125;); &#125; &#125; return classs; &#125; /** * 获取参数类型 * * @param methodParams 参数相关列表 * @return 参数类型列表 */ public static Class&lt;?>[] getMethodParamsType(List&lt;Object[]> methodParams) &#123; Class&lt;?>[] classs = new Class&lt;?>[methodParams.size()]; int index = 0; for (Object[] os : methodParams) &#123; classs[index] = (Class&lt;?>) os[1]; index++; &#125; return classs; &#125; /** * 获取参数值 * * @param methodParams 参数相关列表 * @return 参数值列表 */ public static Object[] getMethodParamsValue(List&lt;Object[]> methodParams) &#123; Object[] classs = new Object[methodParams.size()]; int index = 0; for (Object[] os : methodParams) &#123; classs[index] = (Object) os[0]; index++; &#125; return classs; &#125; &#125; Folding cron表达式工具类 public class CronUtils &#123; /** * 返回一个布尔值代表一个给定的Cron表达式的有效性 * * @param cronExpression Cron表达式 * @return boolean 表达式是否有效 */ public static boolean isValid(String cronExpression) &#123; return CronExpression.isValidExpression(cronExpression); &#125; /** * 返回下一个执行时间根据给定的Cron表达式 * * @param cronExpression Cron表达式 * @return Date 下次Cron表达式执行时间 */ public static Date getNextExecution(String cronExpression) &#123; try &#123; CronExpression cron = new CronExpression(cronExpression); return cron.getNextValidTimeAfter(new Date(System.currentTimeMillis())); &#125; catch (ParseException e) &#123; throw new IllegalArgumentException(e.getMessage()); &#125; &#125; &#125; 参考文章 [1] Quartz 使用教程 [2] 任务调度框架 Quartz 用法指南「超详细」","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"https://blog.ehzyil.xyz/tags/Quartz/"}],"author":"ehzyil"},{"title":"IntelliJ IDEA创建JSP项目","slug":"2023/IntelliJ IDEA创建JSP项目","date":"2023-10-12T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/10/12/2023/IntelliJ IDEA创建JSP项目/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/12/2023/IntelliJ%20IDEA%E5%88%9B%E5%BB%BAJSP%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"创建项目在IntelliJ IDEA中创建jsp项目的步骤如下: 1.点击”Create New Project” 2.选择“Java Enterprise”并将配置设置为箭头所指内容后点击”Next” 输入项目名称并选择存储位置，选择Web Application，选择要使用的Web框架（若为空，自行去下载Tomcat并配置），选择构建系统，选择JDK版本 3.若不选择其他依赖项默认只有“Servlet”依赖，点击Create创建项目 4.创建后的JSP项目的结构如下： ├─.idea │ ├─artifacts │ └─libraries ├─.mvn │ └─wrapper ├─src │ ├─main │ │ ├─java │ │ │ └─com │ │ │ └─example │ │ │ └─practicaltraining │ │ ├─resources │ │ └─webapp │ │ └─WEB-INF │ └─test │ ├─java │ └─resources └─target ├─classes │ └─com │ └─example │ └─practicaltraining ├─generated-sources │ └─annotations └─practicalTraining-1.0-SNAPSHOT ├─META-INF └─WEB-INF └─classes └─com └─example └─practicaltraining 5.点击”Run”即可运行,项目默认创建的有一个”&#x2F;helloServlet”。项目运行后点击即可响应”Hello Servlet”。 更改默认跳转页面1.进入src-&gt;main-&gt;webapp-&gt;WEB-INF下的web.xml文件。 2.更改添加&lt;welcome-file-list&gt;和 &lt;welcome-file&gt;标签并用 &lt;welcome-file&gt;&lt;/welcome-file&gt;包裹启动后要跳转的页面名，该项目默认跳转的页面为login.jsp。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"> &lt;welcome-file-list> &lt;welcome-file>login.jsp&lt;/welcome-file> &lt;/welcome-file-list> &lt;/web-app>","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"https://blog.ehzyil.xyz/tags/IntelliJ-IDEA/"},{"name":"JSP","slug":"JSP","permalink":"https://blog.ehzyil.xyz/tags/JSP/"}],"author":"ehzyil"},{"title":"刷题","slug":"数据结构与算法/刷题","date":"2023-10-12T00:00:00.000Z","updated":"2024-01-06T04:54:46.219Z","comments":true,"path":"2023/10/12/数据结构与算法/刷题/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/12/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%88%B7%E9%A2%98/","excerpt":"","text":"二分查找 69. x 的平方根 - 力扣（LeetCode） 69. x 的平方根 - 力扣（LeetCode）给你一个非负整数 x ，计算并返回 x 的 算术平方根 。 由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 。 注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 。 示例 1： 输入：x &#x3D; 4 输出：2 示例 2： 输入：x &#x3D; 8 输出：2 解释：8 的算术平方根是 2.82842..., 由于返回类型是整数，小数部分将被舍去。 提示： 0 &lt;= x &lt;= 231 - 1 答案： public int mySqrt(int x) &#123; //处理特殊情况 if (x == 0) &#123; return 0; &#125; if (x == 1) &#123; return 1; &#125; int i = 0, j = x / 2 + 1; //使用平衡版二分法寻找比 中间数平方小的 while (1 &lt; j - i) &#123; int mid = (i + j) >>> 1; //求m的平方时会出现大于int值的情况，此时需要转为long进行计算 if ((long) mid * mid > x) &#123; j = mid; &#125; else &#123; i = mid; &#125; &#125; return i; &#125; E01. 二分查找-力扣 704 题要点：减而治之，可以用递归或非递归实现 给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1 例如 输入: nums = [-1,0,3,5,9,12], target = 9 输出: 4 解释: 9 出现在 nums 中并且下标为 4 输入: nums = [-1,0,3,5,9,12], target = 2 输出: -1 解释: 2 不存在 nums 中因此返回 -1 参考答案：可以用讲过的任意一种二分求解 static int binarySearch(int[] a, int target) &#123; int i = 0, j = a.length; while (1 &lt; j - i) &#123; int mid = (i + j) >>> 1; if (a[mid] &lt; target) &#123; i = mid + 1; &#125; else &#123; j = mid - 1; &#125; &#125; return a[i] == target ? i : -1; &#125; E02. 搜索插入位置-力扣 35 题要点：理解谁代表插入位置 给定一个排序数组和一个目标值 在数组中找到目标值，并返回其索引 如果目标值不存在于数组中，返回它将会被按顺序插入的位置 例如 输入: nums &#x3D; [1,3,5,6], target &#x3D; 5 输出: 2 输入: nums &#x3D; [1,3,5,6], target &#x3D; 2 输出: 1 输入: nums &#x3D; [1,3,5,6], target &#x3D; 7 输出: 4 参考答案1：用二分查找基础版代码改写，基础版中，找到返回 m，没找到 i 代表插入点，因此有 public int searchInsert(int[] a, int target) &#123; int i = 0, j = a.length - 1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; return m; &#125; &#125; return i; // 原始 return -1 &#125; 参考答案2：用二分查找平衡版改写，平衡版中 如果 target &#x3D;&#x3D; a[i] 返回 i 表示找到 如果 target &lt; a[i]，例如 target &#x3D; 2，a[i] &#x3D; 3，这时就应该在 i 位置插入 2 如果 a[i] &lt; target，例如 a[i] &#x3D; 3，target &#x3D; 4，这时就应该在 i+1 位置插入 4 public static int searchInsert(int[] a, int target) &#123; int i = 0, j = a.length; while (1 &lt; j - i) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m; &#125; else &#123; i = m; &#125; &#125; return (target &lt;= a[i]) ? i : i + 1; // 原始 (target == a[i]) ? i : -1; &#125; 参考答案3：用 leftmost 版本解，返回值即为插入位置（并能处理元素重复的情况） public int searchInsert(int[] a, int target) &#123; int i = 0, j = a.length - 1; while(i &lt;= j) &#123; int m = (i + j) >>> 1; if(target &lt;= a[m]) &#123; j = m - 1; &#125; else &#123; i = m + 1; &#125; &#125; return i; &#125; E03. 搜索开始结束位置-力扣 34 题给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。 如果数组中不存在目标值 target，返回 [-1, -1]。 你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题 例如 输入：nums &#x3D; [5,7,7,8,8,10], target &#x3D; 8 输出：[3,4] 输入：nums &#x3D; [5,7,7,8,8,10], target &#x3D; 6 输出：[-1,-1] 输入：nums &#x3D; [], target &#x3D; 0 输出：[-1,-1] 参考答案 public static int left(int[] a, int target) &#123; int i = 0, j = a.length - 1; int candidate = -1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; candidate = m; j = m - 1; &#125; &#125; return candidate; &#125; public static int right(int[] a, int target) &#123; int i = 0, j = a.length - 1; int candidate = -1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; candidate = m; i = m + 1; &#125; &#125; return candidate; &#125; public static int[] searchRange(int[] nums, int target) &#123; int x = left(nums, target); if(x == -1) &#123; return new int[] &#123;-1, -1&#125;; &#125; else &#123; return new int[] &#123;x, right(nums, target)&#125;; &#125; &#125; 递归 - single recursionE03. 二分查找class Solution &#123; public static int recursion(int[] a, int target, int i, int j) &#123; //跳出递归条件 if (i > j) &#123; return -1; &#125; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; return recursion(a, target, i, m - 1); &#125; else if (a[m] &lt; target) &#123; return recursion(a, target, m + 1, j); &#125; else &#123; return m; &#125; &#125; public int search(int[] nums, int target) &#123; return recursion(nums, target, 0, nums.length - 1); &#125; &#125; E04. 冒泡排序public static void main(String[] args) &#123; int[] a = &#123;3, 2, 6, 1, 5, 4, 7&#125;; bubble(a, 0, a.length - 1); System.out.println(Arrays.toString(a)); &#125; /** * 递归冒泡排序 * &lt;ul> * &lt;li>将数组划分成两部分 [0 .. j] [j+1 .. a.length-1]&lt;/li> * &lt;li>左边 [0 .. j] 是未排序部分&lt;/li> * &lt;li>右边 [j+1 .. a.length-1] 是已排序部分&lt;/li> * &lt;li>未排序区间内, 相邻的两个元素比较, 如果前一个大于后一个, 则交换位置&lt;/li> * &lt;/ul> */ private static void bubble(int[] a, int low, int high) &#123; //终止条件 左右边界相等 if (low == high) &#123; return; &#125; //每一轮排序 重置j的值 int j = low; //for循环用来排序 for (int i = low; i &lt; high; i++) &#123; if (a[i] > a[i + 1]) &#123; //满足左比右大 交换顺序 int temp=a[i]; a[i]=a[i+1]; a[i+1]=temp; //j用来记录已排序的右边届 j右边的已排序完成 j=i; &#125; &#125; //递归进入下一轮 bubble(a,low,j); &#125; low 与 high 为排序范围 j 表示的是未排序的边界，下一次递归时的 high 发生交换，意味着有无序情况 最后一次交换（以后没有无序）时，左侧 i 仍是无序，右侧 i+1 已然有序 E05. 插入排序版本v1 public static void main(String[] args) &#123; int[] a = &#123;3, 2, 6, 1, 5, 7, 4&#125;; insertion(a, 1); System.out.println(Arrays.toString(a)); &#125; private static void insertion(int[] a, int low) &#123; // 结束条件 low 是已排序和未排序的边界，当low等于数组长度的时候说明全部排序完成 if (low == a.length) return; // low所指下向的值 int t = a[low]; // 已排序区域指针 int i = low - 1; // 通过循环将符合条件的值右移 i>=0来处理只有一张牌的情况 即i=-1 while (i >= 0 &amp;&amp; a[i] > t) &#123; a[i + 1] = a[i]; // 空出插入位置 i--; &#125; // 找到了插入的位置 // 若i+1==low 说明没有移动 if (i + 1 != low) &#123; a[i + 1] = t; &#125; // 递归 insertion(a, low + 1); &#125; 已排序区域：[0 .. i .. low-1] 未排序区域：[low .. high] 版本v2 public static void main(String[] args) &#123; int[] a = &#123;3, 2, 6, 1, 5, 7, 4&#125;; insertion(a, 1, a.length - 1); System.out.println(Arrays.toString(a)); &#125; private static void insertion(int[] a, int low, int high) &#123; if (low > high) &#123; return; &#125; int t = a[low]; int i = low - 1; while (i >= 0 &amp;&amp; a[i] > t) &#123; a[i + 1] = a[i]; i--; &#125; if(i + 1 != low) &#123; a[i + 1] = t; &#125; insertion(a, low + 1, high); &#125; 第一块代码是只考虑 low 边界的情况，参考以上代码，理解 low-1 .. high 范围内的处理方法 扩展：利用二分查找 leftmost 版本，改进寻找插入位置的代码 版本v3 另一种插入排序的实现,缺点: 赋值次数较多private static void insertion2(int[] a, int low) &#123; if (low == a.length) &#123; return; &#125; int i = low - 1; while (i >= 0 &amp;&amp; a[i] > a[i + 1]) &#123; int t = a[i]; a[i] = a[i + 1]; a[i + 1] = t; i--; &#125; insertion(a, low + 1); &#125; E06. 约瑟夫问题[^16]待完成！！！ 递归 - multi recursionE02. 汉诺塔[^13]Tower of Hanoi，是一个源于印度古老传说：大梵天创建世界时做了三根金刚石柱，在一根柱子从下往上按大小顺序摞着 64 片黄金圆盘，大梵天命令婆罗门把圆盘重新摆放在另一根柱子上，并且规定 一次只能移动一个圆盘 小圆盘上不能放大圆盘 下面的动图演示了4片圆盘的移动方法 使用程序代码模拟圆盘的移动过程，并估算出时间复杂度 思路 假设每根柱子标号 a，b，c，每个圆盘用 1，2，3 … 表示其大小，圆盘初始在 a，要移动到的目标是 c 如果只有一个圆盘，此时是最小问题，可以直接求解 移动圆盘1 $a \\mapsto c$ 如果有两个圆盘，那么 圆盘1 $a \\mapsto b$ 圆盘2 $a \\mapsto c$ 圆盘1 $b \\mapsto c$ 如果有三个圆盘，那么 圆盘12 $a \\mapsto b$ 圆盘3 $a \\mapsto c$ 圆盘12 $b \\mapsto c$ 如果有四个圆盘，那么 圆盘 123 $a \\mapsto b$ 圆盘4 $a \\mapsto c$ 圆盘 123 $b \\mapsto c$ 题解 public class E02HanoiTower &#123; static LinkedList&lt;Integer> a = new LinkedList&lt;>(); static LinkedList&lt;Integer> b = new LinkedList&lt;>(); static LinkedList&lt;Integer> c = new LinkedList&lt;>(); public static void main(String[] args) &#123; StopWatch sw = new StopWatch(); int n = 4; init(n); sw.start(\"n=\"+n); move(n,a,b,c); sw.stop(); print(); System.out.println(sw.prettyPrint()); &#125; /** * &lt;h3>移动圆盘&lt;/h3> * * @param n 圆盘个数 * @param a 由 * @param b 借 * @param c 至 */ static void move(int n, LinkedList&lt;Integer> a, LinkedList&lt;Integer> b, LinkedList&lt;Integer> c) &#123; //终止条件 n==0 if (n == 0) return; //将n-1个从a借助c移动到b move(n - 1, a, c, b); //将最后一个在a的盘子移动到c c.addLast(a.removeLast()); // print(); //将n-1个从b借助a移动到c move(n - 1, b,a, c); &#125; static void init(int n) &#123; for (int i = 1; i &lt;= n; i++) &#123; a.add(i); &#125; &#125; //打印列表 private static void print() &#123; System.out.println(\"******************************\"); System.out.println(a); System.out.println(b); System.out.println(c); &#125; &#125; E03. 杨辉三角[^6] 分析 把它斜着看 1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 1 8 1 1 6 (n-i-1)*2 1 2 1 4 1 3 3 1 2 1 4 6 4 1 0 行 $i$，列 $j$，那么 $[i][j]$ 的取值应为 $[i-1][j-1] + [i-1][j]$ 当 $j&#x3D;0$ 或 $i&#x3D;j$ 时，$[i][j]$ 取值为 $1$ 题解 public static void print(int n) &#123; for (int i = 0; i &lt; n; i++) &#123; //打印字符串 if (i &lt; n - 1) &#123; System.out.printf(\"%\" + 2 * (n - 1 - i) + \"s\", \" \"); &#125; //printSpace((n - i - 1) * 4); for (int j = 0; j &lt; i + 1; j++) &#123; System.out.printf(\"%-4d\", element(i, j)); &#125; //换行 System.out.println(); &#125; &#125; //递归函数 public static int element(int i, int j) &#123; if (j == 0 || i == j) &#123; return 1; &#125; return element(i - 1, j - 1) + element(i - 1, j); &#125; public static void printSpace(int n) &#123; for (int i = 0; i &lt; n; i++) &#123; System.out.print(\" \"); &#125; &#125; 优化 优化1是 multiple recursion，因此很多递归调用是重复的，例如recursion(3, 1) 分解为recursion(2, 0) + recursion(2, 1)而 recursion(3, 2) 分解为recursion(2, 1) + recursion(2, 2)这里 recursion(2, 1) 就重复调用了，事实上它会重复很多次，可以用 static AtomicInteger counter &#x3D; new AtomicInteger(0) 来查看递归函数的调用总次数事实上，可以用 memoization 来进行优化：public static void print1(int n) &#123; int[][] triangle = new int[n][]; for (int i = 0; i &lt; n; i++) &#123; // 打印空格 triangle[i] = new int[i + 1]; for (int j = 0; j &lt;= i; j++) &#123; System.out.printf(\"%-4d\", element1(triangle, i, j)); &#125; System.out.println(); &#125; &#125; public static int element1(int[][] triangle, int i, int j) &#123; if (triangle[i][j] > 0) &#123; return triangle[i][j]; &#125; if (j == 0 || i == j) &#123; triangle[i][j] = 1; return triangle[i][j]; &#125; triangle[i][j] = element1(triangle, i - 1, j - 1) + element1(triangle, i - 1, j); return triangle[i][j]; &#125;将数组作为递归函数内可以访问的遍历，如果 $triangle[i][j]$ 已经有值，说明该元素已经被之前的递归函数计算过，就不必重复计算了优化2public static void print2(int n) &#123; int[] row = new int[n]; for (int i = 0; i &lt; n; i++) &#123; // 打印空格 createRow(row, i); for (int j = 0; j &lt;= i; j++) &#123; System.out.printf(\"%-4d\", row[j]); &#125; System.out.println(); &#125; &#125; private static void createRow(int[] row, int i) &#123; if (i == 0) &#123; row[0] = 1; return; &#125; for (int j = i; j > 0; j--) &#123; row[j] = row[j - 1] + row[j]; &#125; &#125;注意：还可以通过每一行的前一项计算出下一项，不必借助上一行，这与杨辉三角的另一个特性有关，暂不展开了 链表E01. 反转单向链表-力扣 206 题对应力扣题目 206. 反转链表 - 力扣（LeetCode） 输入：head &#x3D; [1,2,3,4,5] 输出：[5,4,3,2,1] 输入：[1,2] 输出：[2,1] 输入：[] 输出：[] 方法1 构造一个新链表，从旧链表依次拿到每个节点，创建新节点添加至新链表头部，完成后新链表即是倒序的 public ListNode reverseList(ListNode o1) &#123; ListNode n1 = null; ListNode p = o1; while (p != null) &#123; //null-> 1->null -> 2,1->null n1 = new ListNode(p.val, n1); p = p.next; &#125; return n1; &#125; 评价：简单直白，就是得新创建节点对象 方法2 与方法1 类似，构造一个新链表，从旧链表头部移除节点，添加到新链表头部，完成后新链表即是倒序的，区别在于原题目未提供节点外层的容器类，这里提供一个，另外一个区别是并不去构造新节点 static class List &#123; ListNode head; public List(ListNode head) &#123; this.head = head; &#125; public ListNode removeFirst()&#123; ListNode first = head; if (first != null) &#123; head = first.next; &#125; return first; &#125; public void addFirst(ListNode first) &#123; first.next = head; head = first; &#125; &#125; 代码 public ListNode reverseList(ListNode head) &#123; List list1 = new List(head); List list2 = new List(null); ListNode first; while ((first = list1.removeFirst()) != null) &#123; list2.addFirst(first); &#125; return list2.head; &#125; 评价：更加面向对象，如果实际写代码而非刷题，更多会这么做 方法3 递归，在归时让 $5 \\rightarrow 4$，$4 \\rightarrow 3$ … 首先，写一个递归方法，返回值用来拿到最后一个节点 public ListNode reverseList(ListNode p) &#123; if (p == null || p.next == null) &#123; // 不足两个节点 return p; // 最后一个节点 &#125; ListNode last = reverseList(p.next); return last; &#125; 注意1：递归终止条件是 curr.next &#x3D;&#x3D; null，目的是到最后一个节点就结束递归，与之前递归遍历不一样 注意2：需要考虑空链表即 p &#x3D;&#x3D; null 的情况 可以先测试一下 ListNode o5 = new ListNode(5, null); ListNode o4 = new ListNode(4, o5); ListNode o3 = new ListNode(3, o4); ListNode o2 = new ListNode(2, o3); ListNode o1 = new ListNode(1, o2); ListNode n1 = new E01Leetcode206().reverseList(o1); System.out.println(n1); 会打印 [5] 下面为伪码调用过程，假设节点分别是 $1 \\rightarrow 2 \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$，先忽略返回值 reverseList(ListNode p = 1) &#123; reverseList(ListNode p = 2) &#123; reverseList(ListNode p = 3) &#123; reverseList(ListNode p = 4) &#123; reverseList(ListNode p = 5) &#123; if (p == null || p.next == null) &#123; return p; // 返回5 &#125; &#125; // 此时p是4, p.next是5 &#125; // 此时p是3, p.next是4 &#125; // 此时p是2, p.next是3 &#125; // 此时p是1, p.next是2 &#125; 接下来，从 p &#x3D; 4 开始，要让 $5 \\rightarrow 4$，$4 \\rightarrow 3$ … reverseList(ListNode p = 1) &#123; reverseList(ListNode p = 2) &#123; reverseList(ListNode p = 3) &#123; reverseList(ListNode p = 4) &#123; reverseList(ListNode p = 5) &#123; if (p == null || p.next == null) &#123; return p; // 返回5 &#125; &#125; // 此时p是4, p.next是5, 此时p.next.next=null,要让5指向4,代码写成 p.next.next=p // 还要注意4要指向 null, 否则就死链了（4&lt;==>5即4.next=5，5.next=4） &#125; // 此时p是3, p.next是4,p.next.next=p 4->3 &#125; // 此时p是2, p.next是3 &#125; // 此时p是1, p.next是2 &#125; 最终代码为： ListNode reverseList(ListNode head) &#123; // 如果链表为空或只有一个节点，则直接返回原链表 if (head == null || head.next == null) &#123; return head; &#125; // 递归调用反转链表方法，将当前节点的下一个节点作为参数传入 ListNode last = reverse(head.next); // 将当前节点的下一个节点的下一个节点指向当前节点，实现反转 head.next.next = head; // 将当前节点的下一个节点设为null，断开原链表与反转后链表的连接 head.next = null; // 返回反转后的链表头节点 return last; &#125; Q：为啥不能在递的过程中倒序？ A：比如 $ 1 \\rightarrow 2 \\rightarrow 3 $ 如果递的过程中让 $2 \\rightarrow 1$ 那么此时 $2 \\rightarrow 3$ 就被覆盖，不知道接下来递给谁 而归的时候让 $3 \\rightarrow 2$ 不会影响上一层的 $1 \\rightarrow 2$ 评价：单向链表没有 prev 指针，但利用递归的特性【记住了】链表每次调用时相邻两个节点是谁 未实现的方法 方法4从链表每次拿到第二个节点，将其从链表断开，插入头部，直至它为 null 结束设置指针 o1(旧头)、n1(新头)、o2(旧老二)，分别指向第一，第一，第二节点$\\frac{n1 \\ o1}{1} \\rightarrow \\frac{o2}{2} \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$将 o2 节点从链表断开，即 o1 节点指向第三节点$ \\frac{n1 \\ o1}{1} \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$ ，$\\frac{o2}{2}$o2 节点链入链表头部，即$\\frac{o2}{2} \\rightarrow \\frac{n1 \\ o1}{1} \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$n1 指向 o2$\\frac{n1 \\ o2}{2} \\rightarrow \\frac{o1}{1} \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$o2 指向 o1 的下一个节点，即$\\frac{n1}{2} \\rightarrow \\frac{o1}{1} \\rightarrow \\frac{o2}{3} \\rightarrow 4 \\rightarrow 5 \\rightarrow null$重复以上 $2\\sim5$ 步，直到 o2 指向 null还应当考虑边界条件，即链表中不满两个元素时，无需走以上逻辑参考答案public ListNode reverseList(ListNode o1) &#123; if (o1 == null || o1.next == null) &#123; // 不足两个节点 return o1; &#125; ListNode o2 = o1.next; ListNode n1 = o1; while (o2 != null) &#123; o1.next = o2.next; o2.next = n1; n1 = o2; o2 = o1.next; &#125; return n1; &#125;方法5要点：把链表分成两部分，思路就是不断从链表2的头，往链表1的头搬移n1 指向 null，代表新链表一开始没有元素，o1 指向原链表的首节点$\\frac{n1}{null}$，$\\frac{o1}{1} \\rightarrow 2 \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$开始循环，o2 指向原链表次节点$\\frac{n1}{null}$，$\\frac{o1}{1} \\rightarrow \\frac{o2}{2} \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$搬移$\\frac{o1}{1} \\rightarrow \\frac{n1}{null}$ ， $\\frac{o2}{2} \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$指针复位$\\frac{n1}{1} \\rightarrow null$ ， $\\frac{o1 \\ o2}{2} \\rightarrow 3 \\rightarrow 4 \\rightarrow 5 \\rightarrow null$重复 $2\\sim4$ 步当 o1 &#x3D; null 时退出循环参考答案public ListNode reverseList(ListNode o1) &#123; if (o1 == null || o1.next == null) &#123; return o1; &#125; ListNode n1 = null; while (o1 != null) &#123; ListNode o2 = o1.next; o1.next = n1; n1 = o1; o1 = o2; &#125; return n1; &#125;评价：本质上与方法2 相同，只是方法2更为面向对象题例如输入：head &#x3D; [1,2,6,3,6], val &#x3D; 6 输出：[1,2,3] 输入：head &#x3D; [], val &#x3D; 1 输出：[] 输入：head &#x3D; [7,7,7,7], val &#x3D; 7 输出：[] E03. 删除倒数节点-力扣 19 题例如 输入：head &#x3D; [1,2,3,4,5], n &#x3D; 2 输出：[1,2,3,5] 输入：head &#x3D; [1], n &#x3D; 1 输出：[] 输入：head &#x3D; [1,2], n &#x3D; 1 输出：[1] 另外题目提示 链表至少一个节点 n 只会在合理范围 解法一 ​ 写一个递归方法，得到倒数的次序。 static int recursion(ListNode p, int n) &#123; if (p == null) &#123; return 0; &#125; int nth = recursion(p.next, n); System.out.println(\"nth:\"+nth+\"\\t p:\"+p.toString()); if (nth == n) &#123; p.next = p.next.next; &#125; return nth + 1; &#125; nth是倒数的次序 p为当前节点 nth:0 p:[5] nth:1 p:[4,5] nth:2 p:[3,4,5] nth:3 p:[2,3,4,5] nth:4 p:[1,2,4,5] 当nth&#x3D;&#x3D;n时 p为要删除节点的上一个，删除节点即可。 但上述代码有一个问题，就是若删除的是第一个节点，它没有上一个节点，因此可以加一个哨兵来解决 public ListNode removeNthFromEnd(ListNode head, int n) &#123; ListNode sentinel = new ListNode(-1, head); recursion(sentinel, n); return sentinel.next; &#125; public int recursion(ListNode p, int n) &#123; if (p == null) &#123; return 0; &#125; int nth = recursion(p.next, n); if (nth == n) &#123; p.next = p.next.next; &#125; return nth + 1; &#125; 解法二 快慢指针，p1 指向待删节点的上一个，p2 先走 n + 1 步 i=0 p2 s -> 1 -> 2 -> 3 -> 4 -> 5 -> null i=1 p2 s -> 1 -> 2 -> 3 -> 4 -> 5 -> null i=2 p2 s -> 1 -> 2 -> 3 -> 4 -> 5 -> null i=3 从此开始 p1 p2 依次向右平移, 直到 p2 移动到末尾 p1 p2 s -> 1 -> 2 -> 3 -> 4 -> 5 -> null p1 p2 s -> 1 -> 2 -> 3 -> 4 -> 5 -> null 代码： public static ListNode removeNthFromEnd(ListNode head, int n) &#123; ListNode s = new ListNode(-1, head); ListNode p1 = s; ListNode p2 = s; for (int i = 0; i &lt; n + 1; i++) &#123; p2 = p2.next; &#125; while (p2 != null) &#123; p1 = p1.next; p2 = p2.next; &#125; p1.next = p1.next.next; return s.next; &#125; 这个方法中，使用了两个指针p1和p2来定位要删除的节点。首先，p2指针先向后移动n+1步，使得p1和p2之间的距离为n+1。然后，同时移动p1和p2指针，直到p2指针到达链表末尾。这样，p1指针就指向了要删除节点的前一个节点。 接下来，将p1的next指针指向要删除节点的下一个节点，即完成了删除操作。最后，返回头节点的next指针，即为删除节点后的链表。 由于p2指针先向后移动了n+1步，所以p1指针和p2指针之间的距离为n+1。因此，当p2指针到达链表末尾时，p1指针正好指向要删除节点的前一个节点。这样，通过移动p1指针的next指针，就可以删除要删除的节点。 E04. 有序链表去重-力扣 83 题例如 输入：head &#x3D; [1,1,2] 输出：[1,2] 输入：head &#x3D; [1,1,2,3,3] 输出：[1,2,3] 注意：重复元素保留一个 E05. 有序链表去重-力扣 82 题例如 输入：head &#x3D; [1,2,3,3,4,4,5] 输出：[1,2,5] 输入：head &#x3D; [1,1,1,2,3] 输出：[2,3] 注意：重复元素一个不留 E06. 合并有序链表-力扣 21 题例 输入：l1 &#x3D; [1,2,4], l2 &#x3D; [1,3,4] 输出：[1,1,2,3,4,4] 输入：l1 &#x3D; [], l2 &#x3D; [] 输出：[] 输入：l1 &#x3D; [], l2 &#x3D; [0] 输出：[0] E07. 合并多个有序链表-力扣 23 题例 输入：lists &#x3D; [[1,4,5],[1,3,4],[2,6]] 输出：[1,1,2,3,4,4,5,6] 解释：链表数组如下： [ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6 ] 将它们合并到一个有序链表中得到。 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 E08. 查找链表中间节点-力扣 876 题例如 输入：[1,2,3,4,5] 输出：此列表中的结点 3 (序列化形式：[3,4,5]) 输入：[1,2,3,4,5,6] 输出：此列表中的结点 4 (序列化形式：[4,5,6]) 偶数节点时，中间点是靠右的那个 数组E01. 合并有序数组将数组内两个区间内的有序元素合并 例 [1, 5, 6, 2, 4, 10, 11] 可以视作两个有序区间 [1, 5, 6] 和 [2, 4, 10, 11] 合并后，结果仍存储于原有空间 [1, 2, 4, 5, 6, 10, 11] 队列栈双端队列优先级队列堆二叉树","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.ehzyil.xyz/tags/Leetcode/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"author":"ehzyil"},{"title":"二分查找","slug":"数据结构与算法/二分查找","date":"2023-10-11T00:00:00.000Z","updated":"2024-01-06T04:54:46.219Z","comments":true,"path":"2023/10/11/数据结构与算法/二分查找/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/","excerpt":"","text":"二分查找基础版（左闭右闭型）需求：在有序数组 $A$ 内，查找值 $target$ 如果找到返回索引 如果找不到返回 $-1$ 算法描述 前提 给定一个内含 $n$ 个元素的有序数组 $A$，满足 $A_{0}\\leq A_{1}\\leq A_{2}\\leq \\cdots \\leq A_{n-1}$，一个待查值 $target$ 1 设置 $i&#x3D;0$(left)，$j&#x3D;n-1$(right) 2 如果 $i \\gt j$，结束查找，没找到 3 设置 $m &#x3D; floor(\\frac {i+j}{2})$ ，$m$ 为中间索引，$floor$ 是向下取整（$\\leq \\frac {i+j}{2}$ 的最小整数） 4 如果 $target &lt; A_{m}$ 设置 $j &#x3D; m - 1$，跳到第2步 5 如果 $A_{m} &lt; target$ 设置 $i &#x3D; m + 1$，跳到第2步 6 如果 $A_{m} &#x3D; target$，结束查找，找到了 java 实现 public static int binarySearch(int[] a, int target) &#123; int i = 0, j = a.length - 1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; // 在左边 j = m - 1; &#125; else if (a[m] &lt; target) &#123; // 在右边 i = m + 1; &#125; else &#123; return m; &#125; &#125; return -1; &#125; $i,j$ 对应着搜索区间 $[0,a.length-1]$（注意是闭合的区间），$i&lt;&#x3D;j$ 意味着搜索区间内还有未比较的元素，$i,j$ 指向的元素也可能是比较的目标 思考：如果不加 $i&#x3D;j$ 行不行？ 回答：不行，因为这意味着 $i,j$ 指向的元素会漏过比较 $m$ 对应着中间位置，中间位置左边和右边的元素可能不相等（差一个），不会影响结果 如果某次未找到，那么缩小后的区间内不包含 $m$ 二分查找改变版（左闭右开）另一种写法 public static int binarySearch(int[] a, int target) &#123; int i = 0, j = a.length; while (i &lt; j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; // 在左边 j = m; &#125; else if (a[m] &lt; target) &#123; // 在右边 i = m + 1; &#125; else &#123; return m; &#125; &#125; return -1; &#125; $i,j$ 对应着搜索区间 $[0,a.length)$（注意是左闭右开的区间），$i&lt;j$ 意味着搜索区间内还有未比较的元素，$j$ 指向的一定不是查找目标 思考：为啥这次不加 $i&#x3D;j$ 的条件了？ 回答：这回 $j$ 指向的不是查找目标，如果还加 $i&#x3D;j$ 条件，就意味着 $j$ 指向的还会再次比较，找不到时，会死循环 如果某次要缩小右边界，那么 $j&#x3D;m$，因为此时的 $m$ 已经不是查找目标了 若只添加 $i&#x3D;j$ 的条件但为修改 j = m - 1; -&gt; j = m;运行以下代码时: int search = Solution.binarySearch(new int[]&#123;-1, 0, 3, 5, 9, -1&#125;, 3);//search为-1 //第一轮循环 public static int binarySearch(int[] a, int target) &#123; int i = 0, j = a.length; while (i &lt; j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; // 在左边 j = m - 1; &#125; else if (a[m] &lt; target) &#123; // 在右边 i = m + 1; &#125; else &#123; return m; &#125; &#125; return -1; &#125; 循环次数 i j mid target a[m] 操作 1 0 6 3 3 0 target &lt; a[m] 1 0 6 3 3 0 target &lt; a[m] 2 0 2 1 3 5 a[m] &lt; target 3 2 2 2 不满足i &lt; j返回-1 二分查找性能下面分析二分查找算法的性能 时间复杂度 最坏情况：$O(\\log n)$ 最好情况：如果待查找元素恰好在数组中央，只需要循环一次 $O(1)$ 空间复杂度 需要常数个指针 $i,j,m$，因此额外占用的空间是 $O(1)$ 二分查找平衡版public static int binarySearchBalance(int[] a, int target) &#123; int i = 0, j = a.length; //1 &lt; j - i ==> i &lt; j - 1 // 即当i个j之间有1个以上元素时满足条件 // 否则跳出循环 此时只剩下一个元素 while (1 &lt; j - i) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; // right j = m; &#125; else if (a[m] &lt; target) &#123; // left i = m; &#125; else &#123; return m; &#125; &#125; //判断剩下的那个元素是否是查询元素 不是则返回 -1 return a[i] == target ? i : -1; &#125; 上述代码中可以优化的是将目标元素小于中间元素的情况和目标元素大于中间元素的情况合并为一个条件。在除了目标元素小于中间元素的情况外，都将i更新为m。 思路是，如果目标元素不小于中间元素，那么它要么等于中间元素，要么大于中间元素。在这两种情况下，更新i为m仍然可以保持目标元素在搜索范围内。优化后： public static int binarySearchBalance(int[] a, int target) &#123; int i = 0, j = a.length; while (1 &lt; j - i) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m; &#125; else &#123; i = m; &#125; &#125; return (a[i] == target) ? i : -1; &#125; 思想： 左闭右开的区间，$i$ 指向的可能是目标，而 $j$ 指向的不是目标 不奢望循环内通过 $m$ 找出目标, 缩小区间直至剩 1 个, 剩下的这个可能就是要找的（通过 $i$） $j - i &gt; 1$ 的含义是，在范围内待比较的元素个数 &gt; 1 改变 $i$ 边界时，它指向的可能是目标，因此不能 $m+1$ 循环内的平均比较次数减少了 时间复杂度 $\\Theta(log(n))$ 二分查找 Java 版private static int binarySearch0(int[] a, int fromIndex, int toIndex, int key) &#123; int low = fromIndex; int high = toIndex - 1; while (low &lt;= high) &#123; int mid = (low + high) >>> 1; int midVal = a[mid]; if (midVal &lt; key) low = mid + 1; else if (midVal > key) high = mid - 1; else return mid; // key found &#125; return -(low + 1); // key not found. &#125; 例如 $[1,3,5,6]$ 要插入 $2$ 那么就是找到一个位置，这个位置左侧元素都比它小 等循环结束，若没找到，low 左侧元素肯定都比 target 小，因此 low 即插入点 插入点取负是为了与找到情况区分 -1 是为了把索引 0 位置的插入点与找到的情况进行区分 若未找到 可以获取插入元素的位置(不是索引)即为-result+1 Leftmost 与 Rightmost有时我们希望返回的是最左侧的重复元素，如果用 Basic 二分查找 对于数组 $[1, 2, 3, 4, 4, 5, 6, 7]$，查找元素4，结果是索引3 对于数组 $[1, 2, 4, 4, 4, 5, 6, 7]$，查找元素4，结果也是索引3，并不是最左侧的元素 public static int binarySearchLeftmost1(int[] a, int target) &#123; int i = 0, j = a.length - 1; int candidate = -1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; candidate = m; // 记录候选位置 j = m - 1; // 继续向左 &#125; &#125; return candidate; &#125; 如果希望返回的是最右侧元素 public static int binarySearchRightmost1(int[] a, int target) &#123; int i = 0, j = a.length - 1; int candidate = -1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; candidate = m; // 记录候选位置 i = m + 1; // 继续向右 &#125; &#125; return candidate; &#125; 应用 对于 Leftmost 与 Rightmost，可以返回一个比 -1 更有用的值 Leftmost 改为 public static int binarySearchLeftmost(int[] a, int target) &#123; int i = 0, j = a.length - 1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt;= a[m]) &#123; j = m - 1; &#125; else &#123; i = m + 1; &#125; &#125; return i; &#125; leftmost 返回值的另一层含义：$\\lt target$ 的元素个数 小于等于中间值，都要向左找 Rightmost 改为 public static int binarySearchRightmost(int[] a, int target) &#123; int i = 0, j = a.length - 1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else &#123; i = m + 1; &#125; &#125; return i - 1; &#125; 大于等于中间值，都要向右找 几个名词 范围查询： 查询 $x \\lt 4$，$0 .. leftmost(4) - 1$ 查询 $x \\leq 4$，$0 .. rightmost(4)$ 查询 $4 \\lt x$，$rightmost(4) + 1 .. \\infty $ 查询 $4 \\leq x$， $leftmost(4) .. \\infty$ 查询 $4 \\leq x \\leq 7$，$leftmost(4) .. rightmost(7)$ 查询 $4 \\lt x \\lt 7$，$rightmost(4)+1 .. leftmost(7)-1$ 求排名：$leftmost(target) + 1$ $target$ 可以不存在，如：$leftmost(5)+1 &#x3D; 6$ $target$ 也可以存在，如：$leftmost(4)+1 &#x3D; 3$ 求前任（predecessor）：$leftmost(target) - 1$ $leftmost(3) - 1 &#x3D; 1$，前任 $a_1 &#x3D; 2$ $leftmost(4) - 1 &#x3D; 1$，前任 $a_1 &#x3D; 2$ 求后任（successor）：$rightmost(target)+1$ $rightmost(5) + 1 &#x3D; 5$，后任 $a_5 &#x3D; 7$ $rightmost(4) + 1 &#x3D; 5$，后任 $a_5 &#x3D; 7$ 求最近邻居： 前任和后任距离更近者 完整代码如下： 查看代码 public class BinarySearch &#123; /** * &lt;h3>二分查找基础版&lt;/h3> * * &lt;ol> * &lt;li>i, j, m 指针都可能是查找目标&lt;/li> * &lt;li>因为 1. i > j 时表示区域内没有要找的了&lt;/li> * &lt;li>每次改变 i, j 边界时, m 已经比较过不是目标, 因此分别 m+1 m-1&lt;/li> * &lt;li>向左查找, 比较次数少, 向右查找, 比较次数多&lt;/li> * &lt;/ol> * * @param a 待查找的升序数组 * @param target 待查找的目标值 * @return &lt;p>找到则返回索引&lt;/p> * &lt;p>找不到返回 -1&lt;/p> */ public static int binarySearchBasic(int[] a, int target) &#123; int i = 0, j = a.length - 1; // 设置指针和初值 // L 次 元素在最左边 L 次， 元素在最右边 2*L 次 while (i &lt;= j) &#123; // i~j 范围内有东西 int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; // 目标在左边 j = m - 1; &#125; else if (a[m] &lt; target) &#123; // 目标在右边 i = m + 1; &#125; else &#123; // 找到了 return m; &#125; &#125; return -1; &#125; /* 1 [2,3,4,5] 5 右侧没找到更差 int i = 0, j = a.length - 1; 2 return -1; 1 元素个数 循环次数 4-7 3 floor(log_2(4)) = 2+1 8-15 4 floor(log_2(8)) = 3+1 16-31 5 floor(log_2(16)) = 4+1 32-63 6 floor(log_2(32)) = 5+1 ... ... 循环次数L = floor(log_2(n)) + 1 i &lt;= j L+1 int m = (i + j) >>> 1; L target &lt; a[m] L a[m] &lt; target L i = m + 1; L (floor(log_2(n)) + 1) * 5 + 4 (3) * 5 + 4 = 19*t (10 + 1) * 5 + 4 = 59*t */ /* 问题1: 为什么是 i&lt;=j 意味着区间内有未比较的元素, 而不是 i&lt;j ? i==j 意味着 i,j 它们指向的元素也会参与比较 i&lt;j 只意味着 m 指向的元素参与比较 问题2: (i + j) / 2 有没有问题? 问题3: 都写成小于号有啥好处? */ /** * &lt;h3>二分查找改动版&lt;/h3> * * &lt;ol> * &lt;li>i, m 指针可能是查找目标&lt;/li> * &lt;li>j 指针不可能是查找目标&lt;/li> * &lt;li>因为 1. 2. i >= j 时表示区域内没有要找的了&lt;/li> * &lt;li>改变 i 边界时, m 已经比较过不是目标, 因此需要 i=m+1&lt;/li> * &lt;li>改变 j 边界时, m 已经比较过不是目标, 同时因为 2. 所以 j=m&lt;/li> * &lt;/ol> * * @param a 待查找的升序数组 * @param target 待查找的目标值 * @return &lt;p>找到则返回索引&lt;/p> * &lt;p>找不到返回 -1&lt;/p> */ public static int binarySearchAlternative(int[] a, int target) &#123; int i = 0, j = a.length; // 第一处 while (i &lt; j) &#123; // 第二处 int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m; // 第三处 &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; return m; &#125; &#125; return -1; &#125; /** * &lt;h3>二分查找平衡版&lt;/h3> * * &lt;ol> * &lt;li>不奢望循环内通过 m 找出目标, 缩小区间直至剩 1 个, 剩下的这个可能就是要找的(通过 i)&lt;/li> * &lt;li>i 指针可能是查找目标&lt;/li> * &lt;li>j 指针不可能是查找目标&lt;/li> * &lt;li>因为 1. 2. 3. 当区域内还剩一个元素时, 表示为 j - i == 1&lt;/li> * &lt;li>改变 i 边界时, m 可能就是目标, 同时因为 2. 所以有 i=m&lt;/li> * &lt;li>改变 j 边界时, m 已经比较过不是目标, 同时因为 3. 所以有 j=m&lt;/li> * &lt;li>三分支改为二分支, 循环内比较次数减少&lt;/li> * &lt;/ol> * * @param a 待查找的升序数组 * @param target 待查找的目标值 * @return &lt;p>找到则返回索引&lt;/p> * &lt;p>找不到返回 -1&lt;/p> */ public static int binarySearchBalance(int[] a, int target) &#123; int i = 0, j = a.length; while (1 &lt; j - i) &#123; // 范围内待查找的元素个数 > 1 时 int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; // 目标在左边 j = m; &#125; else &#123; // 目标在 m 或右边 i = m; &#125; &#125; return (target == a[i]) ? i : -1; &#125; /** * &lt;h3>二分查找 Leftmost &lt;/h3> * * @param a 待查找的升序数组 * @param target 待查找的目标值 * @return &lt;p>找到则返回最靠左索引&lt;/p> * &lt;p>找不到返回 -1&lt;/p> */ public static int binarySearchLeftmost1(int[] a, int target) &#123; int i = 0, j = a.length - 1; int candidate = -1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; // 记录候选位置 candidate = m; j = m - 1; &#125; &#125; return candidate; &#125; /** * &lt;h3>二分查找 Rightmost &lt;/h3> * * @param a 待查找的升序数组 * @param target 待查找的目标值 * @return &lt;p>找到则返回最靠右索引&lt;/p> * &lt;p>找不到返回 -1&lt;/p> */ public static int binarySearchRightmost1(int[] a, int target) &#123; int i = 0, j = a.length - 1; int candidate = -1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else if (a[m] &lt; target) &#123; i = m + 1; &#125; else &#123; candidate = m; i = m + 1; &#125; &#125; return candidate; &#125; /** * &lt;h3>二分查找 Leftmost &lt;/h3> * * @param a 待查找的升序数组 * @param target 待查找的目标值 * @return &lt;p>返回 &amp;ge; target 的最靠左索引&lt;/p> */ public static int binarySearchLeftmost2(int[] a, int target) &#123; int i = 0, j = a.length - 1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt;= a[m]) &#123; j = m - 1; &#125; else &#123; i = m + 1; &#125; &#125; return i; &#125; /** * &lt;h3>二分查找 Rightmost &lt;/h3> * * @param a 待查找的升序数组 * @param target 待查找的目标值 * @return &lt;p>返回 &amp;le; target 的最靠右索引&lt;/p> */ public static int binarySearchRightmost2(int[] a, int target) &#123; int i = 0, j = a.length - 1; while (i &lt;= j) &#123; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; j = m - 1; &#125; else &#123; i = m + 1; &#125; &#125; return i - 1; &#125; 黑马程序员Java高级程序员必学的数据结构与算法","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"author":"ehzyil"},{"title":"基础数据结构","slug":"数据结构与算法/基础数据结构","date":"2023-10-11T00:00:00.000Z","updated":"2024-01-06T04:54:46.223Z","comments":true,"path":"2023/10/11/数据结构与算法/基础数据结构/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/11/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"基础数据结构 数组概述定义 在计算机科学中，数组是由一组元素（值或变量）组成的数据结构，每个元素有至少一个索引或键来标识 In computer science, an array is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key 因为数组内的元素是连续存储的，所以数组中元素的地址，可以通过其索引计算出来，例如： int[] array = &#123;1,2,3,4,5&#125; 知道了数组的数据起始地址 $BaseAddress$，就可以由公式 $BaseAddress + i * size$ 计算出索引 $i$ 元素的地址 $i$ 即索引，在 Java、C 等语言都是从 0 开始 $size$ 是每个元素占用字节，例如 $int$ 占 $4$，$double$ 占 $8$ 小测试 byte[] array = &#123;1,2,3,4,5&#125; 已知 array 的数据的起始地址是 0x7138f94c8，那么元素 3 的地址是什么？ 答： 元素3的地址可以通过数组的起始地址加上元素3的索引乘以元素的大小来计算。在这种情况下，元素3的索引是2（数组索引从0开始），元素的大小是1字节（byte类型的大小为1字节）。 0x7138f94c8 + 2 * 1 &#x3D; 0x7138f94ca 空间占用 Java 中数组结构为 8 字节 markword 4 字节 class 指针（压缩 class 指针的情况） 4 字节 数组大小（决定了数组最大容量是 $2^{32}$） 数组元素 + 对齐字节（java 中所有对象大小都是 8 字节的整数倍[^12]，不足的要用对齐字节补足） 例如 int[] array = &#123;1, 2, 3, 4, 5&#125;; 的大小为 40 个字节，组成如下 8 + 4 + 4 + 5*4 + 4(alignment) 随机访问性能 即根据索引查找元素，时间复杂度是 $O(1)$ 动态数组java 版本 public class DynamicArray implements Iterable&lt;Integer> &#123; private int size = 0; // 逻辑大小 private int capacity = 8; // 容量 private int[] array = &#123;&#125;; /** * 向最后位置 [size] 添加元素 * * @param element 待添加元素 */ public void addLast(int element) &#123; add(size, element); &#125; /** * 向 [0 .. size] 位置添加元素 * * @param index 索引位置 * @param element 待添加元素 */ public void add(int index, int element) &#123; checkAndGrow(); // 添加逻辑 if (index >= 0 &amp;&amp; index &lt; size) &#123; // 向后挪动, 空出待插入位置 System.arraycopy(array, index, array, index + 1, size - index); &#125; array[index] = element; size++; &#125; private void checkAndGrow() &#123; // 容量检查 if (size == 0) &#123; array = new int[capacity]; &#125; else if (size == capacity) &#123; // 进行扩容, 1.5 1.618 2 capacity += capacity >> 1; int[] newArray = new int[capacity]; System.arraycopy(array, 0, newArray, 0, size); array = newArray; &#125; &#125; /** * 从 [0 .. size) 范围删除元素 * * @param index 索引位置 * @return 被删除元素 */ public int remove(int index) &#123; // [0..size) int removed = array[index]; if (index &lt; size - 1) &#123; // 向前挪动 System.arraycopy(array, index + 1, array, index, size - index - 1); &#125; size--; return removed; &#125; /** * 查询元素 * * @param index 索引位置, 在 [0..size) 区间内 * @return 该索引位置的元素 */ public int get(int index) &#123; return array[index]; &#125; /** * 遍历方法1 * * @param consumer 遍历要执行的操作, 入参: 每个元素 */ public void foreach(Consumer&lt;Integer> consumer) &#123; for (int i = 0; i &lt; size; i++) &#123; // 提供 array[i] // 返回 void consumer.accept(array[i]); &#125; &#125; /** * 遍历方法2 - 迭代器遍历 */ @Override public Iterator&lt;Integer> iterator() &#123; return new Iterator&lt;Integer>() &#123; int i = 0; @Override public boolean hasNext() &#123; // 有没有下一个元素 return i &lt; size; &#125; @Override public Integer next() &#123; // 返回当前元素,并移动到下一个元素 return array[i++]; &#125; &#125;; &#125; /** * 遍历方法3 - stream 遍历 * * @return stream 流 */ public IntStream stream() &#123; return IntStream.of(Arrays.copyOfRange(array, 0, size)); &#125; &#125; 这些方法实现，都简化了 index 的有效性判断，假设输入的 index 都是合法的 插入或删除性能 头部位置，时间复杂度是 $O(n)$ 中间位置，时间复杂度是 $O(n)$ 尾部位置，时间复杂度是 $O(1)$（均摊来说） 二维数组int[][] array = &#123; &#123;11, 12, 13, 14, 15&#125;, &#123;21, 22, 23, 24, 25&#125;, &#123;31, 32, 33, 34, 35&#125;, &#125;; 内存图如下 二维数组占 32 个字节，其中 array[0]，array[1]，array[2] 三个元素分别保存了指向三个一维数组的引用 三个一维数组各占 40 个字节 它们在内层布局上是连续的 更一般的，对一个二维数组 $Array[m][n]$ $m$ 是外层数组的长度，可以看作 row 行 $n$ 是内层数组的长度，可以看作 column 列 当访问 $Array[i][j]$，$0\\leq i \\lt m, 0\\leq j \\lt n$时，就相当于 先找到第 $i$ 个内层数组（行） 再找到此内层数组中第 $j$ 个元素（列） 小测试 Java 环境下（不考虑类指针和引用压缩，此为默认情况），有下面的二维数组 byte[][] array = &#123; &#123;11, 12, 13, 14, 15&#125;, &#123;21, 22, 23, 24, 25&#125;, &#123;31, 32, 33, 34, 35&#125;, &#125;; 已知 array 对象起始地址是 0x1000，那么 23 这个元素的地址是什么？（不太理解对齐字节！！！） 答： 起始地址 0x1000 外层数组大小：16字节对象头 + 3元素 * 每个引用4字节 + 4 对齐字节 &#x3D; 32 &#x3D; 0x20 第一个内层数组大小：16字节对象头 + 5元素 * 每个byte1字节 + 3 对齐字节 &#x3D; 24 &#x3D; 0x18 第二个内层数组，16字节对象头 &#x3D; 0x10，待查找元素索引为 2 最后结果 &#x3D; 0x1000 + 0x20 + 0x18 + 0x10 + 2*1 &#x3D; 0x104a 局部性原理这里只讨论空间局部性 cpu 读取内存（速度慢）数据后，会将其放入高速缓存（速度快）当中，如果后来的计算再用到此数据，在缓存中能读到的话，就不必读内存了 缓存的最小存储单位是缓存行（cache line），一般是 64 bytes，一次读的数据少了不划算啊，因此最少读 64 bytes 填满一个缓存行，因此读入某个数据时也会读取其临近的数据，这就是所谓空间局部性 对效率的影响 比较下面 ij 和 ji 两个方法的执行效率 int rows = 1000000; int columns = 14; int[][] a = new int[rows][columns]; StopWatch sw = new StopWatch(); sw.start(\"ij\"); ij(a, rows, columns); sw.stop(); sw.start(\"ji\"); ji(a, rows, columns); sw.stop(); System.out.println(sw.prettyPrint()); ij 方法 public static void ij(int[][] a, int rows, int columns) &#123; long sum = 0L; for (int i = 0; i &lt; rows; i++) &#123; for (int j = 0; j &lt; columns; j++) &#123; sum += a[i][j]; &#125; &#125; System.out.println(sum); &#125; ji 方法 public static void ji(int[][] a, int rows, int columns) &#123; long sum = 0L; for (int j = 0; j &lt; columns; j++) &#123; for (int i = 0; i &lt; rows; i++) &#123; sum += a[i][j]; &#125; &#125; System.out.println(sum); &#125; 执行结果 0 0 StopWatch &#39;&#39;: running time &#x3D; 96283300 ns --------------------------------------------- ns % Task name --------------------------------------------- 016196200 017% ij 080087100 083% ji 可以看到 ij 的效率比 ji 快很多，为什么呢？ 缓存是有限的，当新数据来了后，一些旧的缓存行数据就会被覆盖 如果不能充分利用缓存的数据，就会造成效率低下 以 ji 执行为例，第一次内循环要读入 $[0,0]$ 这条数据，由于局部性原理，读入 $[0,0]$ 的同时也读入了 $[0,1] … [0,13]$，如图所示 但很遗憾，第二次内循环要的是 $[1,0]$ 这条数据，缓存中没有，于是再读入了下图的数据 这显然是一种浪费，因为 $[0,1] … [0,13]$ 包括 $[1,1] … [1,13]$ 这些数据虽然读入了缓存，却没有及时用上，而缓存的大小是有限的，等执行到第九次内循环时 缓存的第一行数据已经被新的数据 $[8,0] … [8,13]$ 覆盖掉了，以后如果再想读，比如 $[0,1]$，又得到内存去读了 同理可以分析 ij 函数则能充分利用局部性原理加载到的缓存数据 举一反三 I&#x2F;O 读写时同样可以体现局部性原理 数组可以充分利用局部性原理，那么链表呢？ 答：链表不行，因为链表的元素并非相邻存储 链表概述定义 在计算机科学中，链表是数据元素的线性集合，其每个元素都指向下一个元素，元素存储上并不连续 In computer science, a linked list is a linear collection of data elements whose order is not given by their physical placement in memory. Instead, each element points to the next. 可以分类为[^5] 单向链表，每个元素只知道其下一个元素是谁 双向链表，每个元素知道其上一个元素和下一个元素 循环链表，通常的链表尾节点 tail 指向的都是 null，而循环链表的 tail 指向的是头节点 head 链表内还有一种特殊的节点称为哨兵（Sentinel）节点，也叫做哑元（ Dummy）节点，它不存储数据，通常用作头尾，用来简化边界判断，如下图所示 随机访问性能 根据 index 查找，时间复杂度 $O(n)$ 插入或删除性能 起始位置：$O(1)$ 结束位置：如果已知 tail 尾节点是 $O(1)$，不知道 tail 尾节点是 $O(n)$ 中间位置：根据 index 查找时间 + $O(1)$ 单向链表根据单向链表的定义，首先定义一个存储 value 和 next 指针的类 Node，和一个描述头部节点的引用 public class SinglyLinkedList &#123; private Node head; // 头部节点 private static class Node &#123; // 节点类 int value; Node next; public Node(int value, Node next) &#123; this.value = value; this.next = next; &#125; &#125; &#125; Node 定义为内部类，是为了对外隐藏实现细节，没必要让类的使用者关心 Node 结构 定义为 static 内部类，是因为 Node 不需要与 SinglyLinkedList 实例相关，多个 SinglyLinkedList实例能共用 Node 类定义 头部添加 public class SinglyLinkedList &#123; // ... public void addFirst(int value) &#123; this.head = new Node(value, this.head); &#125; &#125; 如果 this.head &#x3D;&#x3D; null，新增节点指向 null，并作为新的 this.head 如果 this.head !&#x3D; null，新增节点指向原来的 this.head，并作为新的 this.head 注意赋值操作执行顺序是从右到左 while 遍历 public class SinglyLinkedList &#123; // ... public void loop() &#123; Node curr = this.head; while (curr != null) &#123; // 做一些事 System.out.println(curr.value); curr = curr.next; &#125; &#125; &#125; for 遍历 public class SinglyLinkedList &#123; // ... public void loop() &#123; for (Node curr = this.head; curr != null; curr = curr.next) &#123; // 做一些事 System.out.println(curr.value); &#125; &#125; &#125; 以上两种遍历都可以把要做的事以 Consumer 函数的方式传递进来 Consumer 的规则是一个参数，无返回值，因此像 System.out::println 方法等都是 Consumer 调用 Consumer 时，将当前节点 curr.value 作为参数传递给它 xxx.traverse(System.out::println); public void traverse(Consumer&lt;Integer> consumer) &#123; Node p = head; while (p != null) &#123; consumer.accept(p.value); p = p.next; &#125; &#125; 迭代器遍历 public class SinglyLinkedList implements Iterable&lt;Integer> &#123; // ... private class NodeIterator implements Iterator&lt;Integer> &#123; Node curr = head; public boolean hasNext() &#123; return curr != null; &#125; public Integer next() &#123; int value = curr.value; curr = curr.next; return value; &#125; &#125; public Iterator&lt;Integer> iterator() &#123; return new NodeIterator(); &#125; &#125; hasNext 用来判断是否还有必要调用 next next 做两件事 返回当前节点的 value 指向下一个节点 NodeIterator 要定义为非 static 内部类，是因为它与 SinglyLinkedList 实例相关，是对某个 SinglyLinkedList 实例的迭代 递归遍历 public class SinglyLinkedList implements Iterable&lt;Integer> &#123; // ... public void loop() &#123; recursion(this.head); &#125; private void recursion(Node curr) &#123; if (curr == null) &#123; return; &#125; // 前面做些事 recursion(curr.next); // 后面做些事 &#125; &#125; 尾部添加 public class SinglyLinkedList &#123; // ... private Node findLast() &#123; if (this.head == null) &#123; return null; &#125; Node curr; for (curr = this.head; curr.next != null; ) &#123; curr = curr.next; &#125; return curr; &#125; public void addLast(int value) &#123; Node last = findLast(); if (last == null) &#123; addFirst(value); return; &#125; last.next = new Node(value, null); &#125; &#125; 注意，找最后一个节点，终止条件是 curr.next &#x3D;&#x3D; null 分成两个方法是为了代码清晰，而且 findLast() 之后还能复用 尾部添加多个 public class SinglyLinkedList &#123; // ... public void addLast(int first, int... rest) &#123; Node sublist = new Node(first, null); Node curr = sublist; for (int value : rest) &#123; //仅是遍历 curr.next = new Node(value, null); curr = curr.next; &#125; Node last = findLast(); if (last == null) &#123; this.head = sublist; return; &#125; last.next = sublist; &#125; &#125; 先串成一串 sublist 再作为一个整体添加 根据索引获取 public class SinglyLinkedList &#123; // ... private Node findNode(int index) &#123; int i = 0; for (Node curr = this.head; curr != null; curr = curr.next, i++) &#123; if (index == i) &#123; return curr; &#125; &#125; return null; &#125; private IllegalArgumentException illegalIndex(int index) &#123; return new IllegalArgumentException(String.format(\"index [%d] 不合法%n\", index)); &#125; public int get(int index) &#123; Node node = findNode(index); if (node != null) &#123; return node.value; &#125; throw illegalIndex(index); &#125; &#125; 同样，分方法可以实现复用 插入 public class SinglyLinkedList &#123; // ... public void insert(int index, int value) &#123; if (index == 0) &#123; addFirst(value); return; &#125; Node prev = findNode(index - 1); // 找到上一个节点 if (prev == null) &#123; // 找不到 throw illegalIndex(index); &#125; prev.next = new Node(value, prev.next); &#125; &#125; 插入包括下面的删除，都必须找到上一个节点 删除 public class SinglyLinkedList &#123; // ... public void remove(int index) &#123; if (index == 0) &#123; if (this.head != null) &#123; this.head = this.head.next; return; &#125; else &#123; throw illegalIndex(index); &#125; &#125; Node prev = findNode(index - 1); Node curr; if (prev != null &amp;&amp; (curr = prev.next) != null) &#123; prev.next = curr.next; &#125; else &#123; throw illegalIndex(index); &#125; &#125; &#125; 第一个 if 块对应着 removeFirst 情况 最后一个 if 块对应着至少得两个节点的情况 不仅仅判断上一个节点非空，还要保证当前节点非空 完整代码如下： 查看代码 public class SinglyLinkedList implements Iterable&lt;Integer&gt; &#123; private Node head; &#x2F;** * 根据索引移除节点 * * @param index *&#x2F; public void remove(int index) &#123; if (index &#x3D;&#x3D; 0) &#123; if (head &#x3D;&#x3D; null) &#123; this.head.next &#x3D; head.next; &#125; else &#123; throw illegalIndex(index); &#125; &#125; Node prev &#x3D; findNode(index - 1); Node curr; if (prev !&#x3D; null &amp;&amp; (curr &#x3D; prev.next) !&#x3D; null) &#123; prev.next &#x3D; curr.next; &#125; else &#123; throw illegalIndex(index); &#125; &#125; &#x2F;** * 根据索引插入节点 * * @param index * @param value *&#x2F; public void insert(int index, int value) &#123; &#x2F;&#x2F;为空 if (head &#x3D;&#x3D; null) &#123; addLast(value); return; &#125; Node prev &#x3D; findNode(index - 1); &#x2F;&#x2F; 找到上一个节点 if (prev &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 找不到 throw illegalIndex(index); &#125; prev.next &#x3D; new Node(value, prev.next); &#125; &#x2F;** * 根据索引查询节点 * * @param index * @return 查找到的节点 *&#x2F; public Node findNode(int index) &#123; int count &#x3D; 0; for (Node curr &#x3D; head; curr !&#x3D; null; curr &#x3D; curr.next, count++) &#123; if (index &#x3D;&#x3D; count) &#123; return curr; &#125; &#125; return null; &#125; &#x2F;** * 根据索引获取节点的值 * * @param index * @return *&#x2F; public int get(int index) &#123; Node node &#x3D; findNode(index); if (node !&#x3D; null) &#123; return node.value; &#125; throw illegalIndex(index); &#125; private IllegalArgumentException illegalIndex(int index) &#123; return new IllegalArgumentException(String.format(&quot;index [%d] 不合法%n&quot;, index)); &#125; &#x2F;** * 找到最后一个节点 * * @return *&#x2F; private Node findLast() &#123; if (this.head &#x3D;&#x3D; null) return null; Node curr; for (curr &#x3D; this.head; curr.next !&#x3D; null; curr &#x3D; curr.next) ; return curr; &#125; &#x2F;** * 尾部添加多个 *&#x2F; public void addLast(int first, int... rest) &#123; Node sublist &#x3D; new Node(first, null); Node curr &#x3D; sublist; for (int i : rest) &#123; curr.next &#x3D; new Node(i, null); curr &#x3D; curr.next; &#125; Node last &#x3D; findLast(); if (last &#x3D;&#x3D; null) &#123; this.head &#x3D; sublist; return; &#125; last.next &#x3D; sublist; &#125; &#x2F;** * 在链表末尾添加元素 * * @param value *&#x2F; public void addLast(int value) &#123; Node last &#x3D; findLast(); &#x2F;&#x2F;链表为空 在头插入 if (last &#x3D;&#x3D; null) &#123; addFirst(value); return; &#125; last.next &#x3D; new Node(value, null); &#125; &#x2F;** * 头部添加 * * @param value *&#x2F; public void addFirst(int value) &#123; this.head &#x3D; new Node(value, head); &#125; &#x2F;** * while 循环遍历 *&#x2F; public void loopWithWhile() &#123; Node curr &#x3D; this.head; while (curr !&#x3D; null) &#123; System.out.println(curr.value); curr &#x3D; curr.next; &#125; &#125; &#x2F;** * for 循环遍历 *&#x2F; public void loopWithFor() &#123; for (Node curr &#x3D; this.head; curr !&#x3D; null; curr &#x3D; curr.next) System.out.println(curr.value); &#125; &#x2F;** * Consumer&lt;T&gt; 循环遍历 *&#x2F; public void traverse(Consumer&lt;Integer&gt; consumer) &#123; Node p &#x3D; head; while (p !&#x3D; null) &#123; consumer.accept(p.value); p &#x3D; p.next; &#125; &#125; @Override public Iterator&lt;Integer&gt; iterator() &#123; return new NodeIterator(); &#125; &#x2F;** * 递归遍历 *&#x2F; public void loop() &#123; recursion(this.head); &#125; private void recursion(Node curr) &#123; if (curr &#x3D;&#x3D; null) return; &#x2F;&#x2F;正序 &#x2F;&#x2F; System.out.println(curr.value); recursion(curr.next); &#x2F;&#x2F;逆序 System.out.println(curr.value); &#125; static class Node &#123; int value; Node next; public Node(int value, Node next) &#123; this.value &#x3D; value; this.next &#x3D; next; &#125; &#125; private class NodeIterator implements Iterator&lt;Integer&gt; &#123; Node p &#x3D; head; @Override public boolean hasNext() &#123; return p !&#x3D; null; &#125; @Override public Integer next() &#123; int value &#x3D; p.value; p &#x3D; p.next; return value; &#125; &#125; &#125; 单向链表（带哨兵）观察之前单向链表的实现，发现每个方法内几乎都有判断是不是 head 这样的代码，能不能简化呢？ 用一个不参与数据存储的特殊 Node 作为哨兵，它一般被称为哨兵或哑元，拥有哨兵节点的链表称为带头链表 public class SinglyLinkedListSentinel &#123; // ... private Node head = new Node(Integer.MIN_VALUE, null); &#125; 具体存什么值无所谓，因为不会用到它的值 加入哨兵节点后，代码会变得比较简单，先看几个工具方法 public class SinglyLinkedListSentinel &#123; // ... // 根据索引获取节点 private Node findNode(int index) &#123; int i = -1; for (Node curr = this.head; curr != null; curr = curr.next, i++) &#123; if (i == index) &#123; return curr; &#125; &#125; return null; &#125; // 获取最后一个节点 private Node findLast() &#123; Node curr; for (curr = this.head; curr.next != null; ) &#123; curr = curr.next; &#125; return curr; &#125; &#125; findNode 与之前类似，只是 i 初始值设置为 -1 对应哨兵，实际传入的 index 也是 $[-1, \\infty)$ findLast 绝不会返回 null 了，就算没有其它节点，也会返回哨兵作为最后一个节点 这样，代码简化为 public class SinglyLinkedListSentinel &#123; // ... public void addLast(int value) &#123; Node last = findLast(); /* 改动前 if (last == null) &#123; this.head = new Node(value, null); return; &#125; */ last.next = new Node(value, null); &#125; public void insert(int index, int value) &#123; /* 改动前 if (index == 0) &#123; this.head = new Node(value, this.head); return; &#125; */ // index 传入 0 时，返回的是哨兵 Node prev = findNode(index - 1); if (prev != null) &#123; prev.next = new Node(value, prev.next); &#125; else &#123; throw illegalIndex(index); &#125; &#125; public void remove(int index) &#123; /* 改动前 if (index == 0) &#123; if (this.head != null) &#123; this.head = this.head.next; return; &#125; else &#123; throw illegalIndex(index); &#125; &#125; */ // index 传入 0 时，返回的是哨兵 Node prev = findNode(index - 1); Node curr; if (prev != null &amp;&amp; (curr = prev.next) != null) &#123; prev.next = curr.next; &#125; else &#123; throw illegalIndex(index); &#125; &#125; public void addFirst(int value) &#123; /* 改动前 this.head = new Node(value, this.head); */ this.head.next = new Node(value, this.head.next); // 也可以视为 insert 的特例, 即 insert(0, value); &#125; &#125; 对于删除，前面说了【最后一个 if 块对应着至少得两个节点的情况】，现在有了哨兵，就凑足了两个节点 完整代码如下： 查看代码 public class SinglyLinkedListSentinel &#123; static class Node &#123; int value; Node next; public Node(int value, Node next) &#123; this.value &#x3D; value; this.next &#x3D; next; &#125; &#125; &#x2F;&#x2F;哨兵节点 private Node head &#x3D; new Node(Integer.MIN_VALUE, null); &#x2F;** * 根据索引获取节点 * count当不带哨兵因为有头结点所以从0开始，带了哨兵，初始值设置为 -1 对应哨兵 * @param index * @return 查找到的节点 *&#x2F; public Node findNode(int index) &#123; int count &#x3D; -1; for (Node curr &#x3D; head; curr !&#x3D; null; curr &#x3D; curr.next, count++) &#123; if (index &#x3D;&#x3D; count) &#123; return curr; &#125; &#125; return null; &#125; &#x2F;** * 在链表末尾添加元素 * * @param value *&#x2F; public void addLast(int value) &#123; &#x2F;&#x2F;找到最后一个节点 Node last &#x3D; findLast(); &#x2F;&#x2F;添加节点 last.next &#x3D; new Node(value, null); &#125; &#x2F;&#x2F; 获取最后一个节点 不用再判断头结点为空的情况 private Node findLast() &#123; Node curr; for (curr &#x3D; this.head; curr.next !&#x3D; null; ) &#123; curr &#x3D; curr.next; &#125; return curr; &#125; &#x2F;** * 尾部添加多个 *&#x2F; public void addLast(int first, int... rest) &#123; Node sublist &#x3D; new Node(first, null); Node curr &#x3D; sublist; for (int i : rest) &#123; curr.next &#x3D; new Node(i, null); curr &#x3D; curr.next; &#125; Node last &#x3D; findLast(); last.next &#x3D; sublist; &#125; &#x2F;** * 头部添加 * * @param value *&#x2F; public void addFirst(int value) &#123; &#x2F;* 改动前 this.head &#x3D; new Node(value, this.head); *&#x2F; this.head.next &#x3D; new Node(value, this.head.next); &#x2F;&#x2F; 也可以视为 insert 的特例, 即 insert(0, value); &#125; &#x2F;** * 索引越界异常 * @param index * @return *&#x2F; private IllegalArgumentException illegalIndex(int index) &#123; return new IllegalArgumentException(String.format(&quot;index [%d] 不合法%n&quot;, index)); &#125; &#x2F;** * 根据索引获取节点的值 * * @param index * @return *&#x2F; public int get(int index) &#123; Node node &#x3D; findNode(index); if (node !&#x3D; null) &#123; return node.value; &#125; throw illegalIndex(index); &#125; &#x2F;** * 根据索引插入节点 * * @param index * @param value *&#x2F; public void insert(int index, int value) &#123; &#x2F;&#x2F; index 传入 0 时，返回的是哨兵 Node prev &#x3D; findNode(index - 1); &#x2F;&#x2F; 找到上一个节点 if (prev !&#x3D;null) &#123; prev.next &#x3D; new Node(value, prev.next); &#125;else &#123; throw illegalIndex(index); &#125; &#125; &#x2F;** * 根据索引移除 * @param index *&#x2F; public void remove(int index) &#123; Node prev &#x3D; findNode(index - 1); Node curr; if (prev !&#x3D; null &amp;&amp; (curr &#x3D; prev.next) !&#x3D; null) &#123; prev.next &#x3D; curr.next; &#125; else &#123; throw illegalIndex(index); &#125; &#125; public void traverse(Consumer&lt;Integer&gt; consumer) &#123; Node p &#x3D; head.next; while (p !&#x3D; null) &#123; consumer.accept(p.value); p &#x3D; p.next; &#125; &#125; &#125; 双向链表（带哨兵）完整代码如下： 查看代码 public class DoublyLinkedListSentinel implements Iterable&lt;Integer> &#123; private final Node head; private final Node tail; public DoublyLinkedListSentinel() &#123; this.head = new Node(null, 666, null); this.tail = new Node(null, 888, null); head.next = tail; tail.prev = head; &#125; @Override public Iterator&lt;Integer> iterator() &#123; return new Iterator&lt;Integer>() &#123; Node p = head.next; @Override public boolean hasNext() &#123; return p != tail; &#125; @Override public Integer next() &#123; int value = p.value; p = p.next; return value; &#125; &#125;; &#125; public void addFirst(int value) &#123; insert(0, value); &#125; private Node findNode(int index) &#123; int i = -1;//从头节点开始 Node curr; for (curr = head; curr != tail; curr = curr.next, i++) &#123; if (i == index) &#123; return curr; &#125; &#125; return null; &#125; private void insert(int index, int value) &#123; //找到要插入的前一个位置 Node prev = findNode(index - 1); if (prev == null) &#123; throw illegalIndex(index); &#125; Node next = prev.next; //插入 Node added=new Node(prev,value,next); //重新指向 prev.next=added; next.prev=added; &#125; public void removeFirst() &#123; remove(0); &#125; private void remove(int index) &#123; //找到要删除的前一个位置 Node prev = findNode(index - 1); if (prev == null) &#123; throw illegalIndex(index); &#125; //需要用它指向删除后的下一个 Node removed = prev.next; if (removed == tail) &#123; throw illegalIndex(index); &#125; Node next = removed.next; prev.next=next; next.prev=prev; &#125; public void addLast(int value) &#123; Node prev = tail.prev; //单向指向 Node added = new Node(prev, value, tail); //添加的前一个和tail 指向 prev.next = added; tail.prev = added; &#125; public void removeLast() &#123; Node removed = tail.prev; Node prev = removed.prev; if (prev == null) &#123; throw illegalIndex(0); &#125; //移除 removed 重新指向 prev.next = tail; tail.prev = prev; &#125; /** * 参数异常 * * @param index * @return */ private IllegalArgumentException illegalIndex(int index) &#123; return new IllegalArgumentException( String.format(\"index [%d] 不合法%n\", index)); &#125; static class Node &#123; Node prev; int value; Node next; public Node(Node prev, int value, Node next) &#123; this.prev = prev; this.value = value; this.next = next; &#125; &#125; &#125; 环形链表（带哨兵）双向环形链表带哨兵，这时哨兵既作为头，也作为尾 参考实现： 查看代码 public class CircularLinkedList implements Iterable&lt;Integer> &#123; private final Node sentinel = new Node(null, -1, null); // 哨兵 public CircularLinkedList() &#123; //一个哨兵 哨兵指向自己 sentinel.next = sentinel; sentinel.prev = sentinel; &#125; public static void main(String[] args) &#123; CircularLinkedList list = new CircularLinkedList(); list.addFirst(1); list.addLast(2); list.addLast(3); list.addLast(4); Node nodeByValue = list.findNodeByValue(2); list.removeByValue(5); Iterator&lt;Integer> iterator = list.iterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125; /** * 添加到第一个 * * @param value 待添加值 */ public void addFirst(int value) &#123; Node next = sentinel.next; Node added = new Node(sentinel, value, next); sentinel.next = added; next.prev = added; &#125; /** * 添加到最后一个 * * @param value 待添加值 */ public void addLast(int value) &#123; Node prev = sentinel.prev; Node added = new Node(prev, value, sentinel); prev.next = added; sentinel.prev = added; &#125; /** * 删除第一个 */ public void removeFirst() &#123; Node removed = sentinel.next; if (removed == sentinel) &#123; throw new IllegalArgumentException(\"非法\"); &#125; Node a = sentinel; Node b = removed.next; a.next = b; b.prev = a; &#125; /** * 删除最后一个 */ public void removeLast() &#123; Node removed = sentinel.prev; if (removed == sentinel) &#123; throw new IllegalArgumentException(\"非法\"); &#125; Node a = removed.prev; Node b = sentinel; a.next = b; b.prev = a; &#125; /** * 根据值删除节点 * &lt;p>假定 value 在链表中作为 key, 有唯一性&lt;/p> * * @param value 待删除值 */ public void removeByValue(int value) &#123; Node removed = findNodeByValue(value); if (removed!=null)&#123; Node prev = removed.prev; Node next = removed.next; prev.next=next; next.prev=prev; &#125; throw new IllegalArgumentException(value+\"不存在！\"); &#125; private Node findNodeByValue(int value) &#123; for (Node p = sentinel.next; p != sentinel; p = p.next) &#123; if (p.value == value) &#123; return p; &#125; &#125; return null; &#125; @Override public Iterator&lt;Integer> iterator() &#123; return new Iterator&lt;Integer>() &#123; Node p = sentinel.next; @Override public boolean hasNext() &#123; return p != sentinel; &#125; @Override public Integer next() &#123; int value = p.value; p = p.next; return value; &#125; &#125;; &#125; static class Node &#123; Node prev; // 上一个节点指针 int value; // 值 Node next; // 下一个节点指针 public Node(Node prev, int value, Node next) &#123; this.prev = prev; this.value = value; this.next = next; &#125; &#125; &#125; 2.3 递归概述定义 计算机科学中，递归是一种解决计算问题的方法，其中解决方案取决于同一类问题的更小子集 In computer science, recursion is a method of solving a computational problem where the solution depends on solutions to smaller instances of the same problem. 比如单链表递归遍历的例子： void f(Node node) &#123; if(node == null) &#123; return; &#125; println(\"before:\" + node.value) f(node.next); println(\"after:\" + node.value) &#125; 说明： 自己调用自己，如果说每个函数对应着一种解决方案，自己调用自己意味着解决方案是一样的（有规律的） 每次调用，函数处理的数据会较上次缩减（子集），而且最后会缩减至无需继续递归 内层函数调用（子集处理）完成，外层函数才能算调用完成 原理 假设链表中有 3 个节点，value 分别为 1，2，3，以上代码的执行流程就类似于下面的伪码 // 1 -> 2 -> 3 -> null f(1) void f(Node node = 1) &#123; println(\"before:\" + node.value) // 1 void f(Node node = 2) &#123; println(\"before:\" + node.value) // 2 void f(Node node = 3) &#123; println(\"before:\" + node.value) // 3 void f(Node node = null) &#123; if(node == null) &#123; return; &#125; &#125; println(\"after:\" + node.value) // 3 &#125; println(\"after:\" + node.value) // 2 &#125; println(\"after:\" + node.value) // 1 &#125; 思路 确定能否使用递归求解 推导出递推关系，即父问题与子问题的关系，以及递归的结束条件 例如之前遍历链表的递推关系为$$f(n) &#x3D;\\begin{cases}停止&amp; n &#x3D; null \\f(n.next) &amp; n \\neq null\\end{cases}$$ 深入到最里层叫做递 从最里层出来叫做归 在递的过程中，外层函数内的局部变量（以及方法参数）并未消失，归的时候还可以用到 单路递归 Single RecursionE01. 阶乘 用递归方法求阶乘 阶乘的定义 $n!&#x3D; 1⋅2⋅3⋯(n-2)⋅(n-1)⋅n$，其中 $n$ 为自然数，当然 $0! &#x3D; 1$ 递推关系 $$f(n) &#x3D;\\begin{cases}1 &amp; n &#x3D; 1\\n * f(n-1) &amp; n &gt; 1\\end{cases}$$ 代码 private static int f(int n) &#123; if (n == 1) &#123; return 1; &#125; return n * f(n - 1); &#125; 拆解伪码如下，假设 n 初始值为 3 f(int n = 3) &#123; // 解决不了,递 return 3 * f(int n = 2) &#123; // 解决不了,继续递 return 2 * f(int n = 1) &#123; if (n == 1) &#123; // 可以解决, 开始归 return 1; &#125; &#125; &#125; &#125; E02. 反向打印字符串 用递归反向打印字符串，n 为字符在整个字符串 str 中的索引位置 递：n 从 0 开始，每次 n + 1，一直递到 n &#x3D;&#x3D; str.length() - 1 归：从 n &#x3D;&#x3D; str.length() 开始归，从归打印，自然是逆序的 递推关系$$f(n) &#x3D;\\begin{cases}停止 &amp; n &#x3D; str.length() \\f(n+1) &amp; 0 \\leq n \\leq str.length() - 1\\end{cases}$$代码为 public static void reversePrint(String str, int index) &#123; if (index == str.length()) &#123; return; &#125; reversePrint(str, index + 1); System.out.println(str.charAt(index)); &#125; 拆解伪码如下，假设字符串为 “abc” void reversePrint(String str, int index = 0) &#123; void reversePrint(String str, int index = 1) &#123; void reversePrint(String str, int index = 2) &#123; void reversePrint(String str, int index = 3) &#123; if (index == str.length()) &#123; return; // 开始归 &#125; &#125; System.out.println(str.charAt(index)); // 打印 c &#125; System.out.println(str.charAt(index)); // 打印 b &#125; System.out.println(str.charAt(index)); // 打印 a &#125; 多路递归 Multi RecursionE01. 斐波那契数列 之前的例子是每个递归函数只包含一个自身的调用，这称之为 single recursion 如果每个递归函数例包含多个自身调用，称之为 multi recursion 递推关系$$f(n) &#x3D;\\begin{cases}0 &amp; n&#x3D;0 \\1 &amp; n&#x3D;1 \\f(n-1) + f(n-2) &amp; n&gt;1\\end{cases}$$ 下面的表格列出了数列的前几项 F0 F1 F2 F3 F4 F5 F6 F7 F8 F9 F10 F11 F12 F13 0 1 1 2 3 5 8 13 21 34 55 89 144 233 实现 public static int f(int n) &#123; if (n == 0) &#123; return 0; &#125; if (n == 1) &#123; return 1; &#125; return f(n - 1) + f(n - 2); &#125; 执行流程 绿色代表正在执行（对应递），灰色代表执行结束（对应归） 递不到头，不能归，对应着深度优先搜索 时间复杂度 递归的次数也符合斐波那契规律，$2 * f(n+1)-1$ 时间复杂度推导过程 斐波那契通项公式 $f(n) &#x3D; \\frac{1}{\\sqrt{5}}*({\\frac{1+\\sqrt{5}}{2}}^n - {\\frac{1-\\sqrt{5}}{2}}^n)$ 简化为：$f(n) &#x3D; \\frac{1}{2.236}*({1.618}^n - {(-0.618)}^n)$ 带入递归次数公式 $2\\frac{1}{2.236}({1.618}^{n+1} - {(-0.618)}^{n+1})-1$ 时间复杂度为 $\\Theta(1.618^n)$ 更多 Fibonacci 参考[^8][^9][^10] 以上时间复杂度分析，未考虑大数相加的因素 变体1 - 兔子问题[^8] 第一个月，有一对未成熟的兔子（黑色，注意图中个头较小） 第二个月，它们成熟 第三个月，它们能产下一对新的小兔子（蓝色） 所有兔子遵循相同规律，求第 $n$ 个月的兔子数 分析 兔子问题如何与斐波那契联系起来呢？设第 n 个月兔子数为 $f(n)$ $f(n)$ &#x3D; 上个月兔子数 + 新生的小兔子数 而【新生的小兔子数】实际就是【上个月成熟的兔子数】 因为需要一个月兔子就成熟，所以【上个月成熟的兔子数】也就是【上上个月的兔子数】 上个月兔子数，即 $f(n-1)$ 上上个月的兔子数，即 $f(n-2)$ 因此本质还是斐波那契数列，只是从其第一项开始 变体2 - 青蛙爬楼梯 楼梯有 $n$ 阶 青蛙要爬到楼顶，可以一次跳一阶，也可以一次跳两阶 只能向上跳，问有多少种跳法 分析 n 跳法 规律 1 (1) 暂时看不出 2 (1,1) (2) 暂时看不出 3 (1,1,1) (1,2) (2,1) 暂时看不出 4 (1,1,1,1) (1,2,1) (2,1,1)(1,1,2) (2,2) 最后一跳，跳一个台阶的，基于f(3)最后一跳，跳两个台阶的，基于f(2) 5 … … 因此本质上还是斐波那契数列，只是从其第二项开始 对应 leetcode 题目 70. 爬楼梯 - 力扣（LeetCode） 实现(Leetcode 运行会超时 待优化) class Solution &#123; public int climbStairs(int n) &#123; if(n==1) return 1; if(n==2) return 2; if(n==3) return 3; return climbStairs(n-1)+climbStairs(n-2); &#125; &#125; 递归优化-记忆法上述代码存在很多重复的计算，例如求 $f(5)$ 递归分解过程 可以看到（颜色相同的是重复的）： $f(3)$ 重复了 2 次 $f(2)$ 重复了 3 次 $f(1)$ 重复了 5 次 $f(0)$ 重复了 3 次 随着 $n$ 的增大，重复次数非常可观，如何优化呢？ Memoization 记忆法（也称备忘录）是一种优化技术，通过存储函数调用结果（通常比较昂贵），当再次出现相同的输入（子问题）时，就能实现加速效果，改进后的代码 public static void main(String[] args) &#123; int n = 13; int[] cache = new int[n + 1]; Arrays.fill(cache, -1); cache[0] = 0; cache[1] = 1; System.out.println(f(cache, n)); &#125; public static int f(int[] cache, int n) &#123; if (cache[n] != -1) &#123; return cache[n]; &#125; cache[n] = f(cache, n - 1) + f(cache, n - 2); return cache[n]; &#125; 优化后的图示，只要结果被缓存，就不会执行其子问题 改进后的时间复杂度为 $O(n)$ 请自行验证改进后的效果 请自行分析改进后的空间复杂度 注意 记忆法是动态规划的一种情况，强调的是自顶向下的解决 记忆法的本质是空间换时间 递归优化-尾递归爆栈 用递归做 $n + (n-1) + (n-2) … + 1$ public static long sum(long n) &#123; if (n == 1) &#123; return 1; &#125; return n + sum(n - 1); &#125; 在我的机器上 $n &#x3D; 12000$ 时，爆栈了 Exception in thread &quot;main&quot; java.lang.StackOverflowError at Test.sum(Test.java:10) at Test.sum(Test.java:10) at Test.sum(Test.java:10) at Test.sum(Test.java:10) at Test.sum(Test.java:10) ... 为什么呢？ 每次方法调用是需要消耗一定的栈内存的，这些内存用来存储方法参数、方法内局部变量、返回地址等等 方法调用占用的内存需要等到方法结束时才会释放 而递归调用我们之前讲过，不到最深不会回头，最内层方法没完成之前，外层方法都结束不了 例如，$sum(3)$ 这个方法内有个需要执行 $3 + sum(2)$，$sum(2)$ 没返回前，加号前面的 $3$ 不能释放 看下面伪码 long sum(long n = 3) &#123; return 3 + long sum(long n = 2) &#123; return 2 + long sum(long n = 1) &#123; return 1; &#125; &#125; &#125; 尾调用 如果函数的最后一步是调用一个函数，那么称为尾调用，例如 function a() &#123; return b() &#125; 下面三段代码不能叫做尾调用 function a() &#123; const c = b() return c &#125; 因为最后一步并非调用函数 function a() &#123; return b() + 1 &#125; 最后一步执行的是加法 function a(x) &#123; return b() + x &#125; 最后一步执行的是加法 一些语言[^11]的编译器能够对尾调用做优化，例如 function a() &#123; // 做前面的事 return b() &#125; function b() &#123; // 做前面的事 return c() &#125; function c() &#123; return 1000 &#125; a() 没优化之前的伪码 function a() &#123; return function b() &#123; return function c() &#123; return 1000 &#125; &#125; &#125; 优化后伪码如下 a() b() c() 为何尾递归才能优化？ 调用 a 时 a 返回时发现：没什么可留给 b 的，将来返回的结果 b 提供就可以了，用不着我 a 了，我的内存就可以释放 调用 b 时 b 返回时发现：没什么可留给 c 的，将来返回的结果 c 提供就可以了，用不着我 b 了，我的内存就可以释放 如果调用 a 时 不是尾调用，例如 return b() + 1，那么 a 就不能提前结束，因为它还得利用 b 的结果做加法 尾递归 尾递归是尾调用的一种特例，也就是最后一步执行的是同一个函数 尾递归避免爆栈 安装 Scala Scala 入门 object Main &#123; def main(args: Array[String]): Unit = &#123; println(\"Hello Scala\") &#125; &#125; Scala 是 java 的近亲，java 中的类都可以拿来重用 类型是放在变量后面的 Unit 表示无返回值，类似于 void 不需要以分号作为结尾，当然加上也对 还是先写一个会爆栈的函数 def sum(n: Long): Long = &#123; if (n == 1) &#123; return 1 &#125; return n + sum(n - 1) &#125; Scala 最后一行代码若作为返回值，可以省略 return 不出所料，在 $n &#x3D; 11000$ 时，还是出了异常 println(sum(11000)) Exception in thread \"main\" java.lang.StackOverflowError at Main$.sum(Main.scala:25) at Main$.sum(Main.scala:25) at Main$.sum(Main.scala:25) at Main$.sum(Main.scala:25) ... 这是因为以上代码，还不是尾调用，要想成为尾调用，那么： 最后一行代码，必须是一次函数调用 内层函数必须摆脱与外层函数的关系，内层函数执行后不依赖于外层的变量或常量 def sum(n: Long): Long = &#123; if (n == 1) &#123; return 1 &#125; return n + sum(n - 1) // 依赖于外层函数的 n 变量 &#125; 如何让它执行后就摆脱对 n 的依赖呢？ 不能等递归回来再做加法，那样就必须保留外层的 n 把 n 当做内层函数的一个参数传进去，这时 n 就属于内层函数了 传参时就完成累加, 不必等回来时累加 sum(n - 1, n + 累加器) 改写后代码如下 @tailrec def sum(n: Long, accumulator: Long): Long = &#123; if (n == 1) &#123; return 1 + accumulator &#125; return sum(n - 1, n + accumulator) &#125; accumulator 作为累加器 @tailrec 注解是 scala 提供的，用来检查方法是否符合尾递归 这回 sum(10000000, 0) 也没有问题，打印 50000005000000 执行流程如下，以伪码表示 $sum(4, 0)$ // 首次调用 def sum(n = 4, accumulator = 0): Long = &#123; return sum(4 - 1, 4 + accumulator) &#125; // 接下来调用内层 sum, 传参时就完成了累加, 不必等回来时累加，当内层 sum 调用后，外层 sum 空间没必要保留 def sum(n = 3, accumulator = 4): Long = &#123; return sum(3 - 1, 3 + accumulator) &#125; // 继续调用内层 sum def sum(n = 2, accumulator = 7): Long = &#123; return sum(2 - 1, 2 + accumulator) &#125; // 继续调用内层 sum, 这是最后的 sum 调用完就返回最后结果 10, 前面所有其它 sum 的空间早已释放 def sum(n = 1, accumulator = 9): Long = &#123; if (1 == 1) &#123; return 1 + accumulator &#125; &#125; 本质上，尾递归优化是将函数的递归调用，变成了函数的循环调用 改循环避免爆栈 public static void main(String[] args) &#123; long n = 100000000; long sum = 0; for (long i = n; i >= 1; i--) &#123; sum += i; &#125; System.out.println(sum); &#125; 递归时间复杂度-Master theorem[^14]若有递归式$$T(n) &#x3D; aT(\\frac{n}{b}) + f(n)$$其中 $T(n)$ 是问题的运行时间，$n$ 是数据规模 $a$ 是子问题个数 $T(\\frac{n}{b})$ 是子问题运行时间，每个子问题被拆成原问题数据规模的 $\\frac{n}{b}$ $f(n)$ 是除递归外执行的计算 令 $x &#x3D; \\log_{b}{a}$，即 $x &#x3D; \\log_{子问题缩小倍数}{子问题个数}$ 那么$$T(n) &#x3D;\\begin{cases}\\Theta(n^x) &amp; f(n) &#x3D; O(n^c) 并且 c \\lt x\\\\Theta(n^x\\log{n}) &amp; f(n) &#x3D; \\Theta(n^x)\\\\Theta(n^c) &amp; f(n) &#x3D; \\Omega(n^c) 并且 c \\gt x\\end{cases}$$ 例1 $T(n) &#x3D; 2T(\\frac{n}{2}) + n^4$ 此时 $x &#x3D; 1 &lt; 4$，由后者决定整个时间复杂度 $\\Theta(n^4)$ 如果觉得对数不好算，可以换为求【$b$ 的几次方能等于 $a$】 例2 $T(n) &#x3D; T(\\frac{7n}{10}) + n$ $a&#x3D;1, b&#x3D;\\frac{10}{7}, x&#x3D;0, c&#x3D;1$ 此时 $x &#x3D; 0 &lt; 1$，由后者决定整个时间复杂度 $\\Theta(n)$ 例3 $T(n) &#x3D; 16T(\\frac{n}{4}) + n^2$ $a&#x3D;16, b&#x3D;4, x&#x3D;2, c&#x3D;2$ 此时 $x&#x3D;2 &#x3D; c$，时间复杂度 $\\Theta(n^2 \\log{n})$ 例4 $T(n)&#x3D;7T(\\frac{n}{3}) + n^2$ $a&#x3D;7, b&#x3D;3, x&#x3D;1.?, c&#x3D;2$ 此时 $x &#x3D; \\log_{3}{7} &lt; 2$，由后者决定整个时间复杂度 $\\Theta(n^2)$ 例5 $T(n) &#x3D; 7T(\\frac{n}{2}) + n^2$ $a&#x3D;7, b&#x3D;2, x&#x3D;2.?, c&#x3D;2$ 此时 $x &#x3D; log_2{7} &gt; 2$，由前者决定整个时间复杂度 $\\Theta(n^{\\log_2{7}})$ 例6 $T(n) &#x3D; 2T(\\frac{n}{4}) + \\sqrt{n}$ $a&#x3D;2, b&#x3D;4, x &#x3D; 0.5, c&#x3D;0.5$ 此时 $x &#x3D; 0.5 &#x3D; c$，时间复杂度 $\\Theta(\\sqrt{n}\\ \\log{n})$ 例7. 二分查找递归 int f(int[] a, int target, int i, int j) &#123; if (i > j) &#123; return -1; &#125; int m = (i + j) >>> 1; if (target &lt; a[m]) &#123; return f(a, target, i, m - 1); &#125; else if (a[m] &lt; target) &#123; return f(a, target, m + 1, j); &#125; else &#123; return m; &#125; &#125; 子问题个数 $a &#x3D; 1$ 子问题数据规模缩小倍数 $b &#x3D; 2$ 除递归外执行的计算是常数级 $c&#x3D;0$ $T(n) &#x3D; T(\\frac{n}{2}) + n^0$ 此时 $x&#x3D;0 &#x3D; c$，时间复杂度 $\\Theta(\\log{n})$ 例8. 归并排序递归 void split(B[], i, j, A[]) &#123; if (j - i &lt;= 1) return; m = (i + j) / 2; // 递归 split(A, i, m, B); split(A, m, j, B); // 合并 merge(B, i, m, j, A); &#125; 子问题个数 $a&#x3D;2$ 子问题数据规模缩小倍数 $b&#x3D;2$ 除递归外，主要时间花在合并上，它可以用 $f(n) &#x3D; n$ 表示 $T(n) &#x3D; 2T(\\frac{n}{2}) + n$ 此时 $x&#x3D;1&#x3D;c$，时间复杂度 $\\Theta(n\\log{n})$ 例9. 快速排序递归 algorithm quicksort(A, lo, hi) is if lo >= hi || lo &lt; 0 then return // 分区 p := partition(A, lo, hi) // 递归 quicksort(A, lo, p - 1) quicksort(A, p + 1, hi) 子问题个数 $a&#x3D;2$ 子问题数据规模缩小倍数 如果分区分的好，$b&#x3D;2$ 如果分区没分好，例如分区1 的数据是 0，分区 2 的数据是 $n-1$ 除递归外，主要时间花在分区上，它可以用 $f(n) &#x3D; n$ 表示 情况1 - 分区分的好 $T(n) &#x3D; 2T(\\frac{n}{2}) + n$ 此时 $x&#x3D;1&#x3D;c$，时间复杂度 $\\Theta(n\\log{n})$ 情况2 - 分区没分好 $T(n) &#x3D; T(n-1) + T(1) + n$ 此时不能用主定理求解 递归时间复杂度-展开求解像下面的递归式，都不能用主定理求解 例1 - 递归求和 long sum(long n) &#123; if (n == 1) &#123; return 1; &#125; return n + sum(n - 1); &#125; $T(n) &#x3D; T(n-1) + c$，$T(1) &#x3D; c$ 下面为展开过程 $T(n) &#x3D; T(n-2) + c + c$ $T(n) &#x3D; T(n-3) + c + c + c$ … $T(n) &#x3D; T(n-(n-1)) + (n-1)c$ 其中 $T(n-(n-1))$ 即 $T(1)$ 带入求得 $T(n) &#x3D; c + (n-1)c &#x3D; nc$ 时间复杂度为 $O(n)$ 例2 - 递归冒泡排序 void bubble(int[] a, int high) &#123; if(0 == high) &#123; return; &#125; for (int i = 0; i &lt; high; i++) &#123; if (a[i] > a[i + 1]) &#123; swap(a, i, i + 1); &#125; &#125; bubble(a, high - 1); &#125; $T(n) &#x3D; T(n-1) + n$，$T(1) &#x3D; c$ 下面为展开过程 $T(n) &#x3D; T(n-2) + (n-1) + n$ $T(n) &#x3D; T(n-3) + (n-2) + (n-1) + n$ … $T(n) &#x3D; T(1) + 2 + … + n &#x3D; T(1) + (n-1)\\frac{2+n}{2} &#x3D; c + \\frac{n^2}{2} + \\frac{n}{2} -1$ 时间复杂度 $O(n^2)$ 注： 等差数列求和为 $个数*\\frac{\\vert首项-末项\\vert}{2}$ 例3 - 递归快排 快速排序分区没分好的极端情况 $T(n) &#x3D; T(n-1) + T(1) + n$，$T(1) &#x3D; c$ $T(n) &#x3D; T(n-1) + c + n$ 下面为展开过程 $T(n) &#x3D; T(n-2) + c + (n-1) + c + n$ $T(n) &#x3D; T(n-3) + c + (n-2) + c + (n-1) + c + n$ … $T(n) &#x3D; T(n-(n-1)) + (n-1)c + 2+…+n &#x3D; \\frac{n^2}{2} + \\frac{2cn+n}{2} -1$ 时间复杂度 $O(n^2)$ 不会推导的同学可以进入 https://www.wolframalpha.com/ 例1 输入 f(n) &#x3D; f(n - 1) + c, f(1) &#x3D; c 例2 输入 f(n) &#x3D; f(n - 1) + n, f(1) &#x3D; c 例3 输入 f(n) &#x3D; f(n - 1) + n + c, f(1) &#x3D; c 附录参考文章[^1]: “Definition of ALGORITHM”. Merriam-Webster Online Dictionary. Archived from the original on February 14, 2020. Retrieved November 14, 2019.[^2]: Introduction to Algorithm 中文译作《算法导论》[^3]: 主要参考文档 https://en.wikipedia.org/wiki/Binary_search_algorithm[^4]: 图片及概念均摘自 Introduction to Algorithm 4th，3.1节，3.2 节[^5]: 图片引用自 wikipedia linkedlist 条目，https://en.wikipedia.org/wiki/Linked_list [^6]: 也称为 Pascal’s triangle https://en.wikipedia.org/wiki/Pascal%27s_triangle [^7]: 递归求解斐波那契数列的时间复杂度——几种简洁证明 - 知乎 (zhihu.com)[^8]: Fibonacci 介绍：https://en.wikipedia.org/wiki/Fibonacci_number[^9]: 几种计算Fibonacci数列算法的时间复杂度比较 - 知乎 (zhihu.com)[^10]: 几种斐波那契数列算法比较 Fast Fibonacci algorithms (nayuki.io) [^11]: 我知道的有 C++，Scala[^12]: jdk 版本有关，64 位 jdk，按 8 字节对齐[^13]: 汉诺塔图片资料均来自 https://en.wikipedia.org/wiki/Tower_of_Hanoi[^14]: 与主定理类似的还有 Akra–Bazzi method，https://en.wikipedia.org/wiki/Akra%E2%80%93Bazzi_method [^15]: 龟兔赛跑动画来自于 Floyd’s Hare and Tortoise Algorithm Demo - One Step! Code (onestepcode.com) [^16]: Josephus problem 主要参考 https://en.wikipedia.org/wiki/Josephus_problem","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"author":"ehzyil"},{"title":"标签插件","slug":"2023/标签插件","date":"2023-10-10T00:00:00.000Z","updated":"2024-01-06T04:54:46.215Z","comments":true,"path":"2023/10/10/2023/标签插件/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/10/2023/%E6%A0%87%E7%AD%BE%E6%8F%92%E4%BB%B6/","excerpt":"","text":"noteblock演示效果可以在区块中放置一些复杂的结构，支持嵌套。 标题（可选）Windows 10不是為所有人設計,而是為每個人設計嵌套测试： 请坐和放宽，我正在帮你搞定一切… Folding 测试： 点击查看更多 不要说我们没有警告过你我们都有不顺利的时候 &#123;% noteblock::标题（可选） %&#125; Windows 10不是為所有人設計,而是為每個人設計 &#123;% noteblock done %&#125; 嵌套测试： 请坐和放宽，我正在帮你搞定一切... &#123;% endnoteblock %&#125; &#123;% folding yellow::Folding 测试： 点击查看更多 %&#125; &#123;% note warning::不要说我们没有警告过你 %&#125; &#123;% noteblock bug red %&#125; 我们都有不顺利的时候 &#123;% endnoteblock %&#125; &#123;% endfolding %&#125; &#123;% endnoteblock %&#125; 可以支持的参数&#123;% checkbox 纯文本测试 %&#125; &#123;% checkbox checked::支持简单的 [markdown](https:&#x2F;&#x2F;guides.github.com&#x2F;features&#x2F;mastering-markdown&#x2F;) 语法 %&#125; &#123;% checkbox red::支持自定义颜色 %&#125; &#123;% checkbox green checked::绿色 + 默认选中 %&#125; &#123;% checkbox yellow checked::黄色 + 默认选中 %&#125; &#123;% checkbox cyan checked::青色 + 默认选中 %&#125; &#123;% checkbox blue checked::蓝色 + 默认选中 %&#125; &#123;% checkbox plus green checked::增加 %&#125; &#123;% checkbox minus yellow checked::减少 %&#125; &#123;% checkbox times red checked::叉 %&#125; checkbox&#123;% checkbox 样式参数（可选）::文本（支持简单md） %&#125; 演示效果 纯文本测试 支持简单的 markdown 语法 支持自定义颜色 绿色 + 默认选中 黄色 + 默认选中 青色 + 默认选中 蓝色 + 默认选中 增加 减少 叉 上述示例的源码&#123;% checkbox 纯文本测试 %&#125; &#123;% checkbox checked::支持简单的 [markdown](https:&#x2F;&#x2F;guides.github.com&#x2F;features&#x2F;mastering-markdown&#x2F;) 语法 %&#125; &#123;% checkbox red::支持自定义颜色 %&#125; &#123;% checkbox green checked::绿色 + 默认选中 %&#125; &#123;% checkbox yellow checked::黄色 + 默认选中 %&#125; &#123;% checkbox cyan checked::青色 + 默认选中 %&#125; &#123;% checkbox blue checked::蓝色 + 默认选中 %&#125; &#123;% checkbox plus green checked::增加 %&#125; &#123;% checkbox minus yellow checked::减少 %&#125; &#123;% checkbox times red checked::叉 %&#125; 可以支持的参数颜色red, yellow, green, cyan, blue 样式plus, minus, times 选中状态checked timeline&#123;% timeline 时间线标题（可选） %&#125; &#123;% timenode 时间节点（标题） %&#125; 正文内容 &#123;% endtimenode %&#125; &#123;% timenode 时间节点（标题） %&#125; 正文内容 &#123;% endtimenode %&#125; &#123;% endtimeline %&#125; 2020-07-24 2.6.6 -&gt; 3.0 如果有 hexo-lazyload-image 插件，需要删除并重新安装最新版本，设置 lazyload.isSPA: true。2.x 版本的 css 和 js 不适用于 3.x 版本，如果使用了 use_cdn: true 则需要删除。2.x 版本的 fancybox 标签在 3.x 版本中被重命名为 gallery 。2.x 版本的置顶 top: true 改为了 pin: true，并且同样适用于 layout: page 的页面。如果使用了 hexo-offline 插件，建议卸载，3.0 版本默认开启了 pjax 服务。 2020-05-15 2.6.3 -&gt; 2.6.6 不需要额外处理。 2020-04-20 2.6.2 -&gt; 2.6.3 全局搜索 seotitle 并替换为 seo_title。group 组件的索引规则有变，使用 group 组件的文章内，group: group_name 对应的组件名必须是 group_name。group 组件的列表名优先显示文章的 short_title 其次是 title。 link最后更新于 5.0 版本&#123;% link 标题::链接::图片链接（可选） %&#125; 如何参与项目https://volantis.js.org/contributors/ site网站卡片可以显示网站截图、logo、标题、描述，使用方法和 友链标签 一模一样，唯一的区别是数据文件名称为 sites.yml，可以和友链数据混用，通过分组过滤实现不一样的效果。 最后更新于 5.0 版本&#123;% sites [筛选方式]:[组名] %&#125; 演示效果volantis_developervolantis_developerxaoxuuhttps://github.com/xaoxuuMHuiGhttps://github.com/MHuiGinksshttps://github.com/inkssColsrchhttps://github.com/ColsrchDrew233https://github.com/Drew233Linhk1606https://github.com/Linhk1606W4J1ehttps://github.com/W4J1e community_builderxaoxuuhttps://github.com/xaoxuuMHuiGhttps://github.com/MHuiGColsrchhttps://github.com/Colsrchpennduhttps://github.com/penndu 上述示例的源码&#123;% sites only:community_team %&#125; 可以支持的参数数据按组筛选支持分组（白名单模式和黑名单模式）显示: &#x2F;&#x2F; 显示 communtiy_team &#123;% sites only:communtiy_team %&#125; &#x2F;&#x2F; 除了 communtiy_team 别的都显示 &#123;% sites not:community_team %&#125; &#x2F;&#x2F; 多个分组使用 &#96;,&#96; 分隔 &#123;% sites only:communtiy_team, communtiy_builder %&#125; 友链标签您可以在任何位置插入友链，支持静态数据和动态数据，静态数据需要写在数据文件中： 标题和描述都支持 md 格式，需要写在引号中。如果指定了 api 和 repo 字段，则从 issues 中取第一个 json 代码块数据作为友链。 &#123;% friends %&#125; 数据按组筛选友链支持分组（白名单模式和黑名单模式）显示： &#x2F;&#x2F; 显示 volantis_developer &#123;% friends only:volantis_developer %&#125; &#x2F;&#x2F; 显示 volantis_developer 和 community_builder &#123;% friends only:volantis_developer,community_builder %&#125; &#x2F;&#x2F; 除了 community_builder 别的都显示 &#123;% friends not:community_builder %&#125; &#x2F;&#x2F; 显示 volantis_developer volantis_developervolantis_developerxaoxuuMHuiG &#x2F;&#x2F; 显示 volantis_developer 和 community_builder volantis_developervolantis_developerxaoxuuMHuiGxaoxuuMHuiGColsrch &#x2F;&#x2F; 除了 community_builder 别的都显示 volantis_developervolantis_developerxaoxuuMHuiG tab此插件移植自 NexT #tabs 最后更新于 2.1 版本&#123;% tabs 页面内不重复的ID %&#125; &lt;!-- tab 栏目1 --&gt; 内容 &lt;!-- endtab --&gt; &lt;!-- tab 栏目2 --&gt; 内容 &lt;!-- endtab --&gt; &#123;% endtabs %&#125; 栏目1栏目2。。。！！！ 上述示例的源码&#123;% tabs tab-id %&#125; &lt;!-- tab 栏目1 --&gt; 。。。 &lt;!-- endtab --&gt; &lt;!-- tab 栏目2 --&gt; ！！！ &lt;!-- endtab --&gt; &#123;% endtabs %&#125; folding最后更新于 5.0 版本&#123;% folding 参数（可选）::标题 %&#125; ![](https:&#x2F;&#x2F;gcore.jsdelivr.net&#x2F;gh&#x2F;volantis-x&#x2F;cdn-wallpaper&#x2F;abstract&#x2F;41F215B9-261F-48B4-80B5-4E86E165259E.jpeg) &#123;% endfolding %&#125; 演示效果 查看图片测试 查看默认打开的折叠框 这是一个默认打开的折叠框。 查看代码测试 查看列表测试 hahahehe 查看嵌套测试 查看嵌套测试2 查看嵌套测试3 hahaha 上述示例的源码&#123;% folding 查看图片测试 %&#125; ![](https:&#x2F;&#x2F;gcore.jsdelivr.net&#x2F;gh&#x2F;volantis-x&#x2F;cdn-wallpaper&#x2F;abstract&#x2F;41F215B9-261F-48B4-80B5-4E86E165259E.jpeg) &#123;% endfolding %&#125; &#123;% folding cyan open::查看默认打开的折叠框 %&#125; 这是一个默认打开的折叠框。 &#123;% endfolding %&#125; &#123;% folding green::查看代码测试 %&#125; &#123;% endfolding %&#125; &#123;% folding yellow::查看列表测试 %&#125; - haha - hehe &#123;% endfolding %&#125; &#123;% folding red::查看嵌套测试 %&#125; &#123;% folding blue::查看嵌套测试2 %&#125; &#123;% folding 查看嵌套测试3 %&#125; hahaha &lt;span&gt;&lt;img src&#x3D;&#39;https:&#x2F;&#x2F;gcore.jsdelivr.net&#x2F;gh&#x2F;volantis-x&#x2F;cdn-emoji&#x2F;tieba&#x2F;%E6%BB%91%E7%A8%BD.png&#39; style&#x3D;&#39;height:24px&#39;&gt;&lt;&#x2F;span&gt; &#123;% endfolding %&#125; &#123;% endfolding %&#125; &#123;% endfolding %&#125; 可以支持的参数参数位置可以填写颜色和状态，多个参数用空格隔开。 颜色blue, cyan, green, yellow, red 状态状态填写 open 代表默认打开。 From 标签插件","categories":[],"tags":[{"name":"标签插件","slug":"标签插件","permalink":"https://blog.ehzyil.xyz/tags/%E6%A0%87%E7%AD%BE%E6%8F%92%E4%BB%B6/"}],"author":"ehzyil"},{"title":"Java 中常用的日期类","slug":"2023/Java 中常用的日期类","date":"2023-10-09T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/10/09/2023/Java 中常用的日期类/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/09/2023/Java%20%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%97%A5%E6%9C%9F%E7%B1%BB/","excerpt":"","text":"Java 中常用的日期类一、 java.util.Date**System.currentTimeMillis()**：返回当前时间与格林威治时间 1970-01-01 00:00:00 （北京时间：1970-01-01 08:00:00）之间以毫秒为单位的时间差。此方法适用于计算时间差 // 1687936118101 时间戳 Long time = System.currentTimeMillis(); System.currentTimeMillis() 方法的返回类型是 Long 类型。一般用于获取某个方法或其它的执行时间差。即：在开始前获取一次，在结束时获取一次，结束时间减去开始时间，得到执行时间。如： Long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; System.out.print(\"*\"); &#125; Long endTime = System.currentTimeMillis(); Long result = endTime - startTime; System.out.println(\"用时：\"+result); 时间戳与 java.util.Date 类互相转换： // 时间戳转换为 Date 类型 Date date = new Date(time); System.out.println(date); // Date 类型转换为时间戳 Long time = new Date().getTime(); System.out.println(time); 一般 java.util.Date 类与 java.text.SimpleDateFormat 类一起用，用于格式化日期。 如：将日期与字符串互转： // 格式化时间 SimpleDateFormat sdf=new SimpleDateFormat(\"yyyy-MM-dd HH时mm分ss秒\"); System.out.println(sdf.format(new Date())); // 将字符串转换为日期： String pattern= \"yyyy-MM-dd HH:mm:ss\"; String time = \"2022-07-18 22:53:22\"; SimpleDateFormat simpleDateFormat=new SimpleDateFormat(pattern); try &#123; Date date=simpleDateFormat.parse(time); System.out.println(date); &#125; catch (Exception e) &#123; throw new RuntimeException(\"日期格式化错误！！，日期为：\" + time); &#125; 注意：将字符串转换为日期时 pattern要对应。 二. java.sql.Datejava.sql.Date 是 java.util.Date 类的子类；是针对 SQL 语句使用的，它只包含日期而没有时间部分，一般在读写数据库的时候用，PreparedStament#setDate() 方法的参数和 ResultSet#getDate() 方法的都是 java.sql.Date。 Date date=new Date(0L); System.out.println(date); //1970-01-01 java.util.Date 与 java.sql.Date 互相转换： java.util.Date utilDate=new java.util.Date(); System.out.println(utilDate); //Wed Jun 28 15:45:45 CST 2023 java.sql.Date sqldate=new Date(utilDate.getTime()); System.out.println(sqldate); //2023-06-28 三. java.util.Calendarjava.util.Calendar：日历类，是个抽象类 Calendar 实例化的方法： 创建其子类 GregorianCalendar 的对象 调用其静态方法 getInstance() 从下列方法可以得出两种实例化方法一样 Calendar calendar&#x3D;Calendar.getInstance(); System.out.println(calendar.getClass()); &#x2F;&#x2F;class java.util.GregorianCalendar Calendar GregorianCalendar&#x3D;new GregorianCalendar(); System.out.println(calendar.getClass()&#x3D;&#x3D;GregorianCalendar.getClass()); &#x2F;&#x2F;true 常用的方法： get(int field)：获取某个时间set()：设置某个时间add()：在某个时间上，加上某个时间getTime()：将 Calendar 类转换为 Date 类setTime()：将 Date 类转换为 Calendar 类field 取值有： DAY_OF_MONTH：这个月的第几天DAY_OF_YEAR：这年的第几天…注意： 获取月份时：一月是 0，二月是1，…获取星期时：周日是1，周一是2，… getTime() 方法 源码 public final Date getTime() &#123; return new Date(getTimeInMillis()); &#125; Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getTime()); //Wed Jun 28 16:04:30 CST 2023 public int get(int field)方法 Calendar calendar=Calendar.getInstance(); System.out.println(calendar.getTime()); //Wed Jun 28 15:59:38 CST 2023 calendar.set(Calendar.DAY_OF_MONTH, 5); //将当前时间设置成某个时间 System.out.println(calendar.get(Calendar.DAY_OF_MONTH)); //1 System.out.println(calendar.getTime()); //Thu Jun 01 15:59:38 CST 2023 set(int field, int value)方法 Calendar calendar=Calendar.getInstance(); System.out.println(calendar.getTime()); calendar.set(Calendar.DAY_OF_MONTH, 1); //将当前时间设置成某个时间 System.out.println(calendar.get(Calendar.DAY_OF_MONTH)); System.out.println(calendar.getTime()); add(int field, int amount)方法 Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getTime()); //Wed Jun 28 16:04:30 CST 2023 // 给当前时间加上 5 天 calendar.add(Calendar.DAY_OF_MONTH, +5); System.out.println(calendar.getTime()); //Mon Jul 03 16:04:30 CST 2023 // 给当前时间加上 2 月 calendar.add(Calendar.MONTH, 2); System.out.println(calendar.getTime()); //Sun Sep 03 16:04:30 CST 2023 // 给当前时间减去 3 天 calendar.add(Calendar.DAY_OF_MONTH, -3); System.out.println(calendar.getTime()); //Thu Aug 31 16:04:30 CST 2023 setTime(Date date) 方法 源码 public final void setTime(Date date) &#123; setTimeInMillis(date.getTime()); &#125; 四、java.time APIjava.time API 背景java.util.Date、java.util.Calendar 面临的问题： 1.可变性：像日期、时间这样的类应该是不可变的 2.偏移性：Date 中的年份是从 1900 年开始的；月份是从 0 开始的 3.格式化：格式化只对 Date 有用，而对 Calendar 则不行 4.线程安全：它们都不是线程安全 java.time 中包含了： LocalDate：本地日期。yyyy-MM-dd 格式的日期。可以存储生日、纪念日等 LocalTime：本地时间。代表的是时间，不是日期 LocalDateTime：本地日期时间 ZonedDateTime：时区 Duration：持续时间 大大地简化了对日期、时间的操作 java.time API 中常用的 API now()：获取当前时间、日期 of()：获取指定的日期、时间 getXxx()：获取值 withXxx()：设置值 plusXxx()：加 minusXxx()：减 now() 获取当前日期 LocalDate localDate = LocalDate.now(); LocalTime localTime = LocalTime.now(); LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDate);//2023-06-28 System.out.println(localTime);//16:17:21.720 System.out.println(localDateTime);//2023-06-28T16:17:21.720 localDate：表示当前的日期localTime：表示当前的时间localDateTime：表示当前的日期时间 of() 指定一个特定的日期 //给出时间参数，表示出日期和时间 再生成localDateTime对象返回 public static LocalDateTime of(int year, Month month, int dayOfMonth, int hour, int minute) &#123; LocalDate date = LocalDate.of(year, month, dayOfMonth); LocalTime time = LocalTime.of(hour, minute); return new LocalDateTime(date, time); &#125; LocalDateTime localDateTime = LocalDateTime.of(2035,10,1,10,00); System.out.println(localDateTime); //2035-10-01T10:00 getXxx() withXxx() 每次修改，返回的是一个新对象，部分源码如下。 private LocalDateTime with(LocalDate newDate, LocalTime newTime) &#123; ... return new LocalDateTime(newDate, newTime); &#125; LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDateTime); //2023-06-28T16:35:38.764 LocalDateTime dayOfMonth = localDateTime.withDayOfMonth(25); System.out.println(dayOfMonth); //2023-06-25T16:35:38.764 plusXxx() 该方法每次调用返回时调用withXxx()方法，因此每次修改，返回的也是一个新对象。 LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDateTime); //2023-06-28T16:38:55.066 LocalDateTime localDateTime1 = localDateTime.plusDays(2); System.out.println(localDateTime1); //2023-06-30T16:38:55.066 LocalDateTime localDateTime2 = localDateTime.plusMonths(-1); System.out.println(localDateTime2); //2023-05-28T16:38:55.066 minusXxx() 调用plusXxx()把传入的值取反。 public LocalDateTime minusDays(long days) &#123; return (days == Long.MIN_VALUE ? plusDays(Long.MAX_VALUE).plusDays(1) : plusDays(-days)); &#125; 五、java.time.format.DateTimeFormatterjava.time.format.DateTimeFormatter：格式化、解析日期或时间（类似于：SimpleDateFormat） 此类提供了三种格式化方法： 预定义的标准格式：ISO_LOCAL_DATE_TIME… 本地化相关的格式： 自定义格式：ofPattern(“yyyy-MM-dd HH:mm:ss”) LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDateTime); //2023-06-28T16:50:06.649 DateTimeFormatter dtf=DateTimeFormatter.ofPattern(\"yyyy/MM/dd HH:mm:ss\"); System.out.println(dtf.format(localDateTime)); //2023/06/28 16:50:06 六、java.time.InstantInstant：时间线上的一个瞬时点。 在UNIX中，这个数从1970年开始，以秒为的单位；同样的，在Java中，也是从1970年开始，但以毫秒为单位。java.time包通过值类型Instant提供机器视图，不提供处理人类意义上的时间单位。 Instant表示时间线上的一点，而不需要任何上下文信息，例如，时区。概念上讲， 它只是简单的表示自1970年1月1日0时0分0秒（ UTC）开始的秒数。 因为java.time包是基于纳秒计算的，所以Instant的精度可以达到纳秒级。 方法 描述 now() 静态方法， 返回默认UTC时区的Instant类的对象 ofEpochMilli(long epochMilli) 静态方法，返回在 1970-01-01 00:00:00基础上加上指定毫秒数之后的Instant 类的对象 atOffset(ZoneOffset offset) 结合即时的偏移来创建一个 OffsetDateTime toEpochMilli() 返回1970-01-01 00:00:00到当前时间的毫秒数， 即为时间戳 //now():获取本初子午线对应的标准时间，所以和我们当前的时间约有8个小时的时差。 Instant now = Instant.now(); System.out.println(now);//2023-06-28T09:52:51.124Z //添加时间的偏移量 OffsetDateTime offsetDateTime = now.atOffset(ZoneOffset.ofHours(8)); System.out.println(offsetDateTime);//2023-06-28T17:52:51.124+08:00 //toEpochMilli():获取自1970年1月1日0时0分0秒（UTC）开始的毫秒数 ---> Date类的getTime() long milli = now.toEpochMilli(); System.out.println(milli);//1687945971124 //ofEpochMilli():通过给定的毫秒数，获取Instant实例 -->Date(long millis) Instant instant = Instant.ofEpochMilli(System.currentTimeMillis()); System.out.println(instant);//2023-06-28T09:52:51.131Z 七、java.time.temporal.TemporalJava的Temporal类是Java 8引入的日期和时间API的一部分，它是一个抽象类，用于处理各种日期和时间对象。下面是Temporal类的一些常用方法以及对应的例子： of(TemporalField field, long value)：使用指定的字段和值创建一个Temporal对象。 LocalDate date = LocalDate.of(2023, 6, 28); get(TemporalField field)：获取指定字段的值。 int year = LocalDate.now().get(ChronoField.YEAR); with(TemporalField field, long newValue)：将指定字段的值设置为新值，返回一个新的Temporal对象。 LocalDate newDate = LocalDate.now().with(ChronoField.MONTH_OF_YEAR, 7); plus(TemporalAmount amountToAdd)：在当前Temporal对象上添加指定的时间量。 LocalDateTime dateTime = LocalDateTime.now().plus(Duration.ofHours(2)); minus(TemporalAmount amountToSubtract)：在当前Temporal对象上减去指定的时间量。 LocalTime newTime = LocalTime.now().minus(Duration.ofMinutes(30)); isSupported(TemporalUnit unit)：检查指定的时间单位是否支持。 boolean isSupported = LocalDateTime.now().isSupported(ChronoUnit.DAYS); until(Temporal endExclusive, TemporalUnit unit)：计算当前Temporal对象与指定Temporal对象之间的时间间隔。 long daysBetween = LocalDate.of(2023, 12, 31).until(LocalDate.now(), ChronoUnit.DAYS); format(DateTimeFormatter formatter)：使用指定的日期时间格式化器将Temporal对象格式化为字符串。 String formattedDate = LocalDate.now().format(DateTimeFormatter.ofPattern(\"dd-MM-yyyy\")); 这些只是Temporal类的一些常用方法和示例。Temporal类还有其他方法，可以根据具体的需求进行查阅和使用。 案例在 Java 8 中获取年、月、日信息//在 Java 8 中获取年、月、日信息 LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDateTime); //2023-06-28T16:56:25.874 int year = localDateTime.getYear(); System.out.println(year); //2023 Month month = localDateTime.getMonth(); System.out.println(month); //JUNE int day = localDateTime.getDayOfMonth(); System.out.println(day); //28 //某日期 一年中的第几天 int dayOfYear = localDateTime.getDayOfYear(); System.out.println(dayOfYear); //179 在 Java 8 中处理特定日期LocalDateTime dateTime = LocalDateTime.of(2023, 6, 28, 16, 0, 0); // 2023-06-28T16:00 System.out.println(dateTime); 在 Java 8 中判断两个日期是否相等LocalDate localDate=LocalDate.now(); LocalDate nowDate=LocalDate.of(2023,6,28); System.out.println(localDate.equals(nowDate)); //true 在 Java 8 中检查像生日这种周期性事件LocalDate now = LocalDate.now(); LocalDate dateOfBirth = LocalDate.of(2001, 2, 17); MonthDay birthday = MonthDay.of(dateOfBirth.getMonth(), dateOfBirth.getDayOfMonth()); MonthDay currentMonthDay = MonthDay.from(now); if (currentMonthDay.equals(birthday)) &#123; System.out.println(\"Happy Birthday\"); &#125; else &#123; System.out.println(\"Sorry, today is not your birthday\"); &#125; //Sorry, today is not your birthday 如何计算一周后的日期LocalDate 日期不包含时间信息，它的 plus() 方法用来增加天、周、月，ChronoUnit 类声明了这些时间单位。由于 LocalDate 也是不变类型，返回后一定要用变量赋值。minus() 方法用来减去天、周、月等 //1.8之前的方法 //一周后的日期 SimpleDateFormat formatDate = new SimpleDateFormat(\"yyyy-MM-dd\"); Calendar ca = Calendar.getInstance(); ca.add(Calendar.DATE, 7); Date d = ca.getTime(); String after0 = formatDate.format(d); System.out.println(\"一周后日期：\" + after0); //1.8之后的方法 //一周后的日期 LocalDate localDate = LocalDate.now(); //方法1 LocalDate after = localDate.plus(1, ChronoUnit.WEEKS); //方法2 LocalDate after2 = localDate.plusWeeks(1); System.out.println(\"一周后日期：\" + after); /** * 一周后日期：2023-07-07 * 一周后日期：2023-07-07 */ 如何用 Java 判断日期或时间是早于还是晚于另一个日期或时间//日期的比较 LocalDate localDate=LocalDate.now(); System.out.println(localDate);//2023-06-28 LocalDate dateTime = LocalDate.of(2023, 6, 29); boolean before = dateTime.isBefore(localDate); System.out.println(before); boolean after = dateTime.isAfter(localDate); System.out.println(after); //时间的比较 LocalTime localTime=LocalTime.now(); System.out.println(localTime);//17:13:12.341 LocalTime time = LocalTime.of(19, 00, 00); boolean timeAfter = localTime.isAfter(time); System.out.println(timeAfter); boolean timeBefore = localTime.isBefore(time); System.out.println(timeBefore); 如何表示信用卡到期这类固定日期YearMonth currentYearMonth = YearMonth.now(); System.out.printf(\"Days in month year %s has %d days %n\", currentYearMonth, currentYearMonth.lengthOfMonth()); //Days in month year 2023-06 has 30 days //返回到期日期 YearMonth creditCardExpiry = YearMonth.of(2023, Month.OCTOBER); System.out.printf(\"Your credit card expires on %s %n\", creditCardExpiry); //Your credit card expires on 2023-10 //返回月底的本地日期 System.out.println(currentYearMonth.atEndOfMonth()); //2023-06-30 //获取有多少月份 System.out.println(currentYearMonth.lengthOfMonth()); //30 计算两个日期之间的天数和月数1.8之前 //算两个日期间隔多少天，计算间隔多少年，多少月方法类似 String dates1 = \"2023-12-23\"; String dates2 = \"2023-02-26\"; SimpleDateFormat format = new SimpleDateFormat(\"yyyy-MM-dd\"); Date date1 = format.parse(dates1); Date date2 = format.parse(dates2); int day = (int) ((date1.getTime() - date2.getTime()) / (1000 * 3600 * 24)); System.out.println(dates1 + \"和\" + dates2 + \"相差\" + day + \"天\"); //2023-12-23和2023-02-26相差300天 1.8之后 用 java.time.Period 类来做计算 LocalDate now = LocalDate.now(); LocalDate date = LocalDate.of(2025, Month.JUNE, 5); //计算两日期间相差多少天 long day = Math.abs(now.toEpochDay() - date.toEpochDay()); System.out.println(now + \"和\" + date + \"相差\" + day + \"天\"); System.out.println(\"====================\"); Period period = Period.between(now, date); //若第一个日期晚于第二个日期 则返回早日期距较晚日期的天数 //这里period.getDays()得到的天是抛去年月以外的天数，并不是总天数 //月是抛去年以外的月数 System.out.printf(\"离下个时间还有 %s年,%s月,%s天\", period.getYears() ,period.getMonths(),period.getDays()); 计算两日期间相差的月份 ChronoUnit.MONTHS.between(temporal1, temporal2)本质上是调用Temporal的util方法。 Temporal temporal1 = LocalDate.parse(\"2023-06-10\", DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); Temporal temporal2 = LocalDate.now(); //方法返回为相差月份 long monthsDifference = ChronoUnit.MONTHS.between(temporal1, temporal2); //月份差转为正数 monthsDifference = Math.abs(monthsDifference); if (monthsDifference == 0) &#123; System.out.println(\"当月为宽带最后一个月\"); &#125; else if (monthsDifference == 1) &#123; System.out.println(\"下月为宽带最后一个月\"); &#125; else &#123; System.out.println(\"宽带还有更多时间\"); &#125; 可以计算两日期间相差的天数，但要注意两日期 Temporal temporal1 = LocalDate.parse(\"2023-06-10\", DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); Temporal temporal2 = LocalDate.now(); long daysDifference = ChronoUnit.DAYS.between(temporal1, temporal2); daysDifference = Math.abs(daysDifference); System.out.println(daysDifference); //18 获取指定日期Java 8 之前: public void getDay() &#123; SimpleDateFormat format = new SimpleDateFormat(\"yyyy-MM-dd\"); //获取当前月第一天： Calendar c = Calendar.getInstance(); c.set(Calendar.DAY_OF_MONTH, 1); String first = format.format(c.getTime()); System.out.println(\"first day:\" + first); //获取当前月最后一天 Calendar ca = Calendar.getInstance(); ca.set(Calendar.DAY_OF_MONTH, ca.getActualMaximum(Calendar.DAY_OF_MONTH)); String last = format.format(ca.getTime()); System.out.println(\"last day:\" + last); //当年最后一天 Calendar currCal = Calendar.getInstance(); Calendar calendar = Calendar.getInstance(); calendar.clear(); calendar.set(Calendar.YEAR, currCal.get(Calendar.YEAR)); calendar.roll(Calendar.DAY_OF_YEAR, -1); Date time = calendar.getTime(); System.out.println(\"last day:\" + format.format(time)); &#125; Java 8 之后: LocalDate today = LocalDate.now(); //获取当前月第一天： LocalDate firstDayOfThisMonth = today.with(TemporalAdjusters.firstDayOfMonth()); // 取本月最后一天 LocalDate lastDayOfThisMonth = today.with(TemporalAdjusters.lastDayOfMonth()); //下一个月的第一天 LocalDate firstDayOfNextMonth = today.with(TemporalAdjusters.firstDayOfNextMonth()); //取下一天： LocalDate nextDay = lastDayOfThisMonth.plusDays(1); LocalDate nextDay1 = lastDayOfThisMonth.plus(1,ChronoUnit.DAYS); //当年的第一天 LocalDate firstDayOfYear = today.with(TemporalAdjusters.firstDayOfYear()); //当年最后一天 LocalDate lastday = today.with(TemporalAdjusters.lastDayOfYear()); //下一年的第一天 LocalDate firstDayOfNextYear = today.with(TemporalAdjusters.firstDayOfNextYear()); //2021年最后一个周日，如果用Calendar是不得烦死。 LocalDate lastMondayOf2021 = LocalDate.parse(\"2024-6-30\").with(TemporalAdjusters.lastInMonth(DayOfWeek.SUNDAY)); 获取指定日期的0点以及24点// 返回时间格式如：2020-02-17 00:00:00 public static String getStartOfDay(Date time) &#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(time); calendar.set(Calendar.HOUR_OF_DAY, 0); calendar.set(Calendar.MINUTE, 0); calendar.set(Calendar.SECOND, 0); calendar.set(Calendar.MILLISECOND, 0); return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(calendar.getTime()); &#125; // 返回时间格式如：2020-02-19 23:59:59 public static String getEndOfDay(Date time) &#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(time); calendar.set(Calendar.HOUR_OF_DAY, 23); calendar.set(Calendar.MINUTE, 59); calendar.set(Calendar.SECOND, 59); calendar.set(Calendar.MILLISECOND, 999); return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(calendar.getTime()); &#125; // 获取30天以前的时间，同样是比较常用的 public static String getThirtyDaysAgo(Date time) &#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(time); calendar.add(calendar.DATE, -30); calendar.set(Calendar.HOUR_OF_DAY, 0); calendar.set(Calendar.MINUTE, 0); calendar.set(Calendar.SECOND, 0); calendar.set(Calendar.MILLISECOND, 0); return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(calendar.getTime()); &#125; // 获得某天最大时间 2020-02-19 23:59:59 public static Date getEndOfDay(Date date) &#123; LocalDateTime localDateTime = LocalDateTime.ofInstant(Instant.ofEpochMilli(date.getTime()), ZoneId.systemDefault());; LocalDateTime endOfDay = localDateTime.with(LocalTime.MAX); return Date.from(endOfDay.atZone(ZoneId.systemDefault()).toInstant()); &#125; // 获得某天最小时间 2020-02-17 00:00:00 public static Date getStartOfDay(Date date) &#123; LocalDateTime localDateTime = LocalDateTime.ofInstant(Instant.ofEpochMilli(date.getTime()), ZoneId.systemDefault()); LocalDateTime startOfDay = localDateTime.with(LocalTime.MIN); return Date.from(startOfDay.atZone(ZoneId.systemDefault()).toInstant()); &#125; Date now &#x3D; new Date(); &#x2F;&#x2F;获取当前时间 SimpleDateFormat sdf &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); String nowStr &#x3D; sdf.format(now)+&quot; 00:00:00&quot;; &#x2F;&#x2F;得到今天凌晨时间 Calendar calendar &#x3D; Calendar.getInstance(); calendar.setTime(now); calendar.add(Calendar.DAY_OF_MONTH, +1);&#x2F;&#x2F;+1今天的时间加一天 String tomorrow &#x3D; sdf.format(calendar.getTime())+&quot; 00:00:00&quot;; &#x2F;&#x2F;得到明天凌晨的时间","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"}],"author":"ehzyil"},{"title":"Java8特性","slug":"2023/Java8特性","date":"2023-10-09T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/10/09/2023/Java8特性/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/09/2023/Java8%E7%89%B9%E6%80%A7/","excerpt":"","text":"functional interface 函数式接口函数式接口介绍定义：也称 SAM 接口，即 Single Abstract Method interfaces，有且只有一个抽象方法，但可以有多个非抽象方法的接口。 在 java 8 中专门有一个包放函数式接口java.util.function，该包下的所有接口都有 @FunctionalInterface 注解，提供函数式编程。 在其他包中也有函数式接口，其中一些没有@FunctionalInterface 注解，但是只要符合函数式接口的定义就是函数式接口，与是否有@FunctionalInterface注解无关，注解只是在编译时起到强制规范定义的作用。其在 Lambda 表达式中有广泛的应用。 Java内置的函数式接口介绍及使用举例 函数式接口 参数类型 返回类型 用途 Consumer 消费型接口 T void 对类型为T的对象应用操作，包含方法：void accept(T t) Supplier 供给型接口 无 T 返回类型为T的对象，包含方法：T get() Function函数型接口 T R 对类型为T的对象应用操作，并返回结果。结果是R类型的对象。包含方法：R apply(T t) Predicate断定型接口 T boolean 确定类型为T的对象是否满足某约束，并返回boolean 值。包含方法：boolean test(T t) BiFunction T, U R 对类型为T,U参数应用操作，返回R类型的结果。包含方法为：Rapply(T t,U u); UnaryOperator(Function子接口) T T 对类型为T的对象进行一元运算，并返回T类型的结果。包含方法为：Tapply(T t); BinaryOperator(BiFunction子接口) T,T T 对类型为T的对象进行二元运算，并返回T类型的结果。包含方法为：Tapply(T t1,T t2); BiConsumer T,U void 对类型为T,U参数应用操作。包含方法为：voidaccept(Tt,Uu) BiPredicate T,U boolean 包含方法为：booleantest(Tt,Uu) ToIntFunction T int 计算int值的函数 ToLongFunction T long 计算long值的函数 ToDoubleFunction T double 计算double值的函数 IntFunction int R 参数为int类型的函数 LongFunction long R 参数为long类型的函数 DoubleFunction double R 参数为double类型的函数 消费型接口使用举例 //消费型接口使用举例 public void happyTime(double money, Consumer&lt;Double> consumer) &#123; consumer.accept(money); &#125; @org.junit.jupiter.api.Test public void test() &#123; //1. 以前的写法 happyTime(1234, new Consumer&lt;Double>() &#123; @Override public void accept(Double money) &#123; System.out.println(\"突然想回一趟成都了，机票花费\" + money); &#125; &#125;); System.out.println(\"------------------------\"); //2. Lambda表达式，将之前的6行代码压缩到了1行 happyTime(648, money -> System.out.println(\"学习太累了，奖励自己一发十连，花费\" + money)); &#125; /** * 突然想回一趟成都了，机票花费1234.0 * ------------------------ * 学习太累了，奖励自己一发十连，花费648.0 */ 根据给定的规则，过滤集合中的字符串。此规则由Predicate的方法决定 //根据给定的规则，过滤集合中的字符串。此规则由Predicate的方法决定 public List&lt;String> filterString(List&lt;String> strings, Predicate&lt;String> predicate) &#123; ArrayList&lt;String> res = new ArrayList&lt;>(); for (String string : strings) &#123; if (predicate.test(string)) res.add(string); &#125; return res; &#125; @org.junit.jupiter.api.Test public void test2() &#123; List&lt;String> strings = Arrays.asList(\"东京\", \"西京\", \"南京\", \"北京\", \"天津\", \"中京\"); //1. 以前的写法 List&lt;String> list = filterString(strings, new Predicate&lt;String>() &#123; @Override public boolean test(String s) &#123; return s.contains(\"京\"); &#125; &#125;); System.out.println(list); System.out.println(\"------------------------\"); //2. 现在的写法，函数式接口 List&lt;String> list1 = filterString(strings, s -> s.contains(\"京\")); System.out.println(list1); &#125; Lambda表达式 Lambda是一个匿名函数，我们可以把Lambda表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。 使用它可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，是Java的语言表达能力得到了提升 Lambda表达式使用举例 举例一 @Test public void test01()&#123; &#x2F;&#x2F;1. 以前的写法 Runnable runnable01 &#x3D; new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;你 的 城 市 好 像 不 欢 迎 我&quot;); &#125; &#125;; runnable01.run(); System.out.println(&quot;------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Runnable runnable02 &#x3D; () -&gt; System.out.println(&quot;所 以 我 只 好 转 身 离 开 了&quot;); runnable02.run(); &#125; 举例二 @Test public void test02()&#123; &#x2F;&#x2F;1. 以前的写法 Comparator&lt;Integer&gt; comparator01 &#x3D; new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125; &#125;; System.out.println(comparator01.compare(95, 27)); System.out.println(&quot;------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Comparator&lt;Integer&gt; comparator02 &#x3D; (o1,o2) -&gt; o1.compareTo(o2); System.out.println(comparator02.compare(12, 21)); System.out.println(&quot;------------------------&quot;); &#x2F;&#x2F;3. 方法引用 Comparator&lt;Integer&gt; comparator03 &#x3D; Integer::compareTo; System.out.println(comparator03.compare(20, 77)); &#125; Lambda表达式语法的使用 举例： (o1,o2) -&gt; Integer.compare(o1,o2); 格式： -&gt;：lambda操作符或箭头操作符 -&gt;左边：lambda形参列表（其实就是接口中的抽象方法的形参列表） -&gt;右边：lambda体（其实就是重写的抽象方法的方法体） Lambda表达式的使用：（分为6种情况介绍） 语法格式一：无参无返回值 @Test public void test01()&#123; &#x2F;&#x2F;1. 以前的写法 Runnable runnable01 &#x3D; new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;你 的 城 市 好 像 不 欢 迎 我&quot;); &#125; &#125;; runnable01.run(); System.out.println(&quot;-------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Runnable runnable02 &#x3D; () -&gt; System.out.println(&quot;所 以 我 只 好 转 身 离 开 了&quot;); runnable02.run(); &#125; 语法格式二：Lambda需要一个参数，但是没有返回值 @Test public void test03()&#123; &#x2F;&#x2F;1. 以前的写法 Consumer&lt;String&gt; consumer01 &#x3D; new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;; consumer01.accept(&quot;其实我存过你照片 也研究过你的星座&quot;); System.out.println(&quot;-------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Consumer&lt;String&gt; consumer02 &#x3D; (String s) -&gt; &#123;System.out.println(s);&#125;; consumer02.accept(&quot;你喜欢的歌我也会去听 你喜欢的事物我也会想去了解&quot;); &#125; 语法格式三： 数据类型可以省略，因为可由类型推断得出 @Test public void test04()&#123; &#x2F;&#x2F;1. 以前的写法 Consumer&lt;String&gt; consumer01 &#x3D; new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;; consumer01.accept(&quot;我远比表面上更喜欢你&quot;); System.out.println(&quot;-------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Consumer&lt;String&gt; consumer02 &#x3D; (s) -&gt; &#123;System.out.println(s);&#125;; consumer02.accept(&quot;但我没有说&quot;); &#125; 语法格式四： Lambda若只需要一个参数，参数的小括号可以省略 @Test public void test04()&#123; &#x2F;&#x2F;1. 以前的写法 Consumer&lt;String&gt; consumer01 &#x3D; new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;; consumer01.accept(&quot;我远比表面上更喜欢你&quot;); System.out.println(&quot;-------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Consumer&lt;String&gt; consumer02 &#x3D; s -&gt; &#123;System.out.println(s);&#125;; consumer02.accept(&quot;但我没有说&quot;); &#125; 语法格式五： Lambda需要两个或以上参数，多条执行语句，并且有返回值 @Test public void test02() &#123; &#x2F;&#x2F;1. 以前的写法 Comparator&lt;Integer&gt; comparator01 &#x3D; new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; System.out.println(o1); System.out.println(o2); return o1.compareTo(o2); &#125; &#125;; System.out.println(comparator01.compare(95, 27)); System.out.println(&quot;-------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Comparator&lt;Integer&gt; comparator02 &#x3D; (o1, o2) -&gt; &#123; System.out.println(o1); System.out.println(o2); return o1.compareTo(o2); &#125;; System.out.println(comparator02.compare(12, 21)); &#125; 语法格式六： 当Lambda体只有一条语句时，return与{}若有，则都可以省略 public void test02() &#123; &#x2F;&#x2F;1. 以前的写法 Comparator&lt;Integer&gt; comparator01 &#x3D; new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125; &#125;; System.out.println(comparator01.compare(95, 27)); System.out.println(&quot;-------------------------&quot;); &#x2F;&#x2F;2. Lambda表达式 Comparator&lt;Integer&gt; comparator02 &#x3D; (o1, o2) -&gt; o1.compareTo(o2); System.out.println(comparator02.compare(12, 21)); &#125; 方法引用和构造器引用 当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用 方法引用可以看做会Lambda表达式的深层次表达，换句话说，方法引用就是Lambda表达式，也就是函数式接口的一个实例，通过方法的名字来指向一个方法，可以认为是Lambda表达式的一个语法糖 要求：实现接口的抽象方法的参数列表和返回值类型，必须与方法引用的方法的参数列表和返回值类型保持一致 方法引用的使用情况 方法引用的使用 使用情境：当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用！ 方法引用，本质上就是Lambda表达式，而Lambda表达式作为函数式接口的实例。所以方法引用，也是函数式接口的实例。 使用格式： 类(或对象) :: 方法名 具体分为如下的三种情况： 对象::实例方法名 类::静态方法名 类::实例方法名 方法引用使用的要求：要求接口中的抽象方法的形参列表和返回值类型与方法引用的方法的形参列表和返回值类型相同！（针对于情况1和情况2） 先写一个实体类 @Data public class Student &#123; private String name; private Integer id; &#125; 情况一：对象::实例方法名，抽象方法的形参列表和返回值类型与方法引用的方法的形参列表和返回值类型相同 //情况一：对象::实例方法名，抽象方法的形参列表和返回值类型与方法引用的方法的形参列表和返回值类型相同 //Consumer中的void accept(T t) //PrintStream中的void println(T t) //形参列表均为(T t)，返回值均为void，可以使用方法引用 @org.junit.jupiter.api.Test public void test03() &#123; //1. Lambda Consumer&lt;String> consumer01 = s -> System.out.println(s); consumer01.accept(\"她的手只有我的手四分之三那麼大\"); System.out.println(\"-----------------------------\"); //2. 方法引用 PrintStream printStream = System.out; Consumer&lt;String> consumer02 = printStream::println; consumer02.accept(\"\\\"可我還是沒能抓住\\\"\"); System.out.println(\"-----------------------------\"); //3. 但貌似也可以这么写 Consumer&lt;String> consumer03 = System.out::println; consumer03.accept(\"\\\"花落下的时候没死 风捡起花 又丢下 花才死了\\\"\"); &#125; /** * 她的手只有我的手四分之三那麼大 * ----------------------------- * \"可我還是沒能抓住\" * ----------------------------- * \"花落下的时候没死 风捡起花 又丢下 花才死了\" */ 情况二：类 :: 静态方法 //情况二：类 :: 静态方法 //Comparator中的int compare(T t1,T t2) //Integer中的int compare(T t1,T t2) //形参列表均为`(T t1,T t2)`，返回值均为`int`，可以使用方法引用 @org.junit.jupiter.api.Test public void test04() &#123; //1. Lambda Comparator&lt;Integer> comparator01 = (o1, o2) -> Integer.compare(01, 02); System.out.println(comparator01.compare(20, 30)); System.out.println(\"----------------------------\"); //2. 方法引用 Comparator&lt;Integer> comparator02 = Integer::compare; System.out.println(comparator02.compare(64, 30)); &#125; /** * -1 * ---------------------------- * 1 */ //Function中的R apply(T t) //Math中的Long round(Double d) //返回值和参数列表为泛型，也可以匹配上，可以使用方法引用 @org.junit.jupiter.api.Test public void test05() &#123; //1. Lambda Function&lt;Double, Long> function01 = aDouble -> Math.round(aDouble); System.out.println(function01.apply(3.1415926)); System.out.println(\"----------------------------\"); //2. 方法引用 Function&lt;Double, Long> function02 = Math::round; System.out.println(function02.apply(0.876)); &#125; /** * 3 * ---------------------------- * 1 */ 情况三：类 :: 实例方法 //情况三：类 :: 实例方法 // Comparator中的int comapre(T t1,T t2) // String中的int t1.compareTo(t2) @org.junit.jupiter.api.Test public void test06() &#123; //1. Lambda Comparator&lt;Integer> comparator01 = (o1, o2) -> o1.compareTo(o2); System.out.println(comparator01.compare(94, 21)); System.out.println(\"---------------------------\"); //2. 方法引用 Comparator&lt;Integer> comparator02 = Integer::compareTo; System.out.println(comparator02.compare(43, 96)); &#125; //BiPredicate中的boolean test(T t1, T t2); //String中的boolean t1.equals(t2) @org.junit.jupiter.api.Test public void test10() &#123; //1. Lambda BiPredicate&lt;String, String> biPredicate01 = (o1, o2) -> o1.equals(o2); System.out.println(biPredicate01.test(\"Kyle\", \"Kyle\")); System.out.println(\"----------------------------------\"); //2. 方法引用 BiPredicate&lt;String, String> biPredicate02 = String::equals; System.out.println(biPredicate02.test(\"Viole\", \"Violet\")); &#125; /** * true * ---------------------------------- * false */ // Function中的R apply(T t) // Employee中的String toString(); @org.junit.jupiter.api.Test public void test7() &#123; Student student = new Student(\"Kyle\", 9527); //1. Lambda Function&lt;Student, String> function01 = stu -> stu.toString(); System.out.println(function01.apply(student)); System.out.println(\"------------------------------\"); //2. 方法引用 Function&lt;Student, String> function02 = Student::toString; System.out.println(function02.apply(student)); &#125; /** * Student(name=Kyle, id=9527) * ------------------------------ * Student(name=Kyle, id=9527) */ 构造器引用和数组引用的使用 与函数式接口相结合，自动与函数式接口中方法兼容。 可以把构造器引用赋值给定义的方法，要求构造器参数列表要与接口中抽象方法的参数列表一致！且方法的返回值即为构造器对应类的对象。 1.构造器引用 和方法引用类似，函数式接口的抽象方法的形参列表和构造器的形参列表一致。 抽象方法的返回值类型即为构造器所属的类的类型 @org.junit.jupiter.api.Test public void test8() &#123; &#x2F;&#x2F;1. Lambda BiFunction&lt;String, Integer, Student&gt; biFunction01 &#x3D; (string, integer) -&gt; new Student(string, integer); System.out.println(biFunction01.apply(&quot;Kyle&quot;, 9527)); System.out.println(&quot;------------------------------&quot;); &#x2F;&#x2F;2. 方法引用 BiFunction&lt;String, Integer, Student&gt; biFunction02 &#x3D; Student::new; System.out.println(biFunction02.apply(&quot;Lucy&quot;, 9421)); &#125; &#x2F;** * Student(name&#x3D;Kyle, id&#x3D;9527) * ------------------------------ * Student(name&#x3D;Lucy, id&#x3D;9421) *&#x2F; 2.数组引用 可以把数组看做是一个特殊的类，则写法与构造器引用一致 @org.junit.jupiter.api.Test public void test9() &#123; &#x2F;&#x2F;1. Lambda 创建一个指定长度的string数组 Function&lt;Integer, String[]&gt; function01 &#x3D; integer -&gt; new String[integer]; System.out.println(Arrays.toString(function01.apply(5))); System.out.println(&quot;-----------------------------&quot;); &#x2F;&#x2F;2. 数组引用 Function&lt;Integer, String[]&gt; function02 &#x3D; String[]::new; System.out.println(Arrays.toString(function02.apply(7))); &#125; &#x2F;** * [null, null, null, null, null] * ----------------------------- * [null, null, null, null, null, null, null] *&#x2F; Stream APIStream API概述 Java8中有两个最为重要的改变，第一个就是Lambda表达式，另外一个则是Stream API Stream API(java.util.stream)把真正的函数式编程风格引入到Java中，这是目前为止对Java类库最好的补充，因为Stream API可以极大地提高程序员生产力，让程序员写出高效、简洁的代码 Stream是Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。 使用Stream API 对集合数据进行操作，就类似于使用SQL 执行的数据库查询，也可以使用Stream API 来并行执行操作。简言之，Stream API 提供了一种高效且易于使用的处理数据的方式 为什么要使用Stream API 实际开发中，项目中多数数据源都是来自MySQL、Oracle 等。但现在数据源可以更多了，有MongDB、Redis等，而这些NoSQL的数据就需要Java层面去处理。我就是学完Redis再来补票的.. Stream 和Collection 集合的区别：Collection 是一种静态的内存数据结构，而Stream 是有关计算的。前者是主要面向内存，存储在内存中，后者主要是面向CPU，通过CPU 实现计算（这也就是为什么一旦执行终止操作之后，Stream 就不能被再次使用，得重新创建一个新的流才行） 小结 Stream 关注的是对数据的运算，与CPU 打交道；集合关注的是数据的存储，与内存打交道 Stream 自己不会存储数据；Stream 不会改变源对象，相反，他们会返回一个持有结果的新StreamStream 操作是延迟执行的，这意味着他们会等到需要结果的时候才执行 Stream 执行流程 Stream实例化 一系列中间操作（过滤、映射、..） 终止操作 说明 一系列中间操作链，对数据源的数据进行处理 一旦执行终止操作，就执行中间操作链，并产生结果，之后，不会再被使用 Stream的实例化先新建两个类 public class Employee &#123; private int id; private String name; private int age; private double salary; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public double getSalary() &#123; return salary; &#125; public void setSalary(double salary) &#123; this.salary = salary; &#125; public Employee() &#123; System.out.println(\"Employee().....\"); &#125; public Employee(int id) &#123; this.id = id; System.out.println(\"Employee(int id).....\"); &#125; public Employee(int id, String name) &#123; this.id = id; this.name = name; &#125; public Employee(int id, String name, int age, double salary) &#123; this.id = id; this.name = name; this.age = age; this.salary = salary; &#125; @Override public String toString() &#123; return \"Employee&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", age=\" + age + \", salary=\" + salary + '&#125;'; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Employee employee = (Employee) o; if (id != employee.id) return false; if (age != employee.age) return false; if (Double.compare(employee.salary, salary) != 0) return false; return name != null ? name.equals(employee.name) : employee.name == null; &#125; @Override public int hashCode() &#123; int result; long temp; result = id; result = 31 * result + (name != null ? name.hashCode() : 0); result = 31 * result + age; temp = Double.doubleToLongBits(salary); result = 31 * result + (int) (temp ^ (temp >>> 32)); return result; &#125; &#125; /** * 提供用于测试的数据 */ public class EmployeeData &#123; public static List&lt;Employee> getEmployees() &#123; List&lt;Employee> list = new ArrayList&lt;>(); list.add(new Employee(1001, \"马化腾\", 34, 6000.38)); list.add(new Employee(1002, \"马云\", 12, 9876.12)); list.add(new Employee(1003, \"刘强东\", 33, 3000.82)); list.add(new Employee(1004, \"雷军\", 26, 7657.37)); list.add(new Employee(1005, \"李彦宏\", 65, 5555.32)); list.add(new Employee(1006, \"比尔盖茨\", 42, 9500.43)); list.add(new Employee(1007, \"任正非\", 26, 4333.32)); list.add(new Employee(1008, \"扎克伯格\", 35, 2500.32)); return list; &#125; &#125; 创建Stream方式一：通过集合 @org.junit.jupiter.api.Test public void test() &#123; List&lt;Employee> employees= EmployeeData.getEmployees(); //default Stream&lt;E> stream() 返回一个顺序流 Stream&lt;Employee> stream = employees.stream(); //default Stream&lt;E> parallelStream 返回一个并行流 Stream&lt;Employee> employeeStream=employees.parallelStream(); &#125; 创建Stream方式二：通过数组 @org.junit.jupiter.api.Test public void test2() &#123; int[] arr = new int[]&#123;1, 3, 5, 7, 9, 2, 4, 6, 8&#125;; //调用Arrays的static &lt;T> Stream&lt;T> stream(T[] array) 返回一个流 IntStream stream=Arrays.stream(arr); Employee kyle=new Employee(9527,\"Kyle\"); Employee lucy=new Employee(9527,\"Lucy\"); Employee[] employees=&#123;kyle,lucy&#125;; Stream&lt;Employee> stream1=Arrays.stream(employees); &#125; - 创建Stream方式三：通过Stream的of() @org.junit.jupiter.api.Test public void test03() &#123; Stream&lt;Integer> stream=Stream.of(9,4,2,8,2,5,2,7); &#125; 创建Stream方式四：创建无限流 如果不用limit限制输出，则会一直输出下去，forEach就相当于是终止操作 @org.junit.jupiter.api.Test public void test04() &#123; // 迭代 // 遍历前10个数 // public static&lt;T> Stream&lt;T> iterate(final T seed, final UnaryOperator&lt;T> f) Stream.iterate(0,t->t+1).limit(10).forEach(System.out::println); // 生成 // 10个随机数 // public static&lt;T> Stream&lt;T> generate(Supplier&lt;T> s) Stream.generate(Math::random).limit(10).forEach(System.out::println); &#125; Stream的中间操作：筛选与切片 多个中间操作可以连接起来形成一个流水线，除非流水线上触发终止操作，否则中间操作不会执行任何的处理，而在终止操作时一次性全部处理，称为惰性求值 方法 描述 filter(Predicate p) 接收Lambda ，从流中排除某些元素 distinct() 筛选，通过流所生成元素的hashCode() 和equals() 去除重复元素 limit(long maxSize) 截断流，使其元素不超过给定数量 skip(long n) 跳过元素，返回一个扔掉了前n 个元素的流。若流中元素不足n 个，则返回一个空流。与limit(n)互补 @org.junit.jupiter.api.Test public void test05() &#123; List&lt;Employee> employees = EmployeeData.getEmployees(); //1. filter 查询工资大于7000的员工信息 employees.stream().filter(employee -> employee.getSalary()>7000).forEach(System.out::println); System.out.println(\"----------------------------\"); //2. limit(n)——截断流，使其元素不超过给定数量。只输出3条员工信息 employees.stream().limit(3).forEach(System.out::println); System.out.println(\"----------------------------\"); //3. skip(n) —— 跳过元素，返回一个扔掉了前 n 个元素的流。若流中元素不足 n 个，则返回一个空流。与 limit(n) 互补 employees.stream().skip(3).forEach(System.out::println); System.out.println(\"----------------------------\"); //4. distinct()——筛选，通过流所生成元素的 hashCode() 和 equals() 去除重复元素 employees.add(new Employee(9527, \"Kyle\", 20, 9999)); employees.add(new Employee(9527, \"Kyle\", 20, 9999)); employees.add(new Employee(9527, \"Kyle\", 20, 9999)); employees.add(new Employee(9527, \"Kyle\", 20, 9999)); employees.add(new Employee(9527, \"Kyle\", 20, 9999)); employees.stream().distinct().forEach(System.out::println); &#125; /** * Employee&#123;id=1002, name='马云', age=12, salary=9876.12&#125; * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * ---------------------------- * Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125; * Employee&#123;id=1002, name='马云', age=12, salary=9876.12&#125; * Employee&#123;id=1003, name='刘强东', age=33, salary=3000.82&#125; * ---------------------------- * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1005, name='李彦宏', age=65, salary=5555.32&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * Employee&#123;id=1007, name='任正非', age=26, salary=4333.32&#125; * Employee&#123;id=1008, name='扎克伯格', age=35, salary=2500.32&#125; * ---------------------------- * Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125; * Employee&#123;id=1002, name='马云', age=12, salary=9876.12&#125; * Employee&#123;id=1003, name='刘强东', age=33, salary=3000.82&#125; * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1005, name='李彦宏', age=65, salary=5555.32&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * Employee&#123;id=1007, name='任正非', age=26, salary=4333.32&#125; * Employee&#123;id=1008, name='扎克伯格', age=35, salary=2500.32&#125; * Employee&#123;id=9527, name='Kyle', age=20, salary=9999.0&#125; * */ Stream的中间操作:映射 方法 描述 map(Function f) 接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 mapToDouble(ToDoubleFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的DoubleStream。 mapToInt(ToIntFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的IntStream。 mapToLong(ToLongFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的LongStream。 flatMap(Function f) 接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流 @org.junit.jupiter.api.Test public void test06() &#123; List&lt;String> strings = Arrays.asList(\"aa\", \"bb\", \"cc\", \"dd\"); List&lt;Employee> employees = EmployeeData.getEmployees(); //map(Function f)——接收一个函数作为参数，将元素转换成其他形式或提取信息，该函数会被应用到每个元素上，并将其映射成一个新的元素。 // 练习：将字符串转为大写并输出 strings.stream().map(String::toUpperCase).forEach(System.out::println);//方法引用 System.out.println(\"--------------------------\"); strings.stream().map(s -> s.toUpperCase()).forEach(System.out::println);//lambda System.out.println(\"--------------------------\"); // 练习：获取员工姓名长度大于3的员工的姓名。 employees.stream().map(Employee::getName).filter(name->name.length()>3).forEach(System.out::println); System.out.println(\"--------------------------\"); // 练习：将字符串中的多个字符构成的集合转换为对应的Stream实例 strings.stream().map(Test::formStringToStream).forEach(characterStream -> characterStream.forEach(System.out::println)); // 使用flatMap(Function f)达到同样的效果 strings.stream().flatMap(Test::formStringToStream).forEach(System.out::println); &#125; /** *AA * BB * CC * DD * -------------------------- * AA * BB * CC * DD * -------------------------- * 比尔盖茨 * 扎克伯格 * -------------------------- * a * a * b * b * c * c * d * d * a * a * b * b * c * c * d * d * */ public static Stream&lt;Character> formStringToStream(String str) &#123; ArrayList&lt;Character> list = new ArrayList&lt;>(); for (char c : str.toCharArray()) &#123; list.add(c); &#125; return list.stream(); &#125; Stream的中间操作:排序 方法 描述 sorted() 产生一个新流，其中按自然顺序排序 sorted(Comparator com) 产生一个新流，其中按比较器顺序排序 @org.junit.jupiter.api.Test public void test10() &#123; List&lt;Integer> nums = Arrays.asList(13, 54, 97, 52, 43, 64, 27); List&lt;Employee> employees = EmployeeData.getEmployees(); //自然排序 nums.stream().sorted().forEach(System.out::println); //定制排序，先按照年龄升序排，再按照工资降序排 employees.stream().sorted((o1, o2) -> &#123; int result = Integer.compare(o1.getAge(), o2.getAge()); if (result != 0) &#123; return result; &#125; else &#123; return -Double.compare(o1.getSalary(), o2.getSalary()); &#125; &#125;).forEach(System.out::println); &#125; /** * 13 * 27 * 43 * 52 * 54 * 64 * 97 * Employee&#123;id=1002, name='马云', age=12, salary=9876.12&#125; * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1007, name='任正非', age=26, salary=4333.32&#125; * Employee&#123;id=1003, name='刘强东', age=33, salary=3000.82&#125; * Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125; * Employee&#123;id=1008, name='扎克伯格', age=35, salary=2500.32&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * Employee&#123;id=1005, name='李彦宏', age=65, salary=5555.32&#125; * */ Stream的中间操作:匹配与查找 终端操作会从流的流水线生成结果。其结果可以是任何不是流的值，例如：List、Integer，甚至是void 。 流进行了终止操作后，不能再次使用。 方法 描述 allMatch(Predicate p) 检查是否匹配所有元素 anyMatch(Predicate p) 检查是否至少匹配一个元素 noneMatch(Predicate p) 检查是否没有匹配所有元素 findFirst() 返回第一个元素 findAny() 返回当前流中的任意元素 count() 返回流中元素总数 max(Comparator c) 返回流中最大值 min(Comparator c) 返回流中最小值 forEach(Consumer c) 内部迭代(使用Collection 接口需要用户去做迭代，称为外部迭代。相反，Stream API 使用内部迭代——它帮你把迭代做了) @org.junit.jupiter.api.Test public void test7() &#123; List&lt;Employee> employees = EmployeeData.getEmployees(); // allMatch(Predicate p)——检查是否匹配所有元素。 // 练习：是否所有的员工的工资是否都大于5000 System.out.println(\"是否所有的员工的工资是否都大于5000：\" + employees.stream().allMatch(employee -> employee.getSalary() > 5000)); // anyMatch(Predicate p)——检查是否至少匹配一个元素。 // 练习：是否存在员工年龄小于15 System.out.println(\"是否存在员工年龄小于15：\" + employees.stream().allMatch(employee -> employee.getAge() &lt; 15)); // noneMatch(Predicate p)——检查是否没有匹配的元素。 // 练习：是否不存在员工姓“马” System.out.println(\"是否不存在员工姓马：\" + employees.stream().noneMatch(employee -> employee.getName().startsWith(\"马\"))); //findFirst——返回第一个元素 System.out.println(\"返回第一个元素：\" + employees.stream().findFirst()); //findAny——返回当前流中的任意元素 System.out.println(\"返回当前流中的任意元素\" + employees.stream().findAny()); //count——返回流中元素的总个数 System.out.println(\"返回元素总数：\" + employees.stream().count()); //max(Comparator c)——返回流中最大值 System.out.println(\"返回最高工资：\" + employees.stream().map(Employee::getSalary).max(Double::compare)); //min(Comparator c)——返回流中最小值 System.out.println(\"返回最小年龄：\" + employees.stream().map(Employee::getAge).min(Integer::compare)); //forEach(Consumer c)——内部迭代 employees.stream().forEach(System.out::println); System.out.println(\"-------------\"); ////使用集合的遍历操作 employees.forEach(System.out::println); &#125; /** * 是否所有的员工的工资是否都大于5000：false * 是否存在员工年龄小于15：false * 是否不存在员工姓马：false * 返回第一个元素：Optional[Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125;] * 返回当前流中的任意元素Optional[Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125;] * 返回元素总数：8 * 返回最高工资：Optional[9876.12] * 返回最小年龄：Optional[12] * Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125; * Employee&#123;id=1002, name='马云', age=12, salary=9876.12&#125; * Employee&#123;id=1003, name='刘强东', age=33, salary=3000.82&#125; * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1005, name='李彦宏', age=65, salary=5555.32&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * Employee&#123;id=1007, name='任正非', age=26, salary=4333.32&#125; * Employee&#123;id=1008, name='扎克伯格', age=35, salary=2500.32&#125; * ------------- * Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125; * Employee&#123;id=1002, name='马云', age=12, salary=9876.12&#125; * Employee&#123;id=1003, name='刘强东', age=33, salary=3000.82&#125; * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1005, name='李彦宏', age=65, salary=5555.32&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * Employee&#123;id=1007, name='任正非', age=26, salary=4333.32&#125; * Employee&#123;id=1008, name='扎克伯格', age=35, salary=2500.32&#125; * * Process finished with exit code 0 */ Stream的终止操作:归约 方法 描述 reduce(T iden, BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回T reduce(BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回Optional @org.junit.jupiter.api.Test public void test8() &#123; List&lt;Integer> nums = Arrays.asList(13, 32, 23, 31, 94, 20, 77, 21, 17); List&lt;Employee> employees = EmployeeData.getEmployees(); // reduce(T identity, BinaryOperator)——可以将流中元素反复结合起来，得到一个值。返回 T // 练习1：计算1-10的自然数的和 System.out.println(nums.stream().reduce(0,Integer::sum)); //reduce(BinaryOperator) ——可以将流中元素反复结合起来，得到一个值。返回 Optional&lt;T> // 练习2：计算公司所有员工工资总和 System.out.println(employees.stream().map(Employee::getSalary).reduce((o1,o2)->o1+o2)); // 别的写法，计算年龄总和 System.out.println(employees.stream().map(Employee::getAge).reduce(0,Integer::sum)); &#125; /** * 328 * Optional[48424.08] * 273 */ Stream的终止操作:收集 方法 描述 collect(Collector c) 将流转换为其他形式。接收一个Collector接口的实现，用于给Stream中元素做汇总的方法 @org.junit.jupiter.api.Test public void test9() &#123; // collect(Collector c)——将流转换为其他形式。接收一个 Collector接口的实现，用于给Stream中元素做汇总的方法 // 练习1：查找工资大于6000的员工，结果返回为一个List List&lt;Employee> employees = EmployeeData.getEmployees(); List&lt;Employee> collect = employees.stream().filter(employee -> employee.getSalary() > 6000).collect(Collectors.toList()); collect.forEach(System.out::println); System.out.println(\"--------------------\"); // 练习2：查找年龄大于20的员工，结果返回为一个List List&lt;Employee> collect1 = employees.stream().filter(employee -> employee.getAge() > 20).collect(Collectors.toList()); collect1.forEach(System.out::println); &#125; /** * Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125; * Employee&#123;id=1002, name='马云', age=12, salary=9876.12&#125; * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * -------------------- * Employee&#123;id=1001, name='马化腾', age=34, salary=6000.38&#125; * Employee&#123;id=1003, name='刘强东', age=33, salary=3000.82&#125; * Employee&#123;id=1004, name='雷军', age=26, salary=7657.37&#125; * Employee&#123;id=1005, name='李彦宏', age=65, salary=5555.32&#125; * Employee&#123;id=1006, name='比尔盖茨', age=42, salary=9500.43&#125; * Employee&#123;id=1007, name='任正非', age=26, salary=4333.32&#125; * Employee&#123;id=1008, name='扎克伯格', age=35, salary=2500.32&#125; * * Process finished with exit code 0 */ Optional类简介 到目前为止，臭名昭著的空指针异常是导致Java应用程序失败的最常见原因。以前，为了解决空指针异常，Google公司著名的Guava项目引入了Optional类，Guava通过使用检查空值的方式来防止代码污染，它鼓励程序员写更干净的代码。受到Google Guava的启发，Optional类已经成为Java 8类库的一部分。 Optional 类(java.util.Optional) 是一个容器类，它可以保存类型T的值，代表这个值存在。或者仅仅保存null，表示这个值不存在。原来用null 表示一个值不存在，现在Optional 可以更好的表达这个概念。并且可以避免空指针异常。 Optional类的Javadoc描述如下：这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。 Optional提供很多有用的方法，这样我们就不用显式进行空值检测。 创建Optional类对象的方法： Optional.of(T t): 创建一个Optional 实例，t必须非空； Optional.empty() : 创建一个空的Optional 实例 Optional.ofNullable(T t)：t可以为null 判断Optional容器中是否包含对象： boolean isPresent() : 判断是否包含对象 void ifPresent(Consumer&lt;? super T&gt; consumer) ：如果有值，就执行Consumer接口的实现代码，并且该值会作为参数传给它。 获取Optional容器的对象： T get(): 如果调用对象包含值，返回该值，否则抛异常 T orElse(T other) ：如果有值则将其返回，否则返回指定的other对象。 T orElseGet(Supplier&lt;? extends T&gt; other) ：如果有值则将其返回，否则返回由Supplier接口实现提供的对象。 T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) ：如果有值则将其返回，否则抛出由Supplier接口实现提供的异常。 使用举例Boy类 public class Boy &#123; private Girl girl; public Boy() &#123; &#125; public Boy(Girl girl) &#123; this.girl = girl; &#125; public Girl getGirl() &#123; return girl; &#125; public void setGirl(Girl girl) &#123; this.girl = girl; &#125; @Override public String toString() &#123; return \"Boy&#123;\" + \"girl=\" + girl + '&#125;'; &#125; &#125; Gril类 public class Girl &#123; private String name; public Girl() &#123; &#125; public Girl(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return \"Girl&#123;\" + \"name='\" + name + '\\'' + '&#125;'; &#125; &#125; 测试类 @Test public void test()&#123; Girl girl = new Girl(); // girl = null; // of(T t):保证t是非空的 Optional&lt;Girl> optionalGirl = Optional.of(girl); &#125; @Test public void test25()&#123; Girl girl = new Girl(); // girl = null; // ofNullable(T t)：t可以为null Optional&lt;Girl> optionalGirl = Optional.ofNullable(girl); System.out.println(optionalGirl); // orElse(T t1):如果单前的Optional内部封装的t是非空的，则返回内部的t. // 如果内部的t是空的，则返回orElse()方法中的参数t1. Girl girl1 = optionalGirl.orElse(new Girl(\"\")); System.out.println(girl1); &#125;","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"}],"author":"ehzyil"},{"title":"Linux 安装 docker遇到版本问题","slug":"2023/Linux 安装 docker遇到版本问题","date":"2023-10-09T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/10/09/2023/Linux 安装 docker遇到版本问题/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/09/2023/Linux%20%E5%AE%89%E8%A3%85%20docker%E9%81%87%E5%88%B0%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98/","excerpt":"","text":"linux 安装 docker遇到版本问题小记 实验环境 Centos 7 linux 小版本更新docker 对 linux 版本有要求(次要版本 &gt;300 左右). 版本过低会导致一系列: 比如端口映射了,但范围不通的情况 找出系统上正在运行的Linux内核版本$ uname -srm Linux 3.10.0-327.el7.x86_64 x86_64 Linux 3.10.0-327.el7.x86_64 x86_64 3 - 内核版本. 10 - 主修订版本. 0-957 - 次要修订版本. 查询可升级最新版本[root@localhost ~]# yum list kernel 已加载插件：fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com 已安装的软件包 kernel.x86_64 3.10.0-327.el7 @anaconda 可安装的软件包 kernel.x86_64 3.10.0-1160.92.1.el7 updates 上面我们可以看到可以升级到 3.10.0-1160.92.1.el7, 于是执行命令 yum update -y kernel 进行小版本升级 重启系统命令 sudo init 6 重启系统后, 在查看 linux 内核版本 [root@localhost uname -srm Linux 3.10.0-1160.92.1.el7.x86_64 x86_64 卸载并重新安装Docker，问题解决。","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ehzyil.xyz/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.ehzyil.xyz/tags/Linux/"}],"author":"ehzyil"},{"title":"Yauaa：另一个 UserAgent 分析器","slug":"2023/Yauaa：另一个 UserAgent 分析器的使用","date":"2023-10-09T00:00:00.000Z","updated":"2024-01-06T04:54:46.199Z","comments":true,"path":"2023/10/09/2023/Yauaa：另一个 UserAgent 分析器的使用/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/09/2023/Yauaa%EF%BC%9A%E5%8F%A6%E4%B8%80%E4%B8%AA%20UserAgent%20%E5%88%86%E6%9E%90%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Yauaa自述Yauaa: Yet Another UserAgent Analyzer 这是一个 java 库，尝试解析和分析用户代理字符串（以及用户代理客户端提示可用时）并提取尽可能多的相关属性。可与 Java、Scala、Kotlin 配合使用，并为多种处理系统提供现成的 UDF。完整的文档可以在这里找到https://yauaa.basjes.nl 使用Yauaa第一步 添加Yauaa依赖 如果使用基于 Maven 的项目，只需将此依赖项添加到Maven 的项目中即可。 &lt;dependency&gt; &lt;groupId&gt;nl.basjes.parse.useragent&lt;&#x2F;groupId&gt; &lt;artifactId&gt;yauaa&lt;&#x2F;artifactId&gt; &lt;version&gt;7.22.0&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 第二步 创建创建一个工具类 UserAgentAnalyzer. public class UserAgentUtils &#123; private static final UserAgentAnalyzer USER_AGENT_ANALYZER; static &#123; USER_AGENT_ANALYZER = UserAgentAnalyzer .newBuilder() .hideMatcherLoadStats() .withField(UserAgent.OPERATING_SYSTEM_NAME_VERSION_MAJOR) .withField(UserAgent.AGENT_NAME_VERSION) .build(); &#125; /** * 从User-Agent解析客户端操作系统和浏览器版本 */ public static Map&lt;String, String> parseOsAndBrowser(String userAgent) &#123; UserAgent agent = USER_AGENT_ANALYZER.parse(userAgent); String os = agent.getValue(UserAgent.OPERATING_SYSTEM_NAME_VERSION_MAJOR); String browser = agent.getValue(UserAgent.AGENT_NAME_VERSION); Map&lt;String, String> map = new HashMap&lt;>(2); map.put(\"os\", os); map.put(\"browser\", browser); return map; &#125; &#125; 第三步使用 对于每个UserAgent（或一组请求标头），您可以调用该parse方法来获得所需的结果： UserAgent agent = uaa.parse(\"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11\"); for (String fieldName: agent.getAvailableFieldNamesSorted()) &#123; System.out.println(fieldName + \" = \" + agent.getValue(fieldName)); &#125; 请注意，并非所有字段在每次解析后都可用。因此，请准备好接收null或Unknown其他字段特定的默认值 String userAgent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36\"; Map&lt;String, String> userAgentMap = userAgentUtils.parseOsAndBrowser(userAgent); System.err.println(userAgentMap); String os = userAgentMap.get(\"os\"); String browser = userAgentMap.get(\"browser\"); System.err.println(os); System.err.println(browser); 在工具类中 只获取了操作系统和浏览器的名称版本(如有其他需要可自行添加，详见package nl.basjes.parse.useragent;)","categories":[{"name":"工具","slug":"工具","permalink":"https://blog.ehzyil.xyz/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Yauaa","slug":"Yauaa","permalink":"https://blog.ehzyil.xyz/tags/Yauaa/"}],"author":"ehzyil"},{"title":"node的卸载与安装","slug":"2023/node的卸载与安装","date":"2023-10-09T00:00:00.000Z","updated":"2024-01-06T04:54:46.211Z","comments":true,"path":"2023/10/09/2023/node的卸载与安装/","link":"","permalink":"https://blog.ehzyil.xyz/2023/10/09/2023/node%E7%9A%84%E5%8D%B8%E8%BD%BD%E4%B8%8E%E5%AE%89%E8%A3%85/","excerpt":"","text":"一、node.js卸载1、打开cmd 输入下列命令 查看npm包路径 #查看全局安装位置 npm root -g 得到npm的文件路径 下面的命令，可以用于查看本机的npm缓存的位置： npm config get cache 2、删除C:\\Users\\用户名\\AppData\\Roaming目录下的npm和npm-cache； 3、在控制面板中找到Node.js的卸载程序，运行卸载程序。 二、安装1、进入node.js各版本下载链接 找到要安装的版本，下载进行安装 2、查看node.js安装版本和npm版本 ehZyiL@DESKTOP-1H567GC MINGW64 ~&#x2F;Desktop $ node -v v18.16.0 ehZyiL@DESKTOP-1H567GC MINGW64 ~&#x2F;Desktop $ npm -v 9.5.1 cmd进入命令行界面，输入node -v 显示node版本，输入npm -v显示npm版本，如果都能显示则安装成功。","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"软件","slug":"软件","permalink":"https://blog.ehzyil.xyz/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"node.js","slug":"node-js","permalink":"https://blog.ehzyil.xyz/tags/node-js/"}],"author":"ehzyil"},{"title":"Spring Security","slug":"2023/Spring Security","date":"2023-09-16T00:00:00.000Z","updated":"2024-01-06T04:54:46.199Z","comments":true,"path":"2023/09/16/2023/Spring Security/","link":"","permalink":"https://blog.ehzyil.xyz/2023/09/16/2023/Spring%20Security/","excerpt":"","text":"Spring Security1.认证认证原理SpringSecurity的原理其实就是一个过滤器链，内部包含了提供各种功能的过滤器。例如快速入门案例里面使用到的三种过滤器，如下图 监听器 -&gt; 过滤器链 -&gt; dispatcherservlet(前置拦截器 -&gt; mapperHandle -&gt; 后置拦截器 -&gt; 最终拦截器) 下面介绍过滤器链中主要的几个过滤器及其作用： SecurityContextPersistenceFilter 这个Filter是整个拦截过程的入口和出口（也就是第一个和最后一个拦截器），会在请求开始时从配置好的 SecurityContextRepository 中获取 SecurityContext，然后把它设置给 SecurityContextHolder。在请求完成后将 SecurityContextHolder 持有的 SecurityContext 再保存到配置好的 SecurityContextRepository，同时清除 securityContextHolder 所持有的 SecurityContext； UsernamePasswordAuthenticationFilter 用于处理来自表单提交的认证。该表单必须提供对应的用户名和密码，其内部还有登录成功或失败后进行处理的 AuthenticationSuccessHandler 和 AuthenticationFailureHandler，这些都可以根据需求做相关改变； ExceptionTranslationFilter 能够捕获来自 FilterChain 所有的异常，并进行处理。但是它只会处理两类异常：AuthenticationException 和 AccessDeniedException，其它的异常它会继续抛出。 FilterSecurityInterceptor 是用于保护web资源的，使用AccessDecisionManager对当前用户进行授权访问，前面已经详细介绍过了； 认证流程Spring Security的执行流程如下： 用户提交用户名、密码被SecurityFilterChain中的UsernamePasswordAuthenticationFilter过滤器获取到，封装为请求Authentication，通常情况下是UsernamePasswordAuthenticationToken这个实现类。 然后过滤器将Authentication提交至认证管理器（AuthenticationManager）进行认证 认证成功后，AuthenticationManager身份管理器返回一个被填充满了信息的（包括上面提到的权限信息，身份信息，细节信息，但密码通常会被移除）Authentication实例。 SecurityContextHolderAuthentication，安全上下文容器将第3步填充了信息的通 过SecurityContextHolder.getContext().setAuthentication(…)方法，设置到其中。 可以看出AuthenticationManager接口（认证管理器）是认证相关的核心接口，也是发起认证的出发点，它的实现类为ProviderManager。而Spring Security支持多种认证方式，因此ProviderManager维护着一个List列表，存放多种认证方式，最终实际的认证工作是由AuthenticationProvider完成的。咱们知道web表单的对应的AuthenticationProvider实现类为DaoAuthenticationProvider，它的内部又维护着一个UserDetailsService负责UserDetails的获取。最终AuthenticationProvider将UserDetails填充至Authentication。 实践自定义security的思路【登录】 ①、自定义登录接口。用于调用ProviderManager的方法进行认证 如果认证通过生成jwt，然后把用户信息存入redis中 ②、自定义UserDetailsService接口的实现类。在这个实现类中去查询数据库 【校验】 ①、定义Jwt认证过滤器。用于获取token，然后解析token获取其中的userid，还需要从redis中获取用户信息，然后存入SecurityContextHolder 自定义security的搭建第一步:新建Maven项目引入以下依赖 &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.5.0&lt;/version> &lt;/parent> &lt;dependencies> &lt;!--还要引入这个，不然后面javax.servlet依赖找不到--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;!--springboot整合springsecurity--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-security&lt;/artifactId> &lt;/dependency> &lt;!--redis依赖--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;!--fastjson依赖--> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;version>1.2.33&lt;/version> &lt;/dependency> &lt;!--jwt依赖--> &lt;dependency> &lt;groupId>io.jsonwebtoken&lt;/groupId> &lt;artifactId>jjwt&lt;/artifactId> &lt;version>0.9.0&lt;/version> &lt;/dependency> &lt;!--引入Lombok依赖，方便实体类开发--> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 第一步：创建以下类 启动类 @SpringBootApplication @MapperScan(\"com.ehzyil.mapper\") public class SecurityApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext run = SpringApplication.run(SecurityApplication.class); System.out.println(run); &#125; &#125; 测试接口 @RestController public class HelloController &#123; @RequestMapping(\"/hello\") public String hello()&#123; return \"欢迎，开始你新的学习旅程吧\"; &#125; &#125; utils.FastJsonRedisSerializer package com.ehzyil.utils; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.parser.ParserConfig; import com.alibaba.fastjson.serializer.SerializerFeature; import com.fasterxml.jackson.databind.JavaType; import com.fasterxml.jackson.databind.type.TypeFactory; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.SerializationException; import java.nio.charset.Charset; /** * Redis使用FastJson序列化 * * @param &lt;T> */ public class FastJsonRedisSerializer&lt;T> implements RedisSerializer&lt;T> &#123; public static final Charset DEFAULT_CHARSET = Charset.forName(\"UTF-8\"); static &#123; ParserConfig.getGlobalInstance().setAutoTypeSupport(true); &#125; private Class&lt;T> clazz; public FastJsonRedisSerializer(Class&lt;T> clazz) &#123; super(); this.clazz = clazz; &#125; @Override public byte[] serialize(T t) throws SerializationException &#123; if (t == null) &#123; return new byte[0]; &#125; return JSON.toJSONString(t, SerializerFeature.WriteClassName).getBytes(DEFAULT_CHARSET); &#125; @Override public T deserialize(byte[] bytes) throws SerializationException &#123; if (bytes == null || bytes.length &lt;= 0) &#123; return null; &#125; String str = new String(bytes, DEFAULT_CHARSET); return JSON.parseObject(str, clazz); &#125; protected JavaType getJavaType(Class&lt;?> clazz) &#123; return TypeFactory.defaultInstance().constructType(clazz); &#125; &#125; JwtUtil package com.ehzyil.utils; import io.jsonwebtoken.Claims; import io.jsonwebtoken.JwtBuilder; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import javax.crypto.SecretKey; import javax.crypto.spec.SecretKeySpec; import java.util.Base64; import java.util.Date; import java.util.UUID; &#x2F;&#x2F;JWT工具类 public class JwtUtil &#123; &#x2F;&#x2F;有效期为 public static final Long JWT_TTL &#x3D; 60 * 60 * 1000L;&#x2F;&#x2F; 60 * 60 *1000 一个小时 &#x2F;&#x2F;设置秘钥明文, 注意长度必须大于等于6位 public static final String JWT_KEY &#x3D; &quot;huanfqc&quot;; public static String getUUID() &#123; String token &#x3D; UUID.randomUUID().toString().replaceAll(&quot;-&quot;, &quot;&quot;); return token; &#125; &#x2F;** * 生成jtw * * @param subject token中要存放的数据（json格式） * @return *&#x2F; public static String createJWT(String subject) &#123; JwtBuilder builder &#x3D; getJwtBuilder(subject, null, getUUID());&#x2F;&#x2F; 设置过期时间 return builder.compact(); &#125; &#x2F;** * 生成jtw * * @param subject token中要存放的数据（json格式） * @param ttlMillis token超时时间 * @return *&#x2F; public static String createJWT(String subject, Long ttlMillis) &#123; JwtBuilder builder &#x3D; getJwtBuilder(subject, ttlMillis, getUUID());&#x2F;&#x2F; 设置过期时间 return builder.compact(); &#125; private static JwtBuilder getJwtBuilder(String subject, Long ttlMillis, String uuid) &#123; SignatureAlgorithm signatureAlgorithm &#x3D; SignatureAlgorithm.HS256; SecretKey secretKey &#x3D; generalKey(); long nowMillis &#x3D; System.currentTimeMillis(); Date now &#x3D; new Date(nowMillis); if (ttlMillis &#x3D;&#x3D; null) &#123; ttlMillis &#x3D; JwtUtil.JWT_TTL; &#125; long expMillis &#x3D; nowMillis + ttlMillis; Date expDate &#x3D; new Date(expMillis); return Jwts.builder() .setId(uuid) &#x2F;&#x2F;唯一的ID .setSubject(subject) &#x2F;&#x2F; 主题 可以是JSON数据 .setIssuer(&quot;huanf&quot;) &#x2F;&#x2F; 签发者 .setIssuedAt(now) &#x2F;&#x2F; 签发时间 .signWith(signatureAlgorithm, secretKey) &#x2F;&#x2F;使用HS256对称加密算法签名, 第二个参数为秘钥 .setExpiration(expDate); &#125; &#x2F;** * 创建token * * @param id * @param subject * @param ttlMillis * @return *&#x2F; public static String createJWT(String id, String subject, Long ttlMillis) &#123; JwtBuilder builder &#x3D; getJwtBuilder(subject, ttlMillis, id);&#x2F;&#x2F; 设置过期时间 return builder.compact(); &#125; public static void main(String[] args) throws Exception &#123; &#x2F;&#x2F;加密指定字符串，jwt是123456加密后的密文 String jwt &#x3D; createJWT(&quot;123456&quot;); System.out.println(jwt); String token &#x3D; &quot;eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI0Mzg2MTUxZTFkNTE0ZmUwYjRlOWUzZDZiYjFlODA4OSIsInN1YiI6IjEyMzQ1NiIsImlzcyI6Imh1YW5mIiwiaWF0IjoxNjk0NzgzODI3LCJleHAiOjE2OTQ3ODc0Mjd9.z4QnAiSNBQcCAhZPwC5Xfzb0Py4np7qnyrUg0Ih8Qr4&quot;; Claims claims &#x3D; parseJWT(token); System.out.println(claims); &#125; &#x2F;** * 生成加密后的秘钥 secretKey * * @return *&#x2F; public static SecretKey generalKey() &#123; byte[] encodedKey &#x3D; Base64.getDecoder().decode(JwtUtil.JWT_KEY); SecretKey key &#x3D; new SecretKeySpec(encodedKey, 0, encodedKey.length, &quot;AES&quot;); return key; &#125; &#x2F;** * 解析 * * @param jwt * @return * @throws Exception *&#x2F; public static Claims parseJWT(String jwt) throws Exception &#123; SecretKey secretKey &#x3D; generalKey(); return Jwts.parser() .setSigningKey(secretKey) .parseClaimsJws(jwt) .getBody(); &#125; &#125; redis工具类 RedisCache package com.ehzyil.utils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.BoundSetOperations; import org.springframework.data.redis.core.HashOperations; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.core.ValueOperations; import org.springframework.stereotype.Component; import java.util.*; import java.util.concurrent.TimeUnit; @SuppressWarnings(value = &#123;\"unchecked\", \"rawtypes\"&#125;) @Component //redis工具类 public class RedisCache &#123; @Autowired public RedisTemplate redisTemplate; /** * 缓存基本的对象，Integer、String、实体类等 * * @param key 缓存的键值 * @param value 缓存的值 */ public &lt;T> void setCacheObject(final String key, final T value) &#123; redisTemplate.opsForValue().set(key, value); &#125; /** * 缓存基本的对象，Integer、String、实体类等 * * @param key 缓存的键值 * @param value 缓存的值 * @param timeout 时间 * @param timeUnit 时间颗粒度 */ public &lt;T> void setCacheObject(final String key, final T value, final Integer timeout, final TimeUnit timeUnit) &#123; redisTemplate.opsForValue().set(key, value, timeout, timeUnit); &#125; /** * 设置有效时间 * * @param key Redis键 * @param timeout 超时时间 * @return true=设置成功；false=设置失败 */ public boolean expire(final String key, final long timeout) &#123; return expire(key, timeout, TimeUnit.SECONDS); &#125; /** * 设置有效时间 * * @param key Redis键 * @param timeout 超时时间 * @param unit 时间单位 * @return true=设置成功；false=设置失败 */ public boolean expire(final String key, final long timeout, final TimeUnit unit) &#123; return redisTemplate.expire(key, timeout, unit); &#125; /** * 获得缓存的基本对象。 * * @param key 缓存键值 * @return 缓存键值对应的数据 */ public &lt;T> T getCacheObject(final String key) &#123; ValueOperations&lt;String, T> operation = redisTemplate.opsForValue(); return operation.get(key); &#125; /** * 删除单个对象 * * @param key */ public boolean deleteObject(final String key) &#123; return redisTemplate.delete(key); &#125; /** * 删除集合对象 * * @param collection 多个对象 * @return */ public long deleteObject(final Collection collection) &#123; return redisTemplate.delete(collection); &#125; /** * 缓存List数据 * * @param key 缓存的键值 * @param dataList 待缓存的List数据 * @return 缓存的对象 */ public &lt;T> long setCacheList(final String key, final List&lt;T> dataList) &#123; Long count = redisTemplate.opsForList().rightPushAll(key, dataList); return count == null ? 0 : count; &#125; /** * 获得缓存的list对象 * * @param key 缓存的键值 * @return 缓存键值对应的数据 */ public &lt;T> List&lt;T> getCacheList(final String key) &#123; return redisTemplate.opsForList().range(key, 0, -1); &#125; /** * 缓存Set * * @param key 缓存键值 * @param dataSet 缓存的数据 * @return 缓存数据的对象 */ public &lt;T> BoundSetOperations&lt;String, T> setCacheSet(final String key, final Set&lt;T> dataSet) &#123; BoundSetOperations&lt;String, T> setOperation = redisTemplate.boundSetOps(key); Iterator&lt;T> it = dataSet.iterator(); while (it.hasNext()) &#123; setOperation.add(it.next()); &#125; return setOperation; &#125; /** * 获得缓存的set * * @param key * @return */ public &lt;T> Set&lt;T> getCacheSet(final String key) &#123; return redisTemplate.opsForSet().members(key); &#125; /** * 缓存Map * * @param key * @param dataMap */ public &lt;T> void setCacheMap(final String key, final Map&lt;String, T> dataMap) &#123; if (dataMap != null) &#123; redisTemplate.opsForHash().putAll(key, dataMap); &#125; &#125; /** * 获得缓存的Map * * @param key * @return */ public &lt;T> Map&lt;String, T> getCacheMap(final String key) &#123; return redisTemplate.opsForHash().entries(key); &#125; /** * 往Hash中存入数据 * * @param key Redis键 * @param hKey Hash键 * @param value 值 */ public &lt;T> void setCacheMapValue(final String key, final String hKey, final T value) &#123; redisTemplate.opsForHash().put(key, hKey, value); &#125; /** * 获取Hash中的数据 * * @param key Redis键 * @param hKey Hash键 * @return Hash中的对象 */ public &lt;T> T getCacheMapValue(final String key, final String hKey) &#123; HashOperations&lt;String, String, T> opsForHash = redisTemplate.opsForHash(); return opsForHash.get(key, hKey); &#125; /** * 删除Hash中的数据 * * @param key * @param hkey */ public void delCacheMapValue(final String key, final String hkey) &#123; HashOperations hashOperations = redisTemplate.opsForHash(); hashOperations.delete(key, hkey); &#125; /** * 获取多个Hash中的数据 * * @param key Redis键 * @param hKeys Hash键集合 * @return Hash对象集合 */ public &lt;T> List&lt;T> getMultiCacheMapValue(final String key, final Collection&lt;Object> hKeys) &#123; return redisTemplate.opsForHash().multiGet(key, hKeys); &#125; /** * 获得缓存的基本对象列表 * * @param pattern 字符串前缀 * @return 对象列表 */ public Collection&lt;String> keys(final String pattern) &#123; return redisTemplate.keys(pattern); &#125; &#125; config.RedisConfig 类 package com.ehzyil.config; import com.ehzyil.utils.FastJsonRedisSerializer; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.StringRedisSerializer; /** * @author 35238 * @date 2023/7/11 0011 15:40 */ @Configuration public class RedisConfig &#123; @Bean @SuppressWarnings(value = &#123;\"unchecked\", \"rawtypes\"&#125;) public RedisTemplate&lt;Object, Object> redisTemplate(RedisConnectionFactory connectionFactory) &#123; RedisTemplate&lt;Object, Object> template = new RedisTemplate&lt;>(); template.setConnectionFactory(connectionFactory); FastJsonRedisSerializer serializer = new FastJsonRedisSerializer(Object.class); // 使用StringRedisSerializer来序列化和反序列化redis的key值 template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(serializer); // Hash的key也采用StringRedisSerializer的序列化方式 template.setHashKeySerializer(new StringRedisSerializer()); template.setHashValueSerializer(serializer); template.afterPropertiesSet(); return template; &#125; &#125; domain.ResponseResult package com.ehzyil.domain; import com.fasterxml.jackson.annotation.JsonInclude; //响应类 @JsonInclude(JsonInclude.Include.NON_NULL) public class ResponseResult&lt;T> &#123; /** * 状态码 */ private Integer code; /** * 提示信息，如果有错误时，前端可以获取该字段进行提示 */ private String msg; /** * 查询到的结果数据， */ private T data; public ResponseResult(Integer code, String msg) &#123; this.code = code; this.msg = msg; &#125; public ResponseResult(Integer code, T data) &#123; this.code = code; this.data = data; &#125; public Integer getCode() &#123; return code; &#125; public void setCode(Integer code) &#123; this.code = code; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; public T getData() &#123; return data; &#125; public void setData(T data) &#123; this.data = data; &#125; public ResponseResult(Integer code, String msg, T data) &#123; this.code = code; this.msg = msg; this.data = data; &#125; &#125; 在 utile 目录新建 WebUtils 类 package com.ehzyil.utils; import javax.servlet.http.HttpServletResponse; import java.io.IOException; public class WebUtils &#123; /** * 将字符串渲染到客户端 * * @param response 渲染对象 * @param string 待渲染的字符串 * @return null */ public static String renderString(HttpServletResponse response, String string) &#123; try &#123; response.setStatus(200); response.setContentType(\"application/json\"); response.setCharacterEncoding(\"utf-8\"); response.getWriter().print(string); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; &#125; 在 domain目录新建 User类，写入如下 package com.ehzyil.domain; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.io.Serializable; import java.util.Date; //用户表(User)实体类 @Data @AllArgsConstructor @NoArgsConstructor @TableName(\"sys_user\") public class User implements Serializable &#123; private static final long serialVersionUID = -40356785423868312L; /** * 主键 */ @TableId private Long id; /** * 用户名 */ private String userName; /** * 昵称 */ private String nickName; /** * 密码 */ private String password; /** * 账号状态（0正常 1停用） */ private String status; /** * 邮箱 */ private String email; /** * 手机号 */ private String phonenumber; /** * 用户性别（0男，1女，2未知） */ private String sex; /** * 头像 */ private String avatar; /** * 用户类型（0管理员，1普通用户） */ private String userType; /** * 创建人的用户id */ private Long createBy; /** * 创建时间 */ private Date createTime; /** * 更新人 */ private Long updateBy; /** * 更新时间 */ private Date updateTime; /** * 删除标志（0代表未删除，1代表已删除） */ private Integer delFlag; &#125; 自定义security的数据库第一步: 数据库校验用户。从之前的分析我们可以知道，我们自定义了一个UserDetailsService，让SpringSecurity使用我们的UserDetailsService。我们自己的UserDetailsService可以从数据库中查询用户名和密码。我们先创建一个用户表， 建表语句如下： 注意: 要想让用户的密码是明文存储，需要在密码前加{noop}，作用是例如等下在浏览器登陆的时候就可以用huanf作为用户名，112233作为密码来登陆了 create database if not exists huanf_security; use huanf_security; CREATE TABLE `sys_user` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT '主键', `user_name` VARCHAR(64) NOT NULL DEFAULT 'NULL' COMMENT '用户名', `nick_name` VARCHAR(64) NOT NULL DEFAULT 'NULL' COMMENT '昵称', `password` VARCHAR(64) NOT NULL DEFAULT 'NULL' COMMENT '密码', `status` CHAR(1) DEFAULT '0' COMMENT '账号状态（0正常 1停用）', `email` VARCHAR(64) DEFAULT NULL COMMENT '邮箱', `phonenumber` VARCHAR(32) DEFAULT NULL COMMENT '手机号', `sex` CHAR(1) DEFAULT NULL COMMENT '用户性别（0男，1女，2未知）', `avatar` VARCHAR(128) DEFAULT NULL COMMENT '头像', `user_type` CHAR(1) NOT NULL DEFAULT '1' COMMENT '用户类型（0管理员，1普通用户）', `create_by` BIGINT(20) DEFAULT NULL COMMENT '创建人的用户id', `create_time` DATETIME DEFAULT NULL COMMENT '创建时间', `update_by` BIGINT(20) DEFAULT NULL COMMENT '更新人', `update_time` DATETIME DEFAULT NULL COMMENT '更新时间', `del_flag` INT(11) DEFAULT '0' COMMENT '删除标志（0代表未删除，1代表已删除）', PRIMARY KEY (`id`) ) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COMMENT='用户表'; insert into sys_user values (1,'admin','管理员','&#123;noop&#125;123456','0',DEFAULT,DEFAULT,DEFAULT,DEFAULT,'0',DEFAULT,DEFAULT,DEFAULT,DEFAULT,DEFAULT); insert into sys_user values (2,'huanf','涣沷a靑惷','&#123;noop&#125;112233','0',DEFAULT,DEFAULT,DEFAULT,DEFAULT,'1',DEFAULT,DEFAULT,DEFAULT,DEFAULT,DEFAULT); 第二步: 在pom.xml添加如下 &lt;!--引入MybatisPuls依赖--> &lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId> &lt;version>3.4.3&lt;/version> &lt;/dependency> &lt;!--引入mysql驱动的依赖--> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> 第三步: 在 src&#x2F;main&#x2F;resources 目录新建File，文件名为application.yml，写入如下 server: port: 8089 spring: # 数据库连接信息 datasource: url: jdbc:mysql://localhost:3306/huanf_security?characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghai username: root password: 666666 driver-class-name: com.mysql.cj.jdbc.Driver 第四步: 在 src&#x2F;main&#x2F;java&#x2F;com.ehzyil 目录新建 mapper.UserMapper 接口，写入如下 import com.baomidou.mybatisplus.core.mapper.BaseMapper; import com.ehzyil.domain.User; @Service public interface UserMapper extends BaseMapper&lt;User> &#123; &#125; 第五步: 在引导类添加如下. @MapperScan(\"com.ehzyil.mapper\") 第六步: 在pom.xml添加如下 &lt;!--引入Junit，用于测试--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;/dependency> 第七步: 在 src&#x2F;test&#x2F;java 目录新建 com.ehzyil.MapperTest类，写入如下。作用是测试mybatis-plus是否正常 package com.ehzyil; import com.ehzyil.domain.User; import com.ehzyil.mapper.UserMapper; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import java.util.List; @SpringBootTest public class MapperTest &#123; @Autowired private UserMapper userMapper; @Test public void testUserMapper()&#123; &#x2F;&#x2F;查询所有用户 List&lt;User&gt; users &#x3D; userMapper.selectList(null); System.out.println(users); &#125; &#125; 第八步: 运行MapperTest类的testUserMapper方法，看是否能查到数据库的所有用户。到此，可以确定数据库是没问题的，环境到此就准备好了 自定义security的认证实现上面我们已经把准备工作做好了，包括搭建、代码、数据库。接下来我们会实现让security在认证的时候，根据我们数据库的用户和密码进行认证，也就是被security拦截业务接口，出现登录页面之后，我们需要通过输入数据库里的用户和密码来登录，而不是使用security默认的用户和密码进行登录 用户提交账号和密码由DaoAuthenticationProvider调用UserDetailsService的loadUserByUsername()方法获取UserDetails用户信息。 查询DaoAuthenticationProvider的源代码如下： UserDetailsService是一个接口，如下： package org.springframework.security.core.userdetails; public interface UserDetailsService &#123; UserDetails loadUserByUsername(String var1) throws UsernameNotFoundException; &#125; UserDetails是用户信息接口 public interface UserDetails extends Serializable &#123; Collection&lt;? extends GrantedAuthority> getAuthorities(); String getPassword(); String getUsername(); boolean isAccountNonExpired(); boolean isAccountNonLocked(); boolean isCredentialsNonExpired(); boolean isEnabled(); &#125; 我们只要实现UserDetailsService 接口查询数据库得到用户信息返回UserDetails 类型的用户信息即可,框架调用loadUserByUsername()方法拿到用户信息之后是如何执行的，见下图： 思路: 只需要新建一个实现类，在这个实现类里面实现Security官方的UserDetailsService接口，然后重写里面的loadUserByUsername方法 注意: 重写好loadUserByUsername方法之后，我们需要把拿到 ‘数据库与用户输入的数据’ 进行比对的结果，也就是user对象这个结果封装成能被 ‘Security官方的UserDetailsService接口’ 接收的类型，例如可以封装成我们下面写的LoginUser类型。然后才能伪装好数据，给Security官方的认证机制去对比user对象与数据库的结果是否匹配。Security官方的认证机制会拿LoginUser类的方法数据(数据库拿，不再用默认的)，跟我们封装过去的user对象进行匹配，要使匹配一致，就证明认证通过，也就是用户在浏览器页面输入的用户名和密码能被Security认证通过，就不再拦截该用户去访问我们的业务接口 第一步: 在domain目录新建LoginUser类，作为UserDetails接口(Security官方提供的接口)的实现类 package com.ehzyil.domain; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import java.util.Collection; @Data &#x2F;&#x2F;get和set方法 @NoArgsConstructor &#x2F;&#x2F;无参构造 @AllArgsConstructor &#x2F;&#x2F;带参构造 &#x2F;&#x2F;实现UserDetails接口之后，要重写UserDetails接口里面的7个方法 public class LoginUser implements UserDetails &#123; private User user; @Override &#x2F;&#x2F;用于返回权限信息。现在我们正在学&#39;认证&#39;，&#39;权限&#39;后面才学。所以返回null即可 public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; return null; &#125; @Override &#x2F;&#x2F;用于获取用户密码。由于使用的实体类是User，所以获取的是数据库的用户密码 public String getPassword() &#123; return user.getPassword(); &#125; @Override &#x2F;&#x2F;用于获取用户名。由于使用的实体类是User，所以获取的是数据库的用户名 public String getUsername() &#123; return user.getUserName(); &#125; @Override &#x2F;&#x2F;判断登录状态是否过期。把这个改成true，表示永不过期 public boolean isAccountNonExpired() &#123; return true; &#125; @Override &#x2F;&#x2F;判断账号是否被锁定。把这个改成true，表示未锁定，不然登录的时候，不让你登录 public boolean isAccountNonLocked() &#123; return true; &#125; @Override &#x2F;&#x2F;判断登录凭证是否过期。把这个改成true，表示永不过期 public boolean isCredentialsNonExpired() &#123; return true; &#125; @Override &#x2F;&#x2F;判断用户是否可用。把这个改成true，表示可用状态 public boolean isEnabled() &#123; return true; &#125; &#125; 第二步: 在 src&#x2F;main&#x2F;java&#x2F;com.ehzyil 目录新建 service.impl.MyUserDetailServiceImpl 类,实现UserDetailsService接口，写入如下 package com.ehzyil.service.impl; import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper; import com.ehzyil.domain.LoginUser; import com.ehzyil.domain.User; import com.ehzyil.mapper.UserMapper; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.stereotype.Service; import java.util.Objects; @Service public class MyUserDetailServiceImpl implements UserDetailsService &#123; @Autowired private UserMapper userMapper; @Override //UserDetails是Security官方提供的接口 public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //查询用户信息。我们写的userMapper接口里面是空的，所以调用的是mybatis-plus提供的方法 LambdaQueryWrapper&lt;User> queryWrapper = new LambdaQueryWrapper&lt;>(); queryWrapper.eq(User::getUserName,username); User user = userMapper.selectOne(queryWrapper); //如果用户传进来的用户名，但是数据库没有这个用户名，就会导致我们是查不到的情况，那么就进行下面的判断。避免程序安全问题 if(Objects.isNull(user))&#123; throw new RuntimeException(\"用户名或者密码错误\"); &#125; //把查询到的user结果，封装成UserDetails类型，然后返回。 //但是由于UserDetails是个接口，所以我们先需要在domino目录新建LoginUser类，作为UserDetails的实现类，再写下面那行 return new LoginUser(user); &#125; &#125; 第三步: 测试。运行引导类，浏览器输入如下，然后我们输入一下登录的用户名和密码，看是不是根据数据库来进行认证 http:&#x2F;&#x2F;localhost:8089&#x2F;hello 出现以下页面 输入 admin 123456登录 即可访问 http://localhost:8089/hello 密码加密校验问题上面我们实现了自定义Security的认证机制，让Security根据数据库的数据，来认证用户输入的数据是否正确。但是当时存在一个问题，就是我们在数据库存入用户表的时候，插入的huanf用户的密码是 {noop}112233，为什么用112233不行呢 原因: SpringSecurity默认使用的PasswordEncoder要求数据库中的密码格式为：{加密方式}密码。对应的就是{noop}112233，实际表示的是112233 但是我们在数据库直接暴露112233为密码，会造成安全问题，所以我们需要把加密后的1234的密文当作密码，此时用户在浏览器登录时输入1234，我们如何确保用户能够登录进去呢，答案是SpringSecurity默认的密码校验，替换为SpringSecurity为我们提供的BCryptPasswordEncoder 我们只需要使用把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验。我们可以定义一个SpringSecurity的配置类，SpringSecurity要求这个配置类要继承WebSecurityConfigurerAdapter。 【首先是 ‘加密’，如何实现，如下】 第一步: 在config目录新建 SecurityConfig 类，写入如下。作用是根据原文，生成一个密文 package com.ehzyil.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; @Configuration //实现Security提供的WebSecurityConfigurerAdapter类，就可以改变密码校验的规则了 public class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Bean //把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验 //注意也可以注入PasswordEncoder，效果是一样的，因为PasswordEncoder是BCry..的父类 public PasswordEncoder passwordEncoder()&#123; return new BCryptPasswordEncoder(); &#125; &#125; 第二步: 测试。在MapperTest类，添加如下，然后运行 TestBCryptPasswordEncoder 方法 @Test public void TestBCryptPasswordEncoder()&#123; //如果不想在下面那行new的话，那么就在该类注入PasswordEncoder，例如如下 /** * @Autowired * private PasswordEncoder passwordEncoder; */ BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); //模拟用户输入的密码 String encode1 = passwordEncoder.encode(\"1234\"); //再模拟一次用户输入的密码 String encode2 = passwordEncoder.encode(\"1234\"); //虽然这两次的密码都是一样的，但是加密后是不一样的。每次运行，对同一原文都会有不同的加密结果 //原因:会添加随机的盐，加密结果=盐+原文+加密。达到每次加密后的密文都不相同的效果 System.out.println(encode1); System.out.println(encode2); &#125; 【然后是 ‘校验’，如何实现，如下】 第一步(已做可跳过): 在config目录新建 SecurityConfig 类，写入如下。作用是根据原文，生成一个密文 package com.ehzyil.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; @Configuration //实现Security提供的WebSecurityConfigurerAdapter类，就可以改变密码校验的规则了 public class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Bean //把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验 //注意也可以注入PasswordEncoder，效果是一样的，因为PasswordEncoder是BCry..的父类 public PasswordEncoder passwordEncoder()&#123; return new BCryptPasswordEncoder(); &#125; &#125; 第二步: 测试。在MapperTest类，添加如下，然后运行 TestBCryptPasswordEncoder 方法 @Test public void TestBCryptPasswordEncoder()&#123; BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); //模拟用户输入了1234(第一个参数)，然后我们去跟数据库的密文进行比较(第二个参数) boolean result = passwordEncoder.matches(\"1234\", \"$2a$10$zOitKu6UNk.b/iPFTtIj2u80sH/dfJI9vFr57qhDGteuXj/Wl8uSy\"); //看一下比对结果 System.out.println(result); &#125; 重启测试后发现 账号1登不进去，密码加密过的账号2可以登录。 jwt工具类实现加密校验【加密】 第一步: 使用createJWT方法生成指定字符串的密文。 第一步: 使用parseJWT方法将密文解密(校验)为原文。 public static void main(String[] args) throws Exception &#123; System.out.println(\"***************加密****************\"); //加密指定字符串，token是123456加密后的密文 String token = createJWT(\"123456\"); System.out.println(token); System.out.println(\"***************解密****************\"); //把上面那行的密文解密(校验)为原文 Claims claims = parseJWT(token); System.out.println(claims); //输出解密后的原文 System.out.println(claims.getSubject()); &#125; 第二步: 运行JwtUtil类的main方法 ***************加密**************** eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiJiYzg0ZWY1NjY1MmQ0YjgzODg2MGUxOTM2MGNlY2FiIsInN1YiI6IjEyMzQ1NiIsImlzcyI6Imh1YW5mIiwiaWF0IjoxNjk0ODMzMjU3LCJleHAiOjE2OTQ4MzY4NTd9.bJDcdufq0LMhpdwlEbE5mBkZoGYZRxHIFoo1rb5MN1U ***************解密**************** &#123;jti&#x3D;bc84ef56652d4b838860e19360cecabc, sub&#x3D;123456, iss&#x3D;huanf, iat&#x3D;1694833257, exp&#x3D;1694836857&#125; 123456 登录接口的分析在上面的自定义security的思路当中，我们有一个功能需求是自定义登录接口，这个功能还没有实现，我们需要实现这个功能，但是，实现这个功能需要使用到jwt，我们刚刚也学习了使用jwt来实现加密校验，那么下面就正式学习如何实现这个登录接口，首先是分析，如下 ①我们需要自定义登陆接口，也就是在controller目录新建LoginController类，在controller方法里面去调用service接口，在service接口实现AuthenticationManager去进行用户的认证，注意，我们定义的controller方法要让SpringSecurity对这个接口放行(如果不放行的话，会被SpringSecurity拦截)，让用户访问这个接口的时候不用登录也能访问。 ②在service接口中我们通过AuthenticationManager的authenticate方法来进行用户认证,所以需要在SecurityConfig中配置把AuthenticationManager注入容器 ③认证成功的话要生成一个jwt，放入响应中返回。并且为了让用户下回请求时能通过jwt识别出具体的是哪个用户，我们需要把用户信息存入redis，可以把用户id作为key。 登录接口的实现第一步: 修改数据库的huanf用户的密码，把112233明文修改为对应的密文。密文可以用jwt工具类加密112233看一下，或者直接复制我给出的 UPDATE sys_user SET password &#x3D; &#39;$2a$10$YPnG.IYUk0mMechaxSibBuKmNeTzvuHdcxkqvoxizsll6WCQG9CHG&#39; WHERE id &#x3D; 2; ​ 第二步: 在 SecurityConfig 类添加如下 @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http //由于是前后端分离项目，所以要关闭csrf .csrf().disable() //由于是前后端分离项目，所以session是失效的，我们就不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() //指定让spring security放行登录接口的规则 .authorizeRequests() // 对于登录接口 anonymous表示允许匿名访问 .antMatchers(\"/user/login\").anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); &#125; 第三步: 在service目录新建 LoginService 接口，写入如下 package com.ehzyil.service; import com.ehzyil.domain.ResponseResult; import com.ehzyil.domain.User; import org.springframework.stereotype.Service; @Service public interface LoginService &#123; ResponseResult login(User user); &#125; 第四步: 在service目录新建 impl.LoginServiceImpl 类，写入如下 package com.ehzyil.service.impl; @Service //写登录的核心代码 public class LoginServiceImpl implements LoginService &#123; @Autowired //先在SecurityConfig，使用@Bean注解重写官方的authenticationManagerBean类，然后这里才能注入成功 private AuthenticationManager authenticationManager; @Autowired //RedisCache是我们在utils目录写好的类 private RedisCache redisCache; @Override //ResponseResult和user是我们在domain目录写好的类 public ResponseResult login(User user) &#123; //用户在登录页面输入的用户名和密码 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(user.getUserName(),user.getPassword()); //获取AuthenticationManager的authenticate方法来进行用户认证 Authentication authenticate = authenticationManager.authenticate(authenticationToken); //判断上面那行的authenticate是否为null，如果是则认证没通过，就抛出异常 if(Objects.isNull(authenticate))&#123; throw new RuntimeException(\"登录失败\"); &#125; //如果认证通过，就使用userid生成一个jwt，然后把jwt存入ResponseResult后返回 LoginUser loginUser = (LoginUser) authenticate.getPrincipal(); String userid = loginUser.getuser().getId().toString(); String jwt = JwtUtil.createJWT(userid); //把完整的用户信息存入redis，其中userid作为key，注意存入redis的时候加了前缀 login: Map&lt;String, String> map = new HashMap&lt;>(); map.put(\"token\",jwt); redisCache.setCacheObject(\"login:\"+userid,loginUser); return new ResponseResult(200,\"登录成功\",map); &#125; &#125; 第五步: 在controller目录新建 LoginController 类，写入如下 package com.ehzyil.controller; import com.ehzyil.domain.ResponseResult; import com.ehzyil.domain.User; import com.ehzyil.service.LoginService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RestController; @RestController public class LoginController &#123; @Autowired //LoginService是我们在service目录写好的接口 private LoginService loginService; @PostMapping(\"/user/login\") //ResponseResult和user是我们在domain目录写好的类 public ResponseResult login(@RequestBody User user)&#123; //登录 return loginService.login(user); &#125; &#125; 第六步: 在application.yml添加如下，作用是添加redis的连接信息 redis: host: 127.0.0.1 port: 6379 第八步: 运行引导类 第九步: 测试。发送下面的POST请求 localhost:8089&#x2F;user&#x2F;login &#123; &quot;userName&quot;:&quot;huanf&quot;, &quot;password&quot;:&quot;112233&quot; &#125; &#123; \"code\": 200, \"msg\": \"登录成功\", \"data\": &#123; \"token\": \"eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI1YjgzNTU2YjQ5OWY0YjU0ODU5M2Q5OWIjk4OTMwOCIsInN1YiI6IjIiLCJpc3MiOiJodWFuZiIsImlhdCI6MTY5NDg0ODU1OCwiZXhwIjoxNjk0ODUyMTU4fQ.Jca_ufkZFNv0vMvmap3r-AvD0QAjctUzdb5TxYcwicg\" &#125; &#125; 注意：第九步的请求一定要使用未加密的密码！！！！！！！！！（搞了一上午才解决..） 认证过滤器在上面学习的自定义security的思路当中，我们有一个功能需求是定义Jwt认证过滤器，这个功能还没有实现，下面就正式学习如何实现这个功能。要实现Jwt认证过滤器，我们需要获取token，然后解析token获取其中的userid，还需要从redis中获取用户信息，然后存入SecurityContextHolder 为什么要有redis参与: 是为了防止过了很久之后，浏览器没有关闭，拿着token也能访问，这样不安全 认证过滤器的作用是什么: 上面我们实现登录接口的时，当某个用户登录之后，该用户就会有一个token值，我们可以通过认证过滤器，由于有token值，并且token值认证通过，也就是证明是这个用户的token值，那么该用户访问我们的业务接口时，就不会被Security拦截。简单理解作用就是登录过的用户可以访问我们的业务接口，拿到对应的资源 第一步: 定义过滤器。在 src&#x2F;main&#x2F;java&#x2F;com.ehzyil 目录新建 filter.JwtAuthenticationTokenFilter 类，写入如下 package com.ehzyil.filter; import com.ehzyil.domain.LoginUser; import com.ehzyil.utils.JwtUtil; import com.ehzyil.utils.RedisCache; import io.jsonwebtoken.Claims; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import org.springframework.web.filter.OncePerRequestFilter; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.util.Objects; @Component public class JwtAuthenticationTokenFilter extends OncePerRequestFilter &#123; @Autowired private RedisCache redisCache; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; //获取token，指定你要获取的请求头叫什么 String token = request.getHeader(\"token\"); //判空，不一定所有的请求都有请求头，所以上面那行的token可能为空 //!StringUtils.hasText()方法用于检查给定的字符串是否为空或仅包含空格字符 if (!StringUtils.hasText(token)) &#123; //如果请求没有携带token，那么就不需要解析token，不需要获取用户信息，直接放行就可以 filterChain.doFilter(request, response); //return之后，就不会走下面那些代码 return; &#125; //解析token String userid; //把userid定义在外面，才能同时用于下面的46行和52行 try &#123; Claims claims = JwtUtil.parseJWT(token); userid = claims.getSubject(); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(\"token非法\"); &#125; //从redis中获取用户信息 String redisKey = \"login:\" + userid; //LoginUser是我们在domain目录写的实体类 LoginUser loginUser = redisCache.getCacheObject(redisKey); //判断获取到的用户信息是否为空，因为redis里面可能并不存在这个用户信息，例如缓存过期了 if(Objects.isNull(loginUser))&#123; //抛出一个异常 throw new RuntimeException(\"用户未登录\"); &#125; //把最终的LoginUser用户信息，通过setAuthentication方法，存入SecurityContextHolder //TODO 获取权限信息封装到Authentication中 UsernamePasswordAuthenticationToken authenticationToken = //第一个参数是LoginUser用户信息，第二个参数是凭证(null)，第三个参数是权限信息(null) new UsernamePasswordAuthenticationToken(loginUser,null,null); SecurityContextHolder.getContext().setAuthentication(authenticationToken); //全部做完之后，就放行 filterChain.doFilter(request, response); &#125; &#125; 第二步: 修改SecurityConfig类为如下，其实也就是在configure方法加了一点代码、并且注入了JwtAuthenticationTokenFilter类 @Configuration //实现Security提供的WebSecurityConfigurerAdapter类，就可以改变密码校验的规则了 public class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Bean //把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验 //注意也可以注入PasswordEncoder，效果是一样的，因为PasswordEncoder是BCry..的父类 public PasswordEncoder passwordEncoder()&#123; return new BCryptPasswordEncoder(); &#125; //---------------------------认证过滤器的实现---------------------------------- @Autowired //注入我们在filter目录写好的类 private JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter; //---------------------------登录接口的实现---------------------------------- @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http //由于是前后端分离项目，所以要关闭csrf .csrf().disable() //由于是前后端分离项目，所以session是失效的，我们就不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() //指定让spring security放行登录接口的规则 .authorizeRequests() // 对于登录接口 anonymous表示允许匿名访问 .antMatchers(\"/user/login\").anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); //---------------------------认证过滤器的实现---------------------------------- //把token校验过滤器添加到过滤器链中 //第一个参数是上面注入的我们在filter目录写好的类，第二个参数表示你想添加到哪个过滤器之前 http.addFilterBefore(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); &#125; &#125; 第三步: 本地打开你的redis 第四步: 运行引导类 第五步: 测试。打开你的postman，发送如下的POST请求，作用是先登录一个用户，这样就能生成这个用户对应的token值 &#123; &quot;code&quot;: 200, &quot;msg&quot;: &quot;登录成功&quot;, &quot;data&quot;: &#123; &quot;token&quot;: &quot;eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiIzZmU4MTk1YjY3MTc0MmM5YTgwODZkNzE2ZTM4OGNlNyIsInN1YiI6IjIiLCJpc3MiOiJodWFuZiIsImlhdCI6MTY5NDg0ODgzNCwiZXhwIjoxNjk0ODUyNDM0fQ.liyE_t-8Zzh2goiOg0crzQNTqMj1mNAyeg3pSQH0FZo&quot; &#125; &#125; 第六步: 测试。继续在你的postman，发送如下GET请求，作用是拿着刚刚的token值，去访问我们的业务接口，看会不会被Security拦截，如果不会拦截，那么就说明认证过滤器生效了，使用场景就是简单理解就是登录过的用户可以访问我们的业务接口，拿到对应的资源 注意，由于token值我们是存在redis，所以是有默认过期时间的。注意在请求头那里，key要写token，value要写你复制的token值，然后点击发送请求。这个token值实际上就是使用jwt工具类把112233密码加密后的密文，不信你翻一下前面笔记看当时112233的密文，长得是不是跟现在的token值格式一样 退出登录上面我们既测试了登录认证，又实现了基于密文的token认证，到此就完整地实现了我们在 ‘认证’ 的 ‘3. 自定义security的思路’ 里面的【登录】和【校验】的功能 那么，我们怎么退出登录呢，也就是让某个用户的登录状态消失，也就是让token失效 ? 实现起来也比较简单，只需要定义一个登陆接口，然后获取SecurityContextHolder中的认证信息，删除redis中对应的数据即可 注意: 我们的token其实就是用户密码的密文，token是存在redis里面 第一步: 把LoginService接口修改为如下，注意只是稍微增加了一点代码，我用虚线隔开了，增加的代码是在虚线的下方 package com.ehzyil.service; import com.ehzyil.domain.ResponseResult; import com.ehzyil.domain.User; import org.springframework.stereotype.Service; @Service public interface LoginService &#123; ResponseResult login(User user); &#x2F;&#x2F;-----------------------------------退出登录-------------------------------- ResponseResult logout(); &#125; 第二步: 把LoginServiceImpl实现类修改为如下，注意只是稍微增加了一点代码，我用虚线隔开了，增加的代码是在虚线的下方 @Service @Slf4j //写登录的核心代码 public class LoginServiceImpl implements LoginService &#123; @Autowired //先在SecurityConfig，使用@Bean注解重写官方的authenticationManagerBean类，然后这里才能注入成功 private AuthenticationManager authenticationManager; @Autowired //RedisCache是我们在utils目录写好的类 private RedisCache redisCache; @Override //ResponseResult和user是我们在domain目录写好的类 public ResponseResult login(User user) &#123; //用户在登录页面输入的用户名和密码 UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken(user.getUserName(), user.getPassword()); //获取AuthenticationManager的authenticate方法来进行用户认证 Authentication authenticate = authenticationManager.authenticate(authenticationToken); //判断上面那行的authenticate是否为null，如果是则认证没通过，就抛出异常 if (Objects.isNull(authenticate)) &#123; throw new RuntimeException(\"登录失败\"); &#125; //如果认证通过，就使用userid生成一个jwt，然后把jwt存入ResponseResult后返回 LoginUser loginUser = (LoginUser) authenticate.getPrincipal(); String userid = loginUser.getUser().getId().toString(); String jwt = JwtUtil.createJWT(userid); //把完整的用户信息存入redis，其中userid作为key，注意存入redis的时候加了前缀 login: Map&lt;String, String> map = new HashMap&lt;>(); map.put(\"token\", jwt); redisCache.setCacheObject(\"login:\" + userid, loginUser); log.info(\"将token存储到redis！\"); return new ResponseResult(200, \"登录成功\", map); &#125; @Override public ResponseResult logout() &#123; //获取我们在JwtAuthenticationTokenFilter类写的SecurityContextHolder对象中的用户id UsernamePasswordAuthenticationToken authentication = (UsernamePasswordAuthenticationToken) SecurityContextHolder.getContext().getAuthentication(); //loginUser是我们在domain目录写好的实体类 LoginUser loginUser = (LoginUser) authentication.getPrincipal(); //获取用户id Long userid = loginUser.getUser().getId(); //根据用户id，删除redis中的token值，注意我们的key是被 login: 拼接过的，所以下面写完整key的时候要带上 longin: redisCache.deleteObject(\"login:\" + userid); return new ResponseResult(200, \"注销成功\"); &#125; &#125; 第三步: 把LoginController类修改为如下，注意只是稍微增加了一点代码，我用虚线隔开了，增加的代码是在虚线的下方 //-----------------------------------退出登录-------------------------------- @RequestMapping(\"/user/logout\") //ResponseResult是我们在domain目录写好的实体类 public ResponseResult logout()&#123; return loginService.logout(); &#125; 第四步: 本地打开你的redis 第五步: 运行引导类 第六步: 测试。打开你的postman，发送如下的POST请求，作用是先登录一个用户，这样就能生成这个用户对应的token值 第七步: 测试。继续在你的postman，发送如下GET请求，作用是拿着刚刚的token值，去访问我们的业务接口，看在有登录状态的情况下，能不能访问 注意还要带上你刚刚复制的token值，粘贴到消息头的Value输入框 第八步: 测试。继续在你的postman，发送如下GET请求，作用是退出登录，然后去访问我们的业务接口，看在没有登录状态的情况下，能不能访问 2.授权授权的基本流程在SpringSecurity中，会使用默认的FilterSecurityInterceptor来进行权限校验。在FilterSecurityInterceptor中会从SecurityContextHolder获取其中的Authentication，然后获取其中的权限信息。当前用户是否拥有访问当前资源所需的权限 所以我们在项目中只需要把当前登录用户的权限信息也存入Authentication，然后设置我们的资源所需要的权限即可。 自定义访问路径的权限SpringSecurity为我们提供了基于注解的权限控制方案，这也是我们项目中主要采用的方式。我们可以使用注解去指定访问对应的资源所需的权限 第一步: 在SecurityConfig配置类添加如下，作用是开启相关配置 @EnableGlobalMethodSecurity(prePostEnabled &#x3D; true) 第二步: 开启了相关配置之后，就能使用@PreAuthorize等注解了。 @PreAuthorize(&quot;hasAuthority(&#39;hello&#39;)&quot;) 在HelloController类的hello方法，添加如下注解，其中test表示自定义权限的名字 @RestController public class HelloController &#123; @GetMapping(\"/hello\") @PreAuthorize(\"hasAuthority('hello')\") public String hello() &#123; return \"hello world\"; &#125; @PreAuthorize(\"hasAuthority('test')\") @GetMapping(\"/test\") public String hello2() &#123; return \"hasAuthority('test')\"; &#125; &#125; 带权限访问的实现权限信息: 有特殊含义的字符串 我们前面在登录时，会调用到MyUserDetailServiceImpl类的loadUserByUsername方法，当时我们写loadUserByUsername方法时，只写了查询用户数据信息的代码，还差查询用户权限信息的代码。在登录完之后，因为携带了token，所以需要在JwtAuthenticationTokenFilter类添加 ‘获取权限信息封装到Authentication中’ 的代码，添加到UsernamePasswordAuthenticationToken的第三个参数里面，我们当时第三个参数传的是null。 第一步: 在上面的自定义访问路径的权限，我们给HelloController类的”&#x2F;hello”路径和”&#x2F;test”路径添加了权限限制，只有用户具有叫hello或test的权限，才能访问这个路径。 第二步: 把MyUserDetailServiceImpl类修改为如下，主要是增加了查询用户权限信息的代码，权限列表暂时写死 @Override //UserDetails是Security官方提供的接口 public UserDetails loadUserByUsername(String xxusername) throws UsernameNotFoundException &#123; //查询用户信息。我们写的userMapper接口里面是空的，所以调用的是mybatis-plus提供的方法 LambdaQueryWrapper&lt;User> queryWrapper = new LambdaQueryWrapper&lt;>(); //eq方法表示等值匹配，第一个参数是数据库的用户名，第二个参数是我们传进来的用户名，这两个参数进行比较是否相等 queryWrapper.eq(User::getUserName,xxusername); User user = userMapper.selectOne(queryWrapper); //如果用户传进来的用户名，但是数据库没有这个用户名，就会导致我们是查不到的情况，那么就进行下面的判断。避免程序安全问题 if(Objects.isNull(user))&#123;//判断user对象是否为空。当在数据库没有查到数据时，user就会为空，也就会进入这个判断 throw new RuntimeException(\"用户名或者密码错误\"); &#125; //--------------------------------查询用户权限信息--------------------------------- //由于我们自定义了3个权限，所以用List集合存储。注意权限实际就是'有特殊含义的字符串'，所以下面的三个字符串就是自定义的 //下面那行就是我们的权限集合，等下还要在LoginUser类做权限集合的转换 List&lt;String> list = new ArrayList&lt;>(Arrays.asList(\"test\",\"adminAuth\",\"huanfAuth\")); //------------------------------------------------------------------------------ //把查询到的user结果，封装成UserDetails类型，然后返回。 //但是由于UserDetails是个接口，所以我们先需要在domino目录新建LoginUser类，作为UserDetails的实现类，再写下面那行 return new LoginUser(user,list); //这里传了第二个参数，表示的是权限信息 &#125; 第三步: 封装权限信息。把LoginUser类修改为如下，主要是增加了把用户权限字符串的集合，转换封装在authorities变量里面 @Data //get和set方法 @NoArgsConstructor //无参构造 //实现UserDetails接口之后，要重写UserDetails接口里面的7个方法 public class LoginUser implements UserDetails &#123; private User user; //查询用户权限信息 private List&lt;String> permissions; public LoginUser(User user, List&lt;String> permissions) &#123; this.user = user; this.permissions = permissions; &#125; //我们把这个List写到外面这里了，注意成员变量名一定要是authorities，不然会出现奇奇怪怪的问题 @JSONField(serialize = false) //这个注解的作用是不让下面那行的成员变量序列化存入redis，避免redis不支持而报异常 private List&lt;SimpleGrantedAuthority> authorities; @Override //用于返回权限信息。现在我们正在学'认证'，'权限'后面才学。所以返回null即可 //当要查询用户信息的时候，我们不能单纯返回null，要重写这个方法，作用是封装权限信息 public Collection&lt;? extends GrantedAuthority> getAuthorities() &#123; //重写GrantedAuthority接口的getAuthorities方法 /* 第一种权限集合的转换写法如下，传统的方式 //把xxpermissions中的String类型的权限信息(也就是\"test\",\"adminAuth\",\"huanfAuth\")封装成SimpleGrantedAuthority对象 //List&lt;GrantedAuthority> authorities = new ArrayList&lt;>(); //简化这行如下一行，我们把authorities成员变量写到外面了 authorities = new ArrayList&lt;>(); for (String yypermission : xxpermissions) &#123; SimpleGrantedAuthority yyauthority = new SimpleGrantedAuthority(yypermission); authorities.add(yyauthority); &#125; */ /* 第二种权限集合的转换写法如下，函数式编程 + stream流 的方式，双引号表示方法引用 */ //当authorities集合为空，就说明是第一次，就需要转换，当不为空就说明不是第一次，就不需要转换直接返回 if(authorities != null)&#123; //严谨来说这个if判断是避免整个调用链中security本地线程变量在获取用户时的重复解析，和redis存取无关 return authorities; &#125; //为空的话就会执行下面的转换代码 //List&lt;SimpleGrantedAuthority> authorities = xxpermissions //简化这行如下一行，我们把authorities成员变量写到外面了 authorities = permissions .stream() .map(SimpleGrantedAuthority::new) .collect(Collectors.toList()); //最终返回转换结果 return authorities; &#125; @Override //用于获取用户密码。由于使用的实体类是User，所以获取的是数据库的用户密码 public String getPassword() &#123; return user.getPassword(); &#125; @Override //用于获取用户名。由于使用的实体类是User，所以获取的是数据库的用户名 public String getUsername() &#123; return user.getUserName(); &#125; @Override //判断登录状态是否过期。把这个改成true，表示永不过期 public boolean isAccountNonExpired() &#123; return true; &#125; @Override //判断账号是否被锁定。把这个改成true，表示未锁定，不然登录的时候，不让你登录 public boolean isAccountNonLocked() &#123; return true; &#125; @Override //判断登录凭证是否过期。把这个改成true，表示永不过期 public boolean isCredentialsNonExpired() &#123; return true; &#125; @Override //判断用户是否可用。把这个改成true，表示可用状态 public boolean isEnabled() &#123; return true; &#125; &#125; 第四步: 把JwtAuthenticationTokenFilter类修改为如下，主要是补充了前面没写的第三个参数，写成第三步封装好的权限信息 //把最终的LoginUser用户信息，通过setAuthentication方法，存入SecurityContextHolder UsernamePasswordAuthenticationToken authenticationToken = //第一个参数是LoginUser用户信息，第二个参数是凭证(null)，第三个参数是权限信息(null) //在学习封装权限信息时，就要把下面的第三个参数补充完整，getAuthorities是我们在loginUser写的方法 new UsernamePasswordAuthenticationToken(loginUser,null,loginUser.getAuthorities()); SecurityContextHolder.getContext().setAuthentication(authenticationToken); 第五步: 测试。打开postman，发送如下的POST请求，作用是先登录一个用户，这样就能生成这个用户对应的token值 继续在postman，发送如下GET请求，作用是拿着刚刚的token值，去访问我们的业务接口，看在有登录状态的情况下，能不能访问 继续访问hello路径因为没有赋予用户hello权限，因此禁止访问。 3.授权-RBAC权限模型刚刚我们实现了只有当用户具备某种权限，才能访问我们的某个业务接口。但是存在一个问题，我们在给用户设置权限的时候，是写死的，在真正的开发中，我们是需要从数据库查询权限信息，下面就来学习如何从数据库查询权限信息，然后封装给用户。这个功能需要先准备好数据库和java代码，所以，下面的 ‘授权-RBAC权限模型’ 都是在围绕这个功能进行学习，直到实现这个功能 介绍RBAC权限模型 (Role-Based Access Control) ，是权限系统用到的经典模型，基于角色的权限控制。该模型由以下五个主要组成部分构成: 一、用户: 在系统中代表具体个体的实体，可以是人员、程序或其他实体。用户需要访问系统资源 二、角色: 角色是权限的集合，用于定义一组相似权限的集合。角色可以被赋予给用户，从而授予用户相应的权限 三、权限: 权限表示系统中具体的操作或功能，例如读取、写入、执行等。每个权限定义了对系统资源的访问规则 四、用户-角色映射: 用户-角色映射用于表示用户与角色之间的关系。通过为用户分配适当的角色，用户可以获得与角色相关联的权限 五、角色-权限映射: 角色-权限映射表示角色与权限之间的关系。每个角色都被分配了一组权限，这些权限决定了角色可执行的操作 截止目前，我们数据库只有 sys_user 用户表，下面我们会新增4张表，分别是权限表(每条数据是单个’粒度细的权限’)、角色表(每条数据是多个’粒度细的权限’)、角色表与权限表的中间表、用户表与角色表的中间表。总共5张表，组成了RBAC模型，中间表的作用是维护两张表的多对多关系. 数据库表的创建第一步: 在你数据库的huanf_security 库，新建 sys_menu权限表、sys_role角色表、sys_role_menu中间表、sys_user_role中间表，并插入数据 create database if not exists huanf_security; use huanf_security; CREATE TABLE `sys_menu` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `menu_name` varchar(64) NOT NULL DEFAULT 'NULL' COMMENT '菜单名', `path` varchar(200) DEFAULT NULL COMMENT '路由地址', `component` varchar(255) DEFAULT NULL COMMENT '组件路径', `visible` char(1) DEFAULT '0' COMMENT '菜单状态（0显示 1隐藏）', `status` char(1) DEFAULT '0' COMMENT '菜单状态（0正常 1停用）', `perms` varchar(100) DEFAULT NULL COMMENT '权限标识', `icon` varchar(100) DEFAULT '#' COMMENT '菜单图标', `create_by` bigint(20) DEFAULT NULL, `create_time` datetime DEFAULT NULL, `update_by` bigint(20) DEFAULT NULL, `update_time` datetime DEFAULT NULL, `del_flag` int(11) DEFAULT '0' COMMENT '是否删除（0未删除 1已删除）', `remark` varchar(500) DEFAULT NULL COMMENT '备注', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COMMENT='权限表'; CREATE TABLE `sys_role` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(128) DEFAULT NULL, `role_key` varchar(100) DEFAULT NULL COMMENT '角色权限字符串', `status` char(1) DEFAULT '0' COMMENT '角色状态（0正常 1停用）', `del_flag` int(1) DEFAULT '0' COMMENT 'del_flag', `create_by` bigint(200) DEFAULT NULL, `create_time` datetime DEFAULT NULL, `update_by` bigint(200) DEFAULT NULL, `update_time` datetime DEFAULT NULL, `remark` varchar(500) DEFAULT NULL COMMENT '备注', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COMMENT='角色表'; CREATE TABLE `sys_role_menu` ( `role_id` bigint(200) NOT NULL AUTO_INCREMENT COMMENT '角色ID', `menu_id` bigint(200) NOT NULL DEFAULT '0' COMMENT '菜单id', PRIMARY KEY (`role_id`,`menu_id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4; CREATE TABLE `sys_user_role` ( `user_id` bigint(200) NOT NULL AUTO_INCREMENT COMMENT '用户id', `role_id` bigint(200) NOT NULL DEFAULT '0' COMMENT '角色id', PRIMARY KEY (`user_id`,`role_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; insert into sys_user_role values (2,1); insert into sys_role values (1,'经理','ceo',0,0,default,default,default,default,default), (2,'程序员','coder',0,0,default,default,default,default,default); insert into sys_role_menu values (1,1),(1,2); insert into sys_menu values (1,'部门管理','dept','system/dept/index',0,0,'system:dept:list','#',default,default,default,default,default,default), (2,'测试','test','system/test/index',0,0,'system:test:list','#',default,default,default,default,default,default) 第二步: 测试SQL语句，也就是确认一下你的建表、插入数据是否达到要求 # 通过用户id去查询这个用户具有的权限列表。也就是根据userid查询perms，并且限制条件为role和menu都必须正常状态么也就是等于0 SELECT DISTINCT m.`perms` FROM sys_user_role ur LEFT JOIN `sys_role` r ON ur.`role_id` = r.`id` LEFT JOIN `sys_role_menu` rm ON ur.`role_id` = rm.`role_id` LEFT JOIN `sys_menu` m ON m.`id` = rm.`menu_id` WHERE user_id = 2 AND r.`status` = 0 AND m.`status` = 0 查询数据库的权限信息第一步: 在 domain 目录新建 Menu 实体类，写入如下 //权限表(也叫菜单表)的实体类 @TableName(value=\"sys_menu\") //指定表名，避免等下mybatisplus的影响 @Data @AllArgsConstructor @NoArgsConstructor @JsonInclude(JsonInclude.Include.NON_NULL) //Serializable是官方提供的，作用是将对象转化为字节序列 public class Menu implements Serializable &#123; private static final long serialVersionUID = -54979041104113736L; @TableId private Long id; /** * 菜单名 */ private String menuName; /** * 路由地址 */ private String path; /** * 组件路径 */ private String component; /** * 菜单状态（0显示 1隐藏） */ private String visible; /** * 菜单状态（0正常 1停用） */ private String status; /** * 权限标识 */ private String perms; /** * 菜单图标 */ private String icon; private Long createBy; private Date createTime; private Long updateBy; private Date updateTime; /** * 是否删除（0未删除 1已删除） */ private Integer delFlag; /** * 备注 */ private String remark; &#125; 第二步: 在 mapper 目录新建 MenuMapper 接口。作用是定义mapper，其中提供一个方法可以根据userid查询权限信息 @Mapper &#x2F;&#x2F;BaseMapper是mybatisplus官方提供的接口，里面提供了很多单表查询的方法 public interface MenuMapper extends BaseMapper&lt;Menu&gt; &#123; &#x2F;&#x2F;&#x2F;&#x2F;由于是多表联查，mybatisplus的BaseMapper接口没有提供，我们需要自定义方法，所以需要创建对应的mapper文件，定义对应的sql语句 List&lt;String&gt; selectPermsByUserId(Long id); &#125; 第三步: 在 resources 目录新建 mapper目录，接着在这个mapper目录新建File，名字叫 MenuMapper.xml，写入如下 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?> &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" > &lt;mapper namespace=\"com.ehzyil.mapper.MenuMapper\"> &lt;select id=\"selectPermsByUserId\" resultType=\"java.lang.String\"> SELECT DISTINCT m.`perms` FROM sys_user_role ur LEFT JOIN `sys_role` r ON ur.`role_id` = r.`id` LEFT JOIN `sys_role_menu` rm ON ur.`role_id` = rm.`role_id` LEFT JOIN `sys_menu` m ON m.`id` = rm.`menu_id` WHERE user_id = #&#123;userid&#125; AND r.`status` = 0 AND m.`status` = 0 &lt;/select> &lt;/mapper> 第四步: 把application.yml修改为如下，作用是告诉MP，刚刚写的MenuMapper.xml文件是在哪个地方 mybatis-plus: # 配置MenuMapper.xml文件的路径 # 也可以不写，因为默认就是在类加载路径(resouces)下的mapper目录的任意层级的后缀为xml的文件，都会被扫描到 mapper-locations: classpath*:/mapper/**/*.xml 第五步: 测试。这里只是检查mybatismlus能不能拿到数据库的权限字符串。在MapperTest类添加如下 @Autowired private MenuMapper menuMapper; @Test public void testSelectPermsByUserId()&#123; &#x2F;&#x2F;L表示Long类型 List&lt;String&gt; list &#x3D; menuMapper.selectPermsByUserId(2L); System.out.println(list); &#125; RBAC权限模型的实现不要把RBAC模型想得很难，其实难的话只是数据库表的设计和SQL语句的编写，需要5张表。数据库设计好之后就很简单了，使用mybatis-plus去查询数据库表的权限字符串(例如我们的权限字符串是放在sys_menu表)，然后把你查到的数据去替换死数据就好了。我们只剩最后一步，就是替换死数据，如下 第一步: 把MyUserDetailServiceImpl类修改为如下，我们只是增加了查询来自数据库的权限信息的代码 @Autowired private UserMapper userMapper; @Autowired &#x2F;&#x2F;MenuMapper是我们在mapper目录写好的接口，作用是查询来自数据库的权限信息 private MenuMapper menuMapper; @Override &#x2F;&#x2F;UserDetails是Security官方提供的接口 public UserDetails loadUserByUsername(String xxusername) throws UsernameNotFoundException &#123; &#x2F;&#x2F;查询用户信息。我们写的userMapper接口里面是空的，所以调用的是mybatis-plus提供的方法 LambdaQueryWrapper&lt;User&gt; queryWrapper &#x3D; new LambdaQueryWrapper&lt;&gt;(); &#x2F;&#x2F;eq方法表示等值匹配，第一个参数是数据库的用户名，第二个参数是我们传进来的用户名，这两个参数进行比较是否相等 queryWrapper.eq(User::getUserName,xxusername); User user &#x3D; userMapper.selectOne(queryWrapper); &#x2F;&#x2F;如果用户传进来的用户名，但是数据库没有这个用户名，就会导致我们是查不到的情况，那么就进行下面的判断。避免程序安全问题 if(Objects.isNull(user))&#123;&#x2F;&#x2F;判断user对象是否为空。当在数据库没有查到数据时，user就会为空，也就会进入这个判断 throw new RuntimeException(&quot;用户名或者密码错误&quot;); &#125; &#x2F;&#x2F;--------------------------------查询用户权限信息--------------------------------- &#x2F;&#x2F;由于我们自定义了3个权限，所以用List集合存储。注意权限实际就是&#39;有特殊含义的字符串&#39;，所以下面的三个字符串就是自定义的 &#x2F;&#x2F;下面那行就是我们的权限集合，等下还要在LoginUser类做权限集合的转换 &#x2F;&#x2F; List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;(Arrays.asList(&quot;test&quot;,&quot;adminAuth&quot;,&quot;huanfAuth&quot;)); &#x2F;&#x2F;-------------------------------查询来自数据库的权限信息-------------------------------- List&lt;String&gt; list &#x3D; menuMapper.selectPermsByUserId(user.getId()); &#x2F;&#x2F;------------------------------------------------------------------------------ &#x2F;&#x2F;把查询到的user结果，封装成UserDetails类型，然后返回。 &#x2F;&#x2F;但是由于UserDetails是个接口，所以我们先需要在domino目录新建LoginUser类，作为UserDetails的实现类，再写下面那行 return new LoginUser(user,list); &#x2F;&#x2F;这里传了第二个参数，表示的是权限信息 &#125; 第二步: 由于我们知道数据库传过来的权限字符串是 system:dept:list 和 system:test:list，所以我们要把HelloController类的权限字符串修改为如下 system:test:list 第三步: 测试。 自定义异常处理面的我们学习了 ‘认证’ 和 ‘授权’，实现了基本的权限管理，然后也学习了从数据库获取授权的 ‘授权-RBAC权限模型’，实现了从数据库获取用户具备的权限字符串。到此，我们完整地实现了权限管理的功能，但是，当认证或授权出现报错时，我们希望响应回来的json数据有实体类的code、msg、data这三个字段，怎么实现呢 我们需要学习Spring Security的异常处理机制，就可以在认证失败或者是授权失败的情况下也能和我们的接口一样返回相同结构的json，这样可以让前端能对响应进行统一的处理 在SpringSecurity中，如果我们在认证或者授权的过程中出现了异常会被ExceptionTranslationFilter捕获到，如上图。在ExceptionTranslationFilter中会去判断是认证失败还是授权失败出现的异常，其中有如下两种情况 一、如果是认证过程中出现的异常会被封装成AuthenticationException然后调用AuthenticationEntryPoint对象的方法去进行异常处理。 二、如果是授权过程中出现的异常会被封装成AccessDeniedException然后调用AccessDeniedHandler对象的方法去进行异常处理。 总结: 如果我们需要自定义异常处理，我们只需要创建AuthenticationEntryPoint和AccessDeniedHandler的实现类对象，然后配置给SpringSecurity即可 第一步: 在 src&#x2F;main&#x2F;java&#x2F;com.ehzyil 目录新建 handler.AuthenticationEntryPointImpl类，写入如下，作用是自定义认证的实现类 @Component //这个类只处理认证异常，不处理授权异常 public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint &#123; @Override //第一个参数是请求对象，第二个参数是响应对象，第三个参数是异常对象。把异常封装成授权的对象，然后封装到handle方法 public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException &#123; //ResponseResult是我们在domain目录写好的实体类。HttpStatus是spring提供的枚举类，UNAUTHORIZED表示401状态码 ResponseResult result = new ResponseResult(HttpStatus.UNAUTHORIZED.value(), \"用户认证失败，请重新登录\"); //把上面那行拿到的result对象转换为JSON字符串 String json = JSON.toJSONString(result); //WebUtils是我们在utils目录写好的类 WebUtils.renderString(response, json); &#125; &#125; 第二步: 在handler目录新建 AccessDeniedHandlerImpl 类，写入如下，作用是自定义授权的实现类 @Component //这个类只处理授权异常，不处理认证异常 public class AccessDeniedHandlerImpl implements AccessDeniedHandler &#123; @Override //第一个参数是请求对象，第二个参数是响应对象，第三个参数是异常对象。把异常封装成认证的对象，然后封装到handle方法 public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException &#123; //ResponseResult是我们在domain目录写好的实体类。HttpStatus是spring提供的枚举类，FORBIDDEN表示403状态码 ResponseResult result = new ResponseResult(HttpStatus.FORBIDDEN.value(), \"您没有权限进行访问\"); //把上面那行拿到的result对象转换为JSON字符串 String json = JSON.toJSONString(result); //WebUtils是我们在utils目录写好的类 WebUtils.renderString(response, json); &#125; &#125; 第三步: 把 SecurityConfig 类修改为如下，作用是把刚刚两个异常处理的实现类配置在Spring Security里面 @Configuration @EnableGlobalMethodSecurity(prePostEnabled = true) //实现Security提供的WebSecurityConfigurerAdapter类，就可以改变密码校验的规则了 public class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired //注入我们在filter目录写好的类 private JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter; @Autowired //注入Security提供的认证失败的处理器，这个处理器里面的AuthenticationEntryPointImpl实现类，用的不是官方的了， //而是用的是我们在handler目录写好的AuthenticationEntryPointImpl实现类 private AuthenticationEntryPoint authenticationEntryPoint; @Autowired //注入Security提供的授权失败的处理器，这个处理器里面的AccessDeniedHandlerImpl实现类，用的不是官方的了， //而是用的是我们在handler目录写好的AccessDeniedHandlerImpl实现类 private AccessDeniedHandler accessDeniedHandler; //---------------------------认证过滤器的实现---------------------------------- @Bean //把BCryptPasswordEncoder对象注入Spring容器中，SpringSecurity就会使用该PasswordEncoder来进行密码校验 //注意也可以注入PasswordEncoder，效果是一样的，因为PasswordEncoder是BCry..的父类 public PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder(); &#125; //---------------------------登录接口的实现---------------------------------- @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http //由于是前后端分离项目，所以要关闭csrf .csrf().disable() //由于是前后端分离项目，所以session是失效的，我们就不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() //指定让spring security放行登录接口的规则 .authorizeRequests() // 对于登录接口 anonymous表示允许匿名访问 .antMatchers(\"/user/login\").anonymous() // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); //---------------------------认证过滤器的实现---------------------------------- //把token校验过滤器添加到过滤器链中 //第一个参数是上面注入的我们在filter目录写好的类，第二个参数表示你想添加到哪个过滤器之前 http.addFilterBefore(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); //---------------------------异常处理的相关配置------------------------------- http.exceptionHandling() //配置认证失败的处理器 .authenticationEntryPoint(authenticationEntryPoint) //配置授权失败的处理器 .accessDeniedHandler(accessDeniedHandler); &#125; &#125; 第六步: 测试认证异常。打开你的postman，发送如下的POST请求，作用是登录一个不存在的用户，模拟认证异常 第七步: 测试授权异常。先在HelloController类修改PreAuthorize注解的权限字符串，修改成huanf用户不存在的权限字符串，接着重新运行TokenApplication引导类，然后去正常登录一个用户并访问 &#x2F;hello 业务接口，必然会报权限异常，然后我们看一下响应回来的数据格式，是不是我们定义的json格式 跨域跨域的后端解决由于我们的SpringSecurity负责所有请求和资源的管理，当请求经过SpringSecurity时，如果SpringSecurity不允许跨域，那么也是会被拦截，所以下面我们将学习并解决跨域问题。前面我们在测试时，是在postman测试，因此没有出现跨域问题的情况，postman只是负责发请求跟浏览器没关系 浏览器出于安全的考虑，使用 XMLHttpRequest 对象发起HTTP请求时必须遵守同源策略，否则就是跨域的HTTP请求，默认情况下是被禁止的。 同源策略要求源相同才能正常进行通信，即协议、域名、端口号都完全一致。 前后端分离项目，前端项目和后端项目一般都不是同源的，所以肯定会存在跨域请求的问题 我们要实现如下两个需求 (我实际做出的效果跟教程视频不一致，第二个需求其实没必要存在，boot解决了跨域就都解决了): 1、开启SpringBoot的允许跨域访问 2、开启SpringSecurity的允许跨域访问 第一步: 开启SpringBoot的允许跨域访问。在 config 目录新建 CorsConfig 类，写入如下 @Configuration public class CorsConfig implements WebMvcConfigurer &#123; @Override //重写spring提供的WebMvcConfigurer接口的addCorsMappings方法 public void addCorsMappings(CorsRegistry registry) &#123; // 设置允许跨域的路径 registry.addMapping(\"/**\") // 设置允许跨域请求的域名 .allowedOriginPatterns(\"*\") // 是否允许cookie .allowCredentials(true) // 设置允许的请求方式 .allowedMethods(\"GET\", \"POST\", \"DELETE\", \"PUT\") // 设置允许的header属性 .allowedHeaders(\"*\") // 跨域允许时间 .maxAge(3600); &#125; &#125; 第二步: 开启SpringSecurity的允许跨域访问。在把 SecurityConfig 修改为如下。 protected void configure(HttpSecurity http) throws Exception &#123; ... //--------------------------- 设置security运行跨域访问 ------------------ http.cors(); &#125; 第三步: 由于没有前端项目，所以我们下面会跑一个前端项目，然后测试后端的跨域功能 第四步: 运行前端项目。请确保你电脑有安装node.js，然后以管理员身份打开命令行窗口，输入如下 npm install npm run serve 第五步: 访问前端的项目 http:&#x2F;&#x2F;localhost:8080&#x2F;#&#x2F;login 第六步: 由于这个前端项目的要求后端服务的端口是8888，所以我们要修改一下idea的application.yml文件，把默认的8089端口改为8888端口,为了等下直观的看出跨域的问题，我们把后端的 boot与security的跨域代码注释掉 server: # 指定后端的启动端口 port: 8888 第七步: 测试。访问前端项目，登录一个数据库的真实用户，假的也行，主要是看请求会不会出现跨域问题 第八步: 我后来呢，把security的跨域单独注释了，然后重新运行引导类，想验证是不是只要security不允许跨域，那么即使boot允许跨域，那最终也是不允许跨域的，原因是资源必然要经过security。但是实验结果却是security注释了之后，仅靠boot的跨域放行，前端竟然也能正常访问后端接口 授权-权限校验的方法上面学的是HelloController类的 @PreAuthorize注解 的三个方法 我们前面都是使用@PreAuthorize注解，然后在在其中使用的是hasAuthority方法进行校验。SpringSecurity还为我们提供了其它方法例如: hasAnyAuthority，hasRole，hasAnyRole等 1. hasAuthority方法我们最早使用@PreAuthorize注解是在前面笔记的 ‘授权’ 的自定义访问路径的权限。可以回去看看，当时并没有详细学习@PreAuthorize注解的hasAuthority方法，只是直接使用，我们下面就来学习一下hasAuthority方法的原理，然后再学习hasAnyAuthority、hasRole、hasAnyRole方法就容易理解了 hasAuthority方法: 执行到了SecurityExpressionRoot的hasAuthority，内部其实是调用authentication的getAuthorities方法获取用户的权限列表。然后判断我们存入的方法参数数据在权限列表中。hasAnyAuthority方法可以传入多个权限，只有用户有其中任意一个权限都可以访问对应资源 hasAuthority方法的执行流程如下图，图比较多，请从上往下查看 2. hasAnyAuthority方法hasAnyAuthority方法的执行流程跟上面的hasAuthority方法是一样的，只是传参不同。所以重点演示传参，执行流程是真的一模一样，把上面的hasAuthority方法的执行流程认真看一次就行了。hasAuthority方法只能传入一个参数，也就是一个权限字符串。hasAnyAuthority方法可以传入多个参数，也就是多个权限字符串，只要用户具有其中任意一个权限就能访问指定业务接口 第一步: 为方便演示hasAnyAuthority方法能够传入多个参数并看到最终效果，我们把HelloController类的@RequestMapping注解修改为如下 @PreAuthorize(&quot;hasAnyAuthority(&#39;zidingyi&#39;,&#39;huanf&#39;,&#39;system:dept:list&#39;)&quot;); &#x2F;&#x2F;传入3个自定义权限 第二步: 运行引导类，打开postman，发送登录请求，然后发送访问&#x2F;hello接口的请求 3. hasRole方法首先是执行流程，如下几张图，从上往下看，很精华没有尿点 下图是打断点后的测试图 然后是测试的操作，如下 第一步: 为方便演示hasAnyAuthority方法能够传入多个参数并看到最终效果，我们把HelloController类的@RequestMapping注解修改为如下 @PreAuthorize(\"hasRole('system:dept:list')\") //只能传一个权限字符串，多传会报红线 第二步: 运行引导类，打开postman软件，发送登录请求，然后发送访问&#x2F;hello接口的请求 4. hasAnyRole方法执行流程跟刚刚的hasRole方法是一模一样的，只是传参不同。把上面的hasRole方法的执行流程认真看一次就行了。hasRole方法只能传入一个参数，也就是一个权限字符串。hasAnyRole方法可以传入多个参数，也就是多个权限字符串，只要用户具有其中任意一个权限就能访问指定业务接口 第一步: 为方便演示hasAnyAuthority方法能够传入多个参数并看到最终效果，我们把HelloController类的@RequestMapping注解修改为如下 @PreAuthorize(\"hasAnyRole('zidingyi','huanf','system:dept:list')\") 第二步: 运行引导类，打开postman软件，发送登录请求，然后发送访问&#x2F;hello接口的请求 5.自定义权限校验的方法在上面的源码中，我们知道security校验权限的PreAuthorize注解，其实就是获取用户权限，然后跟业务接口的权限进行比较，最后返回一个布尔类型。自定义一个权限校验方法的话，就需要新建一个类，在类里面定义一个方法，按照前面学习的三种方法的定义格式，然后返回值是布尔类型。如下 第一步: 在 src&#x2F;main&#x2F;java&#x2F;com.ehzyil目录新建 expression.HuanfExpressionRoot 类，写入如下 @Component(&quot;huanfEX&quot;) &#x2F;&#x2F;自定义权限校验的方法 public class ExpressionRoot &#123; &#x2F;&#x2F;自定义权限校验的方法 public boolean huanfHasAuthority(String authority) &#123; &#x2F;&#x2F;获取用户具有的权限字符串，有可能用户具有多个权限字符串，所以获取后是一个集合 Authentication authentication &#x3D; SecurityContextHolder.getContext().getAuthentication(); &#x2F;&#x2F;LoginUser是我们在domain目录写好的实体类 LoginUser loginUser &#x3D; (LoginUser) authentication.getPrincipal(); List&lt;String&gt; permissions &#x3D; loginUser.getPermissions(); &#x2F;&#x2F;判断用户权限集合中，是否存在跟业务接口(业务接口的权限字符串会作为authority形参传进来)一样的权限 return permissions.contains(authority); &#125; &#125; 第二步: 刚刚在第一步自定义了huanfHasAuthority方法，用于权限校验，那么如何让 @PreAuthorize 注解去使用huanfHasAuthority方法，只需要在SPEL表达式来获取容器中bean的名字。修改HelloController类为如下 @RestController public class HelloController &#123; @GetMapping(\"/hello\") //官方提供的4个权限校验的方法 //@PreAuthorize(\"hasAuthority('system:dept:list')\") //@PreAuthorize(\"hasAnyAuthority('zidingyi','huanf','system:dept:list')\") //@PreAuthorize(\"hasRole('system:dept:list')\") //@PreAuthorize(\"hasAnyRole('zidingyi','huanf','system:dept:list')\") //自定义权限校验的方法，huanfHasAuthority @PreAuthorize(\"@huanfEX.huanfHasAuthority('system:dept:list')\") public String hello() &#123; return \"欢迎，开始你新的学习旅程吧\"; &#125; @PreAuthorize(\"hasAuthority('test')\") @GetMapping(\"/test\") public String hello2() &#123; return \"hasAuthority('test')\"; &#125; &#125; 使用SPEL表达式，指定@PreAuthorize注解使用我们自定义的huanfHasAuthority方法 第三步: 运行引导类，打开postman软件，发送登录请求，然后发送访问&#x2F;hello接口的请求 6.基于配置的权限控制前面学习的权限控制是基于@PreAuthorize注解来完成的，如何使用配置的方式，也就是在配置类当中，来实现权限控制，如下 第一步: 在HelloController类添加如下，作用是新增一个接口 &#x2F;&#x2F;基于配置的权限控制 @RequestMapping(&quot;&#x2F;configAuth&quot;) public ResponseResult xx()&#123; return new ResponseResult(200,&quot;访问成功&quot;); &#125; 第二步: 把SecurityConfig类修改为如下，主要就是添加权限控制相关的配置 @Override protected void configure(HttpSecurity http) throws Exception &#123; http //由于是前后端分离项目，所以要关闭csrf .csrf().disable() //由于是前后端分离项目，所以session是失效的，我们就不通过Session获取SecurityContext .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() //指定让spring security放行登录接口的规则 .authorizeRequests() // 对于登录接口 anonymous表示允许匿名访问 .antMatchers(\"/user/login\").anonymous() //基于配置的的权限控制。指定接口的地址，为HelloController类里面的/configAuth接口，指定权限为system:dept:list .antMatchers(\"/configAuth\").hasAuthority(\"system:dept:list\") //上一行的hasAuthority方法就是security官方提供的4种权限控制的方法之一 // 除上面外的所有请求全部需要鉴权认证 .anyRequest().authenticated(); //---------------------------认证过滤器的实现---------------------------------- //把token校验过滤器添加到过滤器链中 //第一个参数是上面注入的我们在filter目录写好的类，第二个参数表示你想添加到哪个过滤器之前 http.addFilterBefore(jwtAuthenticationTokenFilter, UsernamePasswordAuthenticationFilter.class); //---------------------------异常处理的相关配置------------------------------- http.exceptionHandling() //配置认证失败的处理器 .authenticationEntryPoint(authenticationEntryPoint) //配置授权失败的处理器 .accessDeniedHandler(accessDeniedHandler); //---------------------------👇 设置security运行跨域访问 👇------------------ http.cors(); &#125; 第三步: 运行引导类，打开postman软件，发送登录请求，然后发送访问&#x2F;configAuth接口的请求 防护CSRF攻击在SecurityConfig类里面的configure方法里面，有一个配置如下，我们上面都没有去学习，下面就来了解一下 http..csrf().disable(); //关闭csrf，可防护csrf攻击。如果不关闭的话 CSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一，如图 详细看这篇博客: https://blog.csdn.net/freeking101/article/details/86537087 防护: SpringSecurity去防止CSRF攻击的方式就是通过csrf_token。后端会生成一个csrf_token，前端发起请求的时候需要携带这个csrf_token,后端会有过滤器进行校验，如果没有携带或者是伪造的就不允许访问 我们可以发现CSRF攻击依靠的是cookie中所携带的认证信息。但是在前后端分离的项目中我们的认证信息其实是token，而token并不是存储中cookie中，并且需要前端代码去把token设置到请求头中才可以，所以CSRF攻击也就不用担心了，前后端分离的项目，在配置类关闭csrf就能防范csrf攻击 参考：https://www.yuque.com/huanfqc/springsecurity/springsecurity","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"https://blog.ehzyil.xyz/tags/Spring-Security/"}],"author":"ehzyil"},{"title":"Docker的配置与软件安装","slug":"2023/Docker的配置与软件安装","date":"2023-07-05T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/07/05/2023/Docker的配置与软件安装/","link":"","permalink":"https://blog.ehzyil.xyz/2023/07/05/2023/Docker%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/","excerpt":"","text":"1.CentOS安装DockerDocker 分为 CE 和 EE 两大版本。CE 即社区版（免费，支持周期 7 个月），EE 即企业版，强调安全，付费使用，支持周期 24 个月。 Docker CE 分为 stable test 和 nightly 三个更新频道。 官方网站上有各种环境下的 安装指南，这里主要介绍 Docker CE 在 CentOS上的安装。 Docker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10， CentOS 7 满足最低内核的要求，所以我们在CentOS 7安装Docker。 1.1.卸载（可选）如果之前安装过旧版本的Docker，可以使用下面命令卸载： yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce 1.2.安装docker首先需要大家虚拟机联网，安装yum工具 yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 --skip-broken 然后更新本地镜像源： # 设置docker镜像源 yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sed -i 's/download.docker.com/mirrors.aliyun.com\\/docker-ce/g' /etc/yum.repos.d/docker-ce.repo yum makecache fast 然后输入命令： yum install -y docker-ce docker-ce为社区免费版本。稍等片刻，docker即可安装成功。 1.3.启动dockerDocker应用需要用到各种端口，逐一去修改防火墙设置。非常麻烦，因此建议大家直接关闭防火墙！ 启动docker前，一定要关闭防火墙后！！ 启动docker前，一定要关闭防火墙后！！ 启动docker前，一定要关闭防火墙后！！ # 关闭 systemctl stop firewalld # 禁止开机启动防火墙 systemctl disable firewalld 通过命令启动docker： systemctl start docker # 启动docker服务 systemctl stop docker # 停止docker服务 systemctl restart docker # 重启docker服务 然后输入命令，可以查看docker版本： docker -v 如图： 1.4.配置镜像加速docker官方镜像仓库网速较差，我们需要设置国内镜像服务： 参考阿里云的镜像加速文档：https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 针对Docker客户端版本大于 1.10.0 的用户 您可以通过修改daemon配置文件&#x2F;etc&#x2F;docker&#x2F;daemon.json来使用加速器 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF' &#123; \"registry-mirrors\": [\"https://d6kkx5k7.mirror.aliyuncs.com\"] &#125; EOF sudo systemctl daemon-reload sudo systemctl restart docker 2.CentOS7安装DockerCompose2.1.下载Linux下需要通过命令下载： # 安装 curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose 如果下载速度较慢，或者下载失败，可以使用课前资料提供的docker-compose文件： 上传到/usr/local/bin/目录也可以。 2.2.修改文件权限修改文件权限： # 修改权限 chmod +x /usr/local/bin/docker-compose 2.3.Base自动补全命令：# 补全命令 curl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose 如果这里出现错误，需要修改自己的hosts文件： echo \"199.232.68.133 raw.githubusercontent.com\" >> /etc/hosts 3.Docker镜像仓库搭建镜像仓库可以基于Docker官方提供的DockerRegistry来实现。 官网地址：https://hub.docker.com/_/registry 3.1.简化版镜像仓库Docker官方的Docker Registry是一个基础版本的Docker镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。 搭建方式比较简单，命令如下： docker run -d \\ --restart=always \\ --name registry \\ -p 5000:5000 \\ -v registry-data:/var/lib/registry \\ registry 命令中挂载了一个数据卷registry-data到容器内的&#x2F;var&#x2F;lib&#x2F;registry 目录，这是私有镜像库存放数据的目录。 访问http://YourIp:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像 3.2.带有图形化界面版本使用DockerCompose部署带有图象界面的DockerRegistry，命令如下： version: '3.0' services: registry: image: registry volumes: - ./registry-data:/var/lib/registry ui: image: joxit/docker-registry-ui:static ports: - 8080:80 environment: - REGISTRY_TITLE=传智教育私有仓库 - REGISTRY_URL=http://registry:5000 depends_on: - registry 3.3.配置Docker信任地址我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置： # 打开要修改的文件 vi /etc/docker/daemon.json # 添加内容： \"insecure-registries\":[\"http://192.168.150.101:8080\"] # 重加载 systemctl daemon-reload # 重启docker systemctl restart docker 4.dibian安装更新、安装必备软件 apt-get update &amp;&amp; apt-get install -y wget vim 安装 wget -qO- get.docker.com | bash 开机自动启动 systemctl enable docker 卸载 sudo apt-get purge docker-ce docker-ce-cli containerd.io sudo rm -rf &#x2F;var&#x2F;lib&#x2F;docker sudo rm -rf &#x2F;var&#x2F;lib&#x2F;containerd 4.RabbitMQ部署指南4.1.单机部署我们在Centos7虚拟机中使用Docker来安装。 4.1.1.下载镜像方式一：在线拉取 docker pull rabbitmq:3-management 方式二：从本地加载 在课前资料已经提供了镜像包： 上传到虚拟机中后，使用命令加载镜像即可： docker load -i mq.tar 4.1.2.安装MQ执行下面的命令来运行MQ容器： docker run \\ -e RABBITMQ_DEFAULT_USER=root \\ -e RABBITMQ_DEFAULT_PASS=666666 \\ --name mq \\ --hostname mq1 \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3-management 4.2.集群部署接下来，我们看看如何安装RabbitMQ的集群。 4.2.1.集群分类在RabbitMQ的官方文档中，讲述了两种集群的配置方式： 普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。 镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。 我们先来看普通模式集群。 4.2.2.设置网络首先，我们需要让3台MQ互相知道对方的存在。 分别在3台机器中，设置 &#x2F;etc&#x2F;hosts文件，添加如下内容： 192.168.150.101 mq1 192.168.150.102 mq2 192.168.150.103 mq3 并在每台机器上测试，是否可以ping通对方： 5.Docker安装MySQL5.1.上传在将课前资料中的mysql.tar文件上传到虚拟机的&#x2F;tmp目录： 通过load命令加载为镜像： docker load -i mysql.tar 效果： 5.2.创建目录创建两个目录，作为数据库的数据卷： 创建目录&#x2F;tmp&#x2F;mysql&#x2F;data 创建目录&#x2F;tmp&#x2F;mysql&#x2F;conf # 创建目录 mkdir -p /tmp/mysql/data mkdir -p /tmp/mysql/conf 将课前资料提供的my.cnf文件上传到&#x2F;tmp&#x2F;mysql&#x2F;conf，如图： 5.3.运行docker命令运行命令： docker run \\ --name mysql \\ -d \\ -p 3306:3306 \\ --restart unless-stopped \\ -v /tmp/mysql/log:/var/log/mysql \\ -v /tmp/mysql/data:/var/lib/mysql \\ -v /tmp/mysql/conf:/etc/mysql \\ -e MYSQL_ROOT_PASSWORD=666666 \\ -d \\ mysql:5.7.25 参考 docker run \\ --name mysql \\ -d \\ -p 3306:3306 \\ --restart unless-stopped \\ -v /mydata/mysql/log:/var/log/mysql \\ -v /tmp/mysql/conf/my.cnf:/etc/mysql/conf.d/hmy.cnf \\ -v /tmp/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=666666 \\ mysql:5.7 [mysqld] skip-name-resolve character_set_server=utf8 datadir=/var/lib/mysql server-id=1000 bind-address=0.0.0.0 docker exec -it mysql bash mysql -uroot -p 拉取指定版本 sudo docker pull mysql:8.0.23 sudo docker run -p 3306:3306 --name mysql8 \\ --restart unless-stopped \\ -v &#x2F;tmp&#x2F;mysql&#x2F;mysql-files:&#x2F;var&#x2F;lib&#x2F;mysql-files \\ -v &#x2F;tmp&#x2F;mysql&#x2F;conf:&#x2F;etc&#x2F;mysql \\ -v &#x2F;tmp&#x2F;mysql&#x2F;logs:&#x2F;var&#x2F;log&#x2F;mysql \\ -v &#x2F;tmp&#x2F;mysql&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql \\ -e MYSQL_ROOT_PASSWORD&#x3D;root \\ -d mysql:8.0.23 6.安装elasticsearch1.部署单点es1.1.创建网络因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络： docker network create es-net 1.2.加载镜像这里我们采用elasticsearch的7.12.1版本的镜像，这个镜像体积非常大，接近1G。不建议大家自己pull。 课前资料提供了镜像的tar包： 大家将其上传到虚拟机中，然后运行命令加载即可： # 导入数据 docker load -i es.tar 同理还有kibana的tar包也需要这样做。 1.3.运行运行docker命令，部署单点es： docker run -d \\ --name es \\ -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\ -e \"discovery.type=single-node\" \\ -v es-data:/usr/share/elasticsearch/data \\ -v es-plugins:/usr/share/elasticsearch/plugins \\ --privileged \\ --network es-net \\ -p 9200:9200 \\ -p 9300:9300 \\ elasticsearch:7.12.1 命令解释： -e &quot;cluster.name=es-docker-cluster&quot;：设置集群名称 -e &quot;http.host=0.0.0.0&quot;：监听的地址，可以外网访问 -e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;：内存大小 -e &quot;discovery.type=single-node&quot;：非集群模式 -v es-data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定es的数据目录 -v es-logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定es的日志目录 -v es-plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定es的插件目录 --privileged：授予逻辑卷访问权 --network es-net ：加入一个名为es-net的网络中 -p 9200:9200：端口映射配置 在浏览器中输入：http://192.168.150.101:9200 即可看到elasticsearch的响应结果： 2.部署kibanakibana可以给我们提供一个elasticsearch的可视化界面，便于我们学习。 2.1.部署运行docker命令，部署kibana docker run -d \\ --name kibana \\ -e ELASTICSEARCH_HOSTS=http://es:9200 \\ --network=es-net \\ -p 5601:5601 \\ kibana:7.12.1 --network es-net ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中 -e ELASTICSEARCH_HOSTS=http://es:9200&quot;：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch -p 5601:5601：端口映射配置 kibana启动一般比较慢，需要多等待一会，可以通过命令： docker logs -f kibana 查看运行日志，当查看到下面的日志，说明成功： 此时，在浏览器输入地址访问：http://192.168.150.101:5601，即可看到结果 2.2.DevToolskibana中提供了一个DevTools界面： 这个界面中可以编写DSL来操作elasticsearch。并且对DSL语句有自动补全功能。 3.安装IK分词器3.1.在线安装ik插件（较慢）# 进入容器内部 docker exec -it elasticsearch /bin/bash # 在线下载并安装 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip #退出 exit #重启容器 docker restart elasticsearch 3.2.离线安装ik插件（推荐）1）查看数据卷目录 安装插件需要知道elasticsearch的plugins目录位置，而我们用了数据卷挂载，因此需要查看elasticsearch的数据卷目录，通过下面命令查看: docker volume inspect es-plugins 显示结果： [ &#123; \"CreatedAt\": \"2022-05-06T10:06:34+08:00\", \"Driver\": \"local\", \"Labels\": null, \"Mountpoint\": \"/var/lib/docker/volumes/es-plugins/_data\", \"Name\": \"es-plugins\", \"Options\": null, \"Scope\": \"local\" &#125; ] 说明plugins目录被挂载到了：/var/lib/docker/volumes/es-plugins/_data 这个目录中。 2）解压缩分词器安装包 下面我们需要把课前资料中的ik分词器解压缩，重命名为ik 3）上传到es容器的插件数据卷中 也就是/var/lib/docker/volumes/es-plugins/_data ： 4）重启容器 # 4、重启容器 docker restart es # 查看es日志 docker logs -f es 5）测试： IK分词器包含两种模式： ik_smart：最少切分 ik_max_word：最细切分 GET /_analyze &#123; \"analyzer\": \"ik_max_word\", \"text\": \"黑马程序员学习java太棒了\" &#125; 结果： &#123; \"tokens\" : [ &#123; \"token\" : \"黑马\", \"start_offset\" : 0, \"end_offset\" : 2, \"type\" : \"CN_WORD\", \"position\" : 0 &#125;, &#123; \"token\" : \"程序员\", \"start_offset\" : 2, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 1 &#125;, &#123; \"token\" : \"程序\", \"start_offset\" : 2, \"end_offset\" : 4, \"type\" : \"CN_WORD\", \"position\" : 2 &#125;, &#123; \"token\" : \"员\", \"start_offset\" : 4, \"end_offset\" : 5, \"type\" : \"CN_CHAR\", \"position\" : 3 &#125;, &#123; \"token\" : \"学习\", \"start_offset\" : 5, \"end_offset\" : 7, \"type\" : \"CN_WORD\", \"position\" : 4 &#125;, &#123; \"token\" : \"java\", \"start_offset\" : 7, \"end_offset\" : 11, \"type\" : \"ENGLISH\", \"position\" : 5 &#125;, &#123; \"token\" : \"太棒了\", \"start_offset\" : 11, \"end_offset\" : 14, \"type\" : \"CN_WORD\", \"position\" : 6 &#125;, &#123; \"token\" : \"太棒\", \"start_offset\" : 11, \"end_offset\" : 13, \"type\" : \"CN_WORD\", \"position\" : 7 &#125;, &#123; \"token\" : \"了\", \"start_offset\" : 13, \"end_offset\" : 14, \"type\" : \"CN_CHAR\", \"position\" : 8 &#125; ] &#125; 3.3 扩展词词典随着互联网的发展，“造词运动”也越发的频繁。出现了很多新的词语，在原有的词汇列表中并不存在。比如：“奥力给”，“传智播客” 等。 所以我们的词汇也需要不断的更新，IK分词器提供了扩展词汇的功能。 1）打开IK分词器config目录： 2）在IKAnalyzer.cfg.xml配置文件内容添加： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"> &lt;properties> &lt;comment>IK Analyzer 扩展配置&lt;/comment> &lt;!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典--> &lt;entry key=\"ext_dict\">ext.dic&lt;/entry> &lt;/properties> 3）新建一个 ext.dic，可以参考config目录下复制一个配置文件进行修改 传智播客 奥力给 4）重启elasticsearch docker restart es # 查看 日志 docker logs -f elasticsearch 日志中已经成功加载ext.dic配置文件 5）测试效果： GET /_analyze &#123; \"analyzer\": \"ik_max_word\", \"text\": \"传智播客Java就业超过90%,奥力给！\" &#125; 注意当前文件的编码必须是 UTF-8 格式，严禁使用Windows记事本编辑 3.4 停用词词典在互联网项目中，在网络间传输的速度很快，所以很多语言是不允许在网络上传递的，如：关于宗教、政治等敏感词语，那么我们在搜索时也应该忽略当前词汇。 IK分词器也提供了强大的停用词功能，让我们在索引时就直接忽略当前的停用词汇表中的内容。 1）IKAnalyzer.cfg.xml配置文件内容添加： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"> &lt;properties> &lt;comment>IK Analyzer 扩展配置&lt;/comment> &lt;!--用户可以在这里配置自己的扩展字典--> &lt;entry key=\"ext_dict\">ext.dic&lt;/entry> &lt;!--用户可以在这里配置自己的扩展停止词字典 *** 添加停用词词典--> &lt;entry key=\"ext_stopwords\">stopword.dic&lt;/entry> &lt;/properties> 3）在 stopword.dic 添加停用词 习大大 4）重启elasticsearch # 重启服务 docker restart elasticsearch docker restart kibana # 查看 日志 docker logs -f elasticsearch 日志中已经成功加载stopword.dic配置文件 5）测试效果： GET /_analyze &#123; \"analyzer\": \"ik_max_word\", \"text\": \"传智播客Java就业率超过95%,习大大都点赞,奥力给！\" &#125; 注意当前文件的编码必须是 UTF-8 格式，严禁使用Windows记事本编辑 4.部署es集群我们会在单机上利用docker容器运行多个es实例来模拟es集群。不过生产环境推荐大家每一台服务节点仅部署一个es的实例。 部署es集群可以直接使用docker-compose来完成，但这要求你的Linux虚拟机至少有4G的内存空间 4.1.创建es集群首先编写一个docker-compose.ym文件，内容如下： version: '2.2' services: es01: image: elasticsearch:7.12.1 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" volumes: - data01:/usr/share/elasticsearch/data ports: - 9201:9201 networks: - elastic es02: image: elasticsearch:7.12.1 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" volumes: - data02:/usr/share/elasticsearch/data ports: - 9202:9202 networks: - elastic es03: image: elasticsearch:7.12.1 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" volumes: - data03:/usr/share/elasticsearch/data networks: - elastic ports: - 9203:9203 volumes: data01: driver: local data02: driver: local data03: driver: local networks: elastic: driver: bridge es运行需要修改一些linux系统权限，修改/etc/sysctl.conf文件 vi /etc/sysctl.conf 添加下面的内容： vm.max_map_count=262144 然后执行命令，让配置生效： sysctl -p 通过docker-compose启动集群： docker-compose up -d 4.2.集群状态监控kibana可以监控es集群，不过新版本需要依赖es的x-pack 功能，配置比较复杂。 这里推荐使用cerebro来监控es集群状态，官方网址：https://github.com/lmenezes/cerebro 课前资料已经提供了安装包： 解压即可使用，非常方便。 解压好的目录如下： 进入对应的bin目录： 双击其中的cerebro.bat文件即可启动服务。 访问http://localhost:9000 即可进入管理界面： 输入你的elasticsearch的任意节点的地址和端口，点击connect即可： 绿色的条，代表集群处于绿色（健康状态）。 4.3.创建索引库 1）利用kibana的DevTools创建索引库 在DevTools中输入指令： PUT /itcast &#123; \"settings\": &#123; \"number_of_shards\": 3, // 分片数量 \"number_of_replicas\": 1 // 副本数量 &#125;, \"mappings\": &#123; \"properties\": &#123; // mapping映射定义 ... &#125; &#125; &#125; 2）利用cerebro创建索引库 利用cerebro还可以创建索引库： 填写索引库信息： 点击右下角的create按钮： 4.4.查看分片效果回到首页，即可查看索引库分片效果： Docker安装Minio1.Docker 搜索镜像 docker search minio 2.拉取镜像 docker pull minio&#x2F;minio 3.Docker 启动Minio镜像 docker run -d \\ -p 9000:9000 \\ -p 9001:9001 \\ --name minio \\ -v &#x2F;home&#x2F;minio&#x2F;data:&#x2F;data \\ -e &quot;MINIO_ROOT_USER&#x3D;admin&quot; \\ -e &quot;MINIO_ROOT_PASSWORD&#x3D;adminadmin&quot; \\ minio&#x2F;minio:RELEASE.2023-03-24T21-41-23Z server --address &#39;:9000&#39; &#x2F;data --console-address &quot;:9001&quot; 解释： docker run :docker 启动容器命令 -d ：后台启动 -p ：端口映射 –name 为这个容器取一个名字 -e ：设置环境变量 -v :文件挂载 minio&#x2F;minio server &#x2F;data ： minio的启动命令 （minio&#x2F;minio 是镜像名字、 &#x2F;data:数据存储位置） 密码长度要求至少8位 使用docker-compose安装 1、安装 docker-compose 并授权 2、创建编排yml文件 指定控制台路径 --console-address &quot;127.0.0.1:9000&quot;指定API路径 --address &quot;127.0.0.1:9090&quot; version: '3' services: minio: image: minio/minio hostname: \"minio\" ports: - 9000:9000 # api 端口 - 9001:9001 # 控制台端口 environment: MINIO_ACCESS_KEY: admin #管理后台用户名 MINIO_SECRET_KEY: admin123 #管理后台密码，最小8个字符 volumes: - /docker/minio/data:/data #映射当前目录下的data目录至容器内/data目录 - /docker/minio/config:/root/.minio/ #映射配置目录 command: server --console-address ':9001' /data #指定容器中的目录 /data privileged: true restart: always 3、执行流程 在yml文件所在目录执行以下命令，等待执行完毕 created...done docker-compose up -d 4.登录控制台 控制台路径：http://ip:9001/","categories":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ehzyil.xyz/categories/Docker/"}],"tags":[{"name":"软件","slug":"软件","permalink":"https://blog.ehzyil.xyz/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.ehzyil.xyz/tags/Docker/"}],"author":"ehzyil"},{"title":"Nacos安装指南","slug":"2023/Nacos安装指南","date":"2023-07-05T00:00:00.000Z","updated":"2024-01-06T04:54:46.195Z","comments":true,"path":"2023/07/05/2023/Nacos安装指南/","link":"","permalink":"https://blog.ehzyil.xyz/2023/07/05/2023/Nacos%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/","excerpt":"","text":"1.Windows安装开发阶段采用单机安装即可。 1.1.下载安装包在Nacos的GitHub页面，提供有下载链接，可以下载编译好的Nacos服务端或者源代码： GitHub主页：https://github.com/alibaba/nacos GitHub的Release下载页：https://github.com/alibaba/../../../images/nacos/releases 如图： 本课程采用1.4.1.版本的Nacos，课前资料已经准备了安装包： windows版本使用nacos-server-1.4.1.zip包即可。 1.2.解压将这个包解压到任意非中文目录下，如图： 目录说明： bin：启动脚本 conf：配置文件 1.3.端口配置Nacos的默认端口是8848，如果你电脑上的其它进程占用了8848端口，请先尝试关闭该进程。 如果无法关闭占用8848端口的进程，也可以进入nacos的conf目录，修改配置文件中的端口： 修改其中的内容： 1.4.启动启动非常简单，进入bin目录，结构如下： 然后执行命令即可： windows命令： startup.cmd -m standalone 执行后的效果如图： 1.5.访问在浏览器输入地址：http://127.0.0.1:8848/nacos即可： 默认的账号和密码都是nacos，进入后： 2.Linux安装Linux或者Mac安装方式与Windows类似。 2.1.安装JDKNacos依赖于JDK运行，索引Linux上也需要安装JDK才行。 上传jdk安装包： 上传到某个目录，例如：/usr/local/ 然后解压缩： tar -xvf jdk-8u144-linux-x64.tar.gz 然后重命名为java 配置环境变量： export JAVA_HOME=/usr/local/java export PATH=$PATH:$JAVA_HOME/bin 设置环境变量： source /etc/profile 2.2.上传安装包如图： 也可以直接使用课前资料中的tar.gz： 上传到Linux服务器的某个目录，例如/usr/local/src目录下： 2.3.解压命令解压缩安装包： tar -xvf nacos-server-1.4.1.tar.gz 然后删除安装包： rm -rf nacos-server-1.4.1.tar.gz 目录中最终样式： 目录内部： 2.4.端口配置与windows中类似 2.5.启动在..&#x2F;..&#x2F;..&#x2F;images&#x2F;nacos&#x2F;bin目录中，输入命令启动Nacos： sh startup.sh -m standalone 3.Nacos的依赖父工程： &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-alibaba-dependencies&lt;/artifactId> &lt;version>2.2.5.RELEASE&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> 客户端： &lt;!-- nacos客户端依赖包 --> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId> &lt;/dependency>","categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ehzyil.xyz/tags/Docker/"},{"name":"Nacos","slug":"Nacos","permalink":"https://blog.ehzyil.xyz/tags/Nacos/"}],"author":"ehzyil"},{"title":"[转载]Telegram（电报）：新手指南、使用教程及频道推荐","slug":"2023/Telegram：新手指南、使用教程及频道推荐","date":"2019-11-09T00:00:00.000Z","updated":"2022-11-28T00:00:00.000Z","comments":true,"path":"2019/11/09/2023/Telegram：新手指南、使用教程及频道推荐/","link":"","permalink":"https://blog.ehzyil.xyz/2019/11/09/2023/Telegram%EF%BC%9A%E6%96%B0%E6%89%8B%E6%8C%87%E5%8D%97%E3%80%81%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%E5%8F%8A%E9%A2%91%E9%81%93%E6%8E%A8%E8%8D%90/","excerpt":"Telegram 是迄今为止最棒的即时聊天软件，在这个自由新世界，不必自我审查（Freedom of speech）。","text":"Telegram 是迄今为止最棒的即时聊天软件，在这个自由新世界，不必自我审查（Freedom of speech）。 💡 全文有两万七千多字，善用右侧的目录栏和查找功能（Ctrl + F），助你快速定位想要看到的内容。你也可以移步到 Telegram 内阅读此文的 精简版。 🧱 TG 在中国大陆必须 翻墙 后才能使用。不过，学会科学上网，难道不是当代数字公民的必备技能吗？ 📁 tingtalk.me 在 2020-04-04 被墙了，如需在墙内传阅： 前往 GitHub 阅读 下载本文的 PDF 或 可编辑的 Markdown 源文档 ✈️ 电报介绍2013 年 5 月 20 日，斯诺登向《卫报》媒体透露棱镜计划（PRISM）： 我愿意牺牲掉这一切（工作、收入和女朋友）（把真相告诉世人），因为美国政府利用他们正在秘密建造的这一个庞大监视机器摧毁隐私、互联网自由和世界各地人们的基本自由的行为让他良心不安。by Edward Snowden 许多人第一次意识到 Ta 们的数字通信遭到了监视（The year Telegram was born was marked by the Snowden Revelations, when many people realized for the first time their digital communications were being watched.）。 2013 年 8 月 14 日，杜洛夫兄弟（Pavel Durov 和 Nikolai Durov）正式发布了开源（Open Source）的 Telegram（特指客户端）。这个充满理想主义的软件不接受外部投资（不需要向任何股东负责），也不会通过广告盈利，且挣钱永远不会是 Telegram 的终极目标（Making profits will never be an end-goal for Telegram），所以 Telegram 至今没有向第三方披露过一个字节的用户私人数据。Telegram 只会默默地践行一个理念：这个星球上的每个人都享有自由的权利（Everyone on the planet has a right to be free.）。This is the Telegram way： We believe that humans are inherently intelligent and benevolent beings that deserve to be trusted; trusted with freedom to share their thoughts, freedom to communicate privately, freedom to create tools. This philosophy defines everything we do. 我们相信人类天生就是聪明和仁慈的，值得信任的；坚信人类可以自由地分享想法，自由地私下交流，自由地创造工具。 这种哲学定义了我们所做的一切。by Pavel Durov 截止 2022 年 6 月 19 日，Telegram 已有 7 亿月活跃用户。 👍 近乎完美 **高度加密**：使用独有的网络传输协议 MTProto，无惧被黑客攻击。 **没有审查**：不用担心被封号，除非执法调查单位能证明用户是恐怖分子。 没有广告：一个纯碎极致的大众化即时通讯软件（Instant Messaging App）。 **不占内存**：聊天记录保存在云端（Cloud-Based），任何设备，无缝同步，随取随用。 超大群聊：封顶 20 万人，配合各种管理工具（例如限制发言间隔），让大型社群的交流也能井井有条。 **表情贴纸**：采用高清的 矢量 格式，并且支持自制表情包（Custom Sticker Sets）。 👎 瑕不掩瑜欢迎访问 Feature Suggestion Platform，向 Telegram 提交缺陷报告和功能建议（Bugs and Suggestions），一起帮扶 Telegram 做大做强。 🐼 中文搜索体验差毕竟是国外的软件，所以有一些水土不服也是可以理解的。以下方法可以助你更快地找到聊天记录和频道信息。 方法一：手动分词Telegram 的中文搜索是以「词组」为单位的，以标点符号或空格作为词的间隔。 辜鸿铭说过：真正的自由，并不意味着可以随心所欲，而是可以自由地做正确的事情。 在搜索框输入： 真正的自由 并不意味着可以随心所欲 而是可以自由地做正确的事情 都可搜到这条历史信息，因为标点符号充当了分词符。但是这些词未免太长了吧？！也记不住呀。不过别忘了 Telegram 分词规则，我们可以手动添加多余的标点符号（例如井号 ＃）或空格来分词： #辜鸿铭 说过：真正的 #自由，并不意味着可以随心所欲，而是可以自由地做正确的事情。 点击以下词组，或者在搜索框输入： #辜鸿铭 #自由 都可以找到这句话。建议频道主在发布内容的时候，用 # 打上相应的标签，方便订阅者找到想要的信息。 方法二：导出文件嫌手动分词太麻烦了？那就在电脑上导出 HTML 或 JSON 格式的聊天记录，想怎么搜就怎么搜。 不过，已经有人向 Telegram 提交了 改善中文搜索的提案，所以请为这个 Suggestion 投票和鼓气。拜托了。 关联阅读 为什么 Telegram 不能搜索中文讯息 - 翁君牧 Telegram 中文搜索方案探索 - Newlearner 🙃 硬币的另一面在加密通信「庇护」下的土壤，滋生了臭名昭著的网络性犯罪案件：N 号房事件。所幸的是，2020 年 11 月 26 日，主犯赵主彬一审判处监禁 40 年。 以及存在大量的 NSFW 内容、币圈广告和灰色产业链。科技能否向善，在于我们能否约束自己内心的 邪念。 📱 只能用手机号码注册 国外：手机号不用实名制，相对安全。 国内：通过 Google Voice 注册电报，并且可以绕开私聊限制。 而且，添加陌生人到通讯录（Add to contacts），记得每次都要取消勾选 Share my phone number with ***。Telegram 在这个方面上没有记住用户习惯，不应该呀，我去反馈反馈。 另外，如果你的手机号码，被某人保存在 Ta 的手机通讯录，Ta 也开放了通讯录给 Telegram。当你用这个手机号码注册 Telegram 后，Ta 就会第一时间知道你也加入 Telegram 了。所以对隐私有要求，请使用无需实名的虚拟号码或者单独小号来注册。 🗓️ 逃离微信我与 Telegram 的结缘，始于 2016 年春。那时我刚学会了科学上网，并下载了 Telegram 这个 Instant Messaging app。虽然我在电报上找不到朋友和我聊天，但我并没有卸载 Telegram，因为相比输入法和微信，Telegram 提供了丰富的 Emoji 供我选择。如此一来，我在 Android 手机上也能使用最新的 Emoji 点缀朋友圈。 近年来，天下苦微信久矣。 WeChat 掌门人可能是一个无马（码）不欢的 骑兵：每次登录微信电脑版都要扫码时，我的心中都会万马奔腾。 只能发送小于 100 MB 的文件；一次只能发送 9 张图片，而且每次发送都要勾选原图（Telegram 会记住这个用户习惯），下载原图文件名会改变。 占用巨大的存储空间，备份与同步的体验特别差，也不能换成欧盟号码导出用户数据。 注册微信的时候，用户会默认同意 腾讯微信软件许可及服务协议 ，其中在 7.1.2 提到一个霸王条款：「微信帐号的所有权归腾讯公司所有，用户完成申请注册手续后，仅获得微信帐号的使用权，且该使用权仅属于初始申请注册人。……」。 用户免费使用微信（无所有权），微信收集用户的私人数据，贩卖给广告商，这无可厚非。但当用户想要取回 Ta 所创造的内容（数字资产）时，例如导出微信个人数据（朋友圈数据和收藏功能数据等），只好借助欧盟的 GDPR（通用数据保护条例）行使数据可携权。于是我花了 5.26 USD（含税）买了一个比利时的手机号码，微信却猖言道：「由于当地法规限制，WeChat 暂不支援中国大陆用户将绑定的手机号码更换为欧盟手机号码。」 请问是哪条「当地法规」？这不是「法制」，而是「Fuck 制」：强奸一个个没有反抗能力的用户！2020-04-22 原谅我「口吐芬芳」，不懂中国特色。另外，随着言论审查力度的加大，任何「风吹草动」都要「斩草除根」： Cyberspace Administration of China（网信办）会因为我转发一则关于 中华人民共和国宪法修正案 的 Twitter 评论到 24 人的微信同学群，几小时后，请我到最近的派出所「喝茶」，那是我第一次坐警车。 微信上无法发送某些链接（例如纽约时报的文章），也不显示发送失败，让你以为发出去了，其实只对你可见。 微信会秋后算账，删除我之前写的一篇介绍 搜索技巧 的公众号文章，接着 博客 在中国大陆地区被墙，公众号 被永久封号。虽然公众号写了 4 年只有五百多个关注者，但每一个订阅者都来之不易。就这样，我跟读者们都失联了。 经过一系列发生我身上的 屏蔽事件 后，让我意识到中文互联网已经完全沦陷了，于是逃难到 Telegram。经过一段时间的使用后，我彻底成为了 Telegram 的 自来水，见人就夸。然而身边的亲朋好友却不为所动，不愿跟我一起 数字移民 到这个可以安心说话的地方，甘愿做「温室里的花朵」和「笼的传人」，享受表面上的岁月静好。我不会责怪 Ta 们，如果你看过《肖申克的救赎》，就能理解这种「放弃抗争」的心态。 刚入狱的时候，你痛恨周围的高墙，慢慢地，你习惯了生活在其中，最终你发现，自己不得不依靠它而生存。by The Shawshank Redemption 既然说不动认识我的人，但世界那么大，人口那么多，网络世界上一定有一群人，Ta 们和我一样，反感「温室园丁」不透明的做法，不愿做一只数字农场里的电子绵羊，相信「自由价更高」。 我要当一个 踹车轮 的人，为我心中的理想世界投票。因此我熬了几个月，把 Telegram 官网的 FAQ 和 Blog 全部看完了（从 2013 年创立电报至今），结合 Google 搜索引擎旁征博引，整理出这篇可能是中文互联网内容最翔实，排版最精美的《电报指南》，目的就是尽可能地为读者呈现 Telegram 的强大、私密以及友好的用户体验。 在 Durov’s Chat 用蹩脚的中式英语给教程做推广，受到 Pavel 的肯定。 2016 年国庆，我花了一周时间看完了「即刻 app」的所有主题（圈子），写了一篇三千多字文章：《即刻 App - 不再错过你感兴趣的资讯》(图文版 | 文字版）。即刻已经没有复活的可能了（即刻 App 居然在 2020 年 6 月 10 日回来了，但是缺失了话题追踪功能），Telegram 顺势成了新的资讯中心。 人生苦短，逃离微信（Escape from the WeChat）。stay-away-from-wechat 项目收集微信的反人性设计、无理审查行为、侵犯用户隐私、监控聊天记录、试图控制人民生活相关信息，期望用户认识到微信的弊病，倡导用户用脚投票、拒绝使用微信 👎️。欢迎提交 Issues 和 Pull requests 🤖️。 欢迎读者们转移到没有监控和审查的地方 ，一起在这片乐土上过上没羞没臊体面的数字生活。 🌟 注册使用接下来，就正式进入主题，教读者朋友们电报怎么使用。 👇 下载登录请进入 Telegram Apps 的官方下载页面，选择对应的平台，下载，安装，注册。 自由开放的 Telegram 在各平台都有数十种客户端，各有哪些优缺点，又该如何选择呢？请查阅 Telegram 客户端版本比较，但我不推荐使用第三方电报客户端，安全没有保证。 如果你有注册或登录问题 先从 常见登录问题 中寻找方法，无果，联系 Telegram： 途径一：请使用此 表格 与 Telegram 联系 途径二：在 Twitter 上联系 Telegram Login Help 不知何种原因遭到封禁，请写邮件给 &#x72;&#101;&#x63;&#111;&#118;&#x65;&#x72;&#x40;&#x74;&#x65;&#x6c;&#x65;&#103;&#x72;&#x61;&#109;&#46;&#x6f;&#x72;&#103; 用英文写 Email 用 国际电话号码格式 书写被封的手机号码（中国的国家代码为 +86，美国的 +1） 真人值班，大概 24 小内就会被解封。但违反 Telegram 服务条款（Terms of Service），例如乱发广告，是不会被解封的。 参考资料： 记一次成功的 Telegram 账号解封 by @askahh Telegram 官方封禁的账号会受到什么处罚 by @TGgeek 如何在电脑上使用 Telegram for Desktop 打开客户端 点击右上角的 SETTINGS（设置）&gt; Connection type（连接类型）&gt; Use custom proxy（使用自定义代理）&gt; ADD PROXY（添加代理），以 Shadowsocks(R) 为例： SOCKS Hostname: 127.0.0.1 Port: 1080（不同的翻墙客户端，端口略有不同） 使用 Clash 翻墙的用户，可跳过这一步，选择 Use system proxy settings（使用系统代理设置）。 🐼 汉化界面既然已经出来混了（突破网络墙），首选使用英文版的 Telegram（突破语言墙），好像加起来也没几个单词。要是一点英文底子都没有： 点此安装官方简体中文语言包 选择 CHANGE（更改） 即可把界面语言替换为简体中文 截至 2020 年 11 月 01 日，Telegram for Android 翻译已完成 95% 了，但不妨碍日常使用。 🔒 账号设置 支持视频头像（Profile Videos）。 支持登录多个账号。手机端长按另一个账号，不切换账号，也能快速预览消息。Multiple accounts: preview chat list. You can press and hold on another connected account in Settings for a sneak peek of its chats list. 👤 设置用户名你可以在 Setting（设置）里面填写一个 Username（用户名）。设置后，别人能够在不知道你的电话号码的情况下，通过搜索用户名找到你。 用户名可以随时更改或删除（用户名为空）。 用户名不区分大小写（TingTalk &#x3D; tingtalk），但 Telegram 会记住大小写偏好。 侵权 如果一个骗子假装是你，联系 @notoscam。 如何举报假冒的频道或群组：点击右上角的 ... &gt; Report &gt; Fake Account 针对品牌方，用户名被占用怎么办？把你在 Facebook、Twitter 或 Instagram 的用户名（两个平台以上）发给 @username_bot。 如果你看到表情包（sticker sets）、频道（channels）或机器人（bots）侵犯了你的版权，请提交投诉到 &#100;&#x6d;&#x63;&#x61;&#64;&#116;&#101;&#108;&#x65;&#x67;&#114;&#97;&#x6d;&#46;&#x6f;&#114;&#x67; 联系人 添加和删除联系人（Contacts）都是单向操作，双方的通讯录都是独立的（你中有我，我中可能没有你），也没有通知。 （单向）添加联系人之后，加入共同小组后，通讯录好友会排在小组名单前面。如果你想加入一些不想让别人知道的群组，还是用小号吧。 点击左侧菜单栏 &gt; Contacts（联系人）&gt; Find People Nearby（寻找附近的人）。你也可以创建一个基于本地的群聊。 🔓 解除私聊限制自由的土壤吸引了比特币、社工库、NSFW 等灰色产业到电报野蛮生长，因为这些国产老鼠屎对电报的滥用，导致使用中国大陆的手机号码（+86）注册 Telegram 后，私聊 Ta 人时，可能会提示 Sorry, you can only send messages to mutual contacts at the momet.（对不起，你现在只能发送私信给双向联系人。），这表明此账号被判定为 Spam（垃圾信息）账号了。 如何解除私聊限制：在 Telegram 搜索 @SpamBot，点击 START，然后依次点击底部出现的菜单或回复以下话术（仅供参考）： But I can’t message non-contacts. No, I’ll never do any of this. I can’t chat with non-contacts. Accident. 大概半小时之后（有些人要十几天），即可解除禁言。 另外，若用户在 24 小时内访问超过 200 个群组或频道的链接（点击打开就算访问，不需要加入），就会被打入冷宫 24 小时。禁闭期间，无法通过链接访问新的群组或频道（点击链接一直转圈而无法访问）。 ⛑️ 隐私和安全依次点击 Setting（设置）&gt; Privacy and Security（隐私和安全） 🙈 隐藏手机号码Phone number（手机号码）&gt; Who can see my phone number（谁可以看到我的手机号码：Nobody 不允许任何人） 对隐私有要求，或者彻底解除 +86 开头的手机号码的私聊限制，可以把手机号码换绑到非中国区的手机号码，例如 Google Voice： 注册 Google 账号。 在 Google 或淘宝上搜索关键词 Google Voice 或 GV ，购买别人注册下来的号码。 转移到自己的 Google 账号上。 以及 🧨 再次强调：添加陌生人到通讯录（Add to contacts），记得每次都要取消勾选 Share my phone number with ***。 开启 SIM 卡的密码，纵使别人捡到你的手机（卡），没有 PIN 码就不能使用你的手机号码，也就不能收到登录验证码，以此来登录 Telegram。 🎭 匿名转发Forwarded messages: Nobody（引用转发来源：不允许任何人） 启用此设置后，转发你的消息将无法指向（链接）回你的帐户，只会在 From ***（来自***）字段中显示一个无法点击的昵称（非用户名）。而昵称不是唯一的，所以通过这种方式，将没有证据证明某条消息是你发送的（无法溯源）。 📍 隐藏通话 IP 地址Calls &gt; Peer-to-Peer：Nobody Telegram 为了提高语音通话的质量，默认采用端对端连接（Peer-to-Peer）。由于流量没有经过 Telegram 服务器中转，所以会暴露用户的 IP 地址。但是禁用端对端通话后，通话质量会略有下降。 另外，配合使用 Tor（The Onion Router、洋葱路由器）可以隐藏用户真实 IP 地址、避免网络监控及流量分析。 🔐 本机锁定码Passcode Lock 相当于给 Telegram 加上应用锁。这样一来，临时借用你设备的人也看不到你的小秘密。 设置完密码锁之后，可以在下方的自动锁（Auto-lock）设定时长，一旦超过时长未操作，那么 Telegram 将自动上锁。或者在聊天列表页面上主动点击锁头图标，Telegram 就会立即锁定应用，新消息通知将不包括文本或发件人姓名。再次进入应用时，要求输入锁定码。 在 Android 客户端上，还可以关闭「在任务切换页面显示内容」（Show App Content in Task Switcher），同时在 Telegram 内也无法截屏。 密码锁只在当前设备可用，不会同步到云端或其他设备，所以在不同的设备上可以设置不同的密码锁。如果忘记，只能重装 App，而且重新登录之后，需要重新设置新的密码锁，私密聊天（Secret Chat）也不会同步回来。 ✌️ 两步验证Two-step verification（两步验证：添加密码提示和 ❗️ 安全邮箱 ❗️） 以后登录时，输入验证码后，还要输入密码。 安全密码：请勿使用纯数字密码，可使用开源的 KeePass 生成高强度密码。 电子邮箱：忘记密码，可以通过 Email 找回密码。尽量选择国外邮箱服务，例如 Gmail 或者 Outlook 💥 删除账户Delete my account if away for 1 month/3 months/6 months/1 year （删除我的帐户若离线时间达 1 个月 &#x2F; 3 个月 &#x2F; 6 个月 &#x2F; 1 年） 自动删除：以上就是电报自带账户自毁机制（Account Self-Destruction） 主动删除：不想使用此账号，可 永久删除账户（Delete Account） 为什么要给账户设置自毁机制 Telegram 作为一个免费的非商业软件，没有任何收入来源，为了节约服务器的存储空间，Telegram 会自动删除长时间不上线的用户。再说了，Telegram 也不需要你的私人数据。 如果不慎丢失了 SIM（手机卡），此前未开启 SIM 卡的 PIN 码（强烈建议开启）和 Telegram 账户的两步验证，新的「主人」就能把你的 Telegram 账号占为己有。但是假如你设置了 1 个月不上线就销户，坏人在第 32 天捡到你的手机，不过此时你的 Telegram 账号已经不存在了。 🛡️ 其它隐私设置 使用没有个人特征的头像（记得在个人资料里删除历史头像）、昵称和用户名，确保硅基身份不会和碳基身份产生关联。 不使用 Touch ID 或 Face ID 解锁你的手机，只以密码锁屏（数字 + 字母），以免被「执法人员」控制身体后强行解锁。 💬 对话界面Telegram 有一个非常人性化的特性：记忆浏览进度，打开对话界面会自动跳转到未读消息 Unread Messages（The app restores your previous scroll position when you switch back to a chat）或者上次的未读位置。纵使重新安装 Telegram，没看完的消息，状态依旧是未读的。 ✏️ 消息发送前打上句号之前，检查一遍内容是否有误，虽然 Telegram 支持无限期的（撤回）修改。 ↩️ 引用消息手机 左滑（Swipe left）Reply 消息。 长按，在弹出的界面中选择 Reply。 电脑 左键双击消息的空白处，例如在时间附近。 左键单击对话框的右上角的 Reply。 右击消息，在弹出的菜单中选择 Reply。 点击引用的消息，就会向上滚动到原始消息（If you tap on the quote, the app scrolls up to the original message）。 假设从 Unread Messages 开始浏览动态（已发布 120 条 Post），遇到新消息引用了旧消息，例如庭说频道的第 100 条消息 https://t.me/tingtalk/100 引用第 56 条消息 https://t.me/tingtalk/56，点击引用的消息，即可定位到第 56 条消息。如何回到第 100 条消息，点击右下角的 🔽 就会回到第 100 条消息，而不是回到最新的消息（shows an arrow button to go back to the previous location. This makes navigating conversations in groups easy even if you’ve been away for a while）。这是一个非常动人的细节，深深地被 Telegram 折服。 电脑右击 &#x2F; 手机点按被引用消息（右下角有个 ↶），在弹出的菜单里选择 View * Reply，就能展开所有对此话题的讨论（回复）。 📝 文本格式化学会插入超文本链接，避免冗长的 URL 霸屏（简短的网址例外），是一种网络美德。 Markdown 语法官方客户端只支持以下Markdown 语法： 加粗（前后加入两个星号）：**bold** 删除线（前后加入两个波浪号）：~~strikethrough~~ 等宽字体（前后加入一个重音符）：`monospace` 斜体（前后加入两个下划线）：__italic__（原生 Markdown 语法是前后一个星号） 不支持使用 Markdown 语法 Create link，虽然可以通过快捷键 Ctrl + K 插入超链接，但略显麻烦。如果你是 Windows 10 用户和 Markdown 爱好者，我想到了一个优雅的写作方法。 @sudo_radio 提供信息：Telegram X for Android 也支持超链接语法。 公开版：最后一次更新是 2020 年 5 月 15 日 测试版：申请入口 | APKMirror 准备工作 下载 Unigram（下文 有安装教程） 下载 Typora 或其它 Markdown 编辑器 添加浏览器插件 油猴，并安装这个 脚本：快速复制 Markdown 格式（[标题](网址)）的超链接到剪贴板 写作流程 打开 Typora，开始写作 通过脚本快速插入超链接 写好后复制 Markdown 源代码，打开 Unigram 并粘贴 打上一些 #标签（Hashtags）给消息分类，方便读者检索 点击发送，Markdown 语法即可被渲染，包括超链接 这样写长文，一气呵成，Awesome！ 得益于 Telegram 账号可以登录很多个设备，用完 Unigram 和 Telegram X for Android 后，可切换回官方客户端。 关联阅读：文案风格指南 by 庭说 Desktop（桌面电脑端） 在编辑区输入文本。 左键选择想要格式化的文本。 右击 &gt; Formatting（格式选项）。 Formatting Shortcut for Windows Bold（加粗 ） Ctrl + B Italic（斜体） Ctrl + I Underline（下划线） Ctrl + U Strikethrough（删除线） Ctrl + Shift + X Monospace（等宽字体） Ctrl + Shift + M Create link（超链接） Ctrl + K Plain text（纯文本） Ctrl + Shift + N 重磅推荐 Ctrl + K！简单几步，让排版清清爽爽。 Android（安卓） 在编辑区输入文本。 长按选择想要格式化的文本。 原生 Android 系统会直接弹出格式化选项；魔改安卓系统（例如 MIUI）需要轻触界面右上角的三个点（在顶栏右侧，大概在通知栏电量 🔋 的下方。非常刁钻的一个位置），才能看到文本格式化选项。 iOS（iPhone &amp; iPad） 在编辑区输入文本。 长按选择想要格式化的文本，会弹出一些文字操作的选项。 轻触 BIU（或许藏在 ▶️ 后面），即可看到文本格式化选项。 如果觉得以上格式化文本的方法太麻烦，打乱了输入节奏，可在任意聊天框输入 @bold，接着使用 Markdown 编辑消息（最多输入 256 字符），最后选择 Custom markdown。 #️⃣ 主题标签任何以 # 开头的词组，以标点符号或空格结尾的词组（hashtags）都可以被点击搜索，也相当于用标签给消息分组。 康德说过：#自由 不是让你想做什么就做什么，自由是教你不想做什么，就可以不做什么。 消息发出后，#自由 就会变成一个可点击搜索的状态。 🌅 发送原图先选择想要发送的图片（不止于 9 张）： Android：点击弹出窗口右上角的三个点，Send without compression iOS、macOS 和 Windows：Send as a file 请注意： 原图不会压缩图片，但是会暴露文件名、隐藏的 GPS 信息和拍摄信息，慎重发送。 Telegram 会记住你的操作习惯，下次发送图片时不必再次勾选原图选项。 🎬 发送视频支持时间戳（Timestamp）：发送本地视频或 YouTube 视频时，在 Add a caption（添加标题）里标记你最喜欢的时刻（mark your favorite moments），例如： 建议直接跳到 05:06 开始欣赏，有惊喜。 05:06 会自动高亮显示，点击 05:06，视频就会从第 5 分 6 秒播放。其中 05:06 必填项，提示的话可以选填。 引用回复本地视频或 YouTube 视频也支持加入时间戳（Timestamps in replies and captions open videos and YouTube links to that exact moment.）。 你发现了吗？YouTube 和哔哩哔哩的评论区也是支持这种时间戳。 不支持时间戳的软件和网页，怎么办 YouTube：https://www.youtube.com/watch?v=SyM3jMFjess&amp;t=05m06s 右键点击进度条 在弹出的菜单中选择 复制当前时间的视频网址 哔哩哔哩：https://www.bilibili.com/video/av55857100?t=14m15s 不支持复制当前时间的视频网址，需要手动填写 参数说明 ?t= &#x2F; &amp;t= 时间 time h 时 hour m 分 minute s 秒 second 发送视频时，可选择压缩等级。Change the resolution of a video from the editor’s quality slider. 内置视频播放器（in-app media player）：直接在 app 内观看 YouTube 或 Vimeo 视频，不必跳转到浏览器或者相应的视频 app。操作逻辑与国外视频 App 保持一致：双击左侧快退，双击右侧快进。 制作 GIF 动图在发送视频时，点击视频打开编辑窗口，使其静音（tap the mute audio button），新的 GIF 就诞生了，还会自动保存在最近使用的 GIF 里（recent GIFs tab）。 📡 消息发送时手机上长按（电脑上右击）消息发送键： Send without sound（静音发送）：纵使对方在睡觉，你的 urgent idea 也不会搅人春梦，简直就是为健忘的人而设计。 Scheduled Message（定时发送） 发送日程消息时，对方是不知道你使用了定时发送。 在 Saved Messages（我的收藏）也可以发送定时消息作为提醒（Set a reminder）。 Send when * comes online（当对方上线时发送）：这样就可以排在对方聊天列表的前面（Put you right at the top of their chat list.）。此功能需要对方在隐私设置里开启展示最后上线时间（This option only appears for users who share their Last Seen status with you, and vice versa.） 接收者可屏蔽联系人 &#x2F; 群组 &#x2F; 频道的消息通知（Mute Notifications）： 1 个小时 4 个小时 18 个小时 3 天 永久静音 🔙 消息发送后点击消息，选择 Pin，即可在频道、群组或私聊界面中置顶多个消息（Multiple Pinned Messages）。在群组中置顶消息时，可强制通知全员（notify all members），即使成员的群组已经设置为静音。 ✔️ 消息状态消息的读取状态（回执）分为两种 One check（✔️）：发送成功。在微信，有些消息没发送出去，只对你可见，也不会有发送失败的感叹号 ❗。这是对用户赤裸裸的欺骗 。 Two checks（✔️✔️）：消息已阅。瞥见状态栏弹出来的消息，不会产生已读标记。因此，一直显示单勾，不代表对方没看到信息。 一个偷看消息的小技巧：在对话列表，长按头像可预览消息，但消息状态不会变为已读。（Pull up a preview of messages – without making messages as read. ） ✏️ 消息更正在 Telegram，说出去的话不会像泼出去的水收不回来，在 48 小时内（频道是无限期修改），你都可以重新编辑（Edit your messages after posting），包括文字、图片和视频（Edit sent media to re-crop, re-decorate or completely replace photos and videos.），所以： 文字出现 typos，不用删除，多久之前发的消息都能随时更正（Edit）。 图片忘记打马赛克，但因为有图片说明（配文），懒得撤回重输，可以当场抹除敏感信息，当场换图片（Replace Media）。 视频发错了，善后方式与图片同理。 图片换视频，视频换图片，Why not? 如何替换图片或视频？长按或右击消息，选择 Edit： 通用法：点击笔头图标 ✏️（或 Replace file&#x2F;photo），弹出资源窗口，选择正确的图片和视频即可替换。 桌面端：复制正确的图片和视频，回到 Telegram，粘贴即可替换。 并且支持直接标记别人发来的图片，修改完再发出去，无需保存在本地图库。Instantly edit and send back media you receive to add notations or decorations without saving it to your gallery. 在电脑端，把鼠标放在 edited 上，会显示最后修改消息的时间。 👇 长按消息 消息可以无限期撤回（Delete Messages）：删除信息时，勾选 Also delete for ***，聊天记录就可以双向删除，通话记录也支持这个特性（Call history can also be deleted for all sides at any time）。电报服务器更不会存储被删除的聊天记录和通话记录，因此数据将彻底永远消失。 选择部分消息（Select Parts of Messages）：长按 2 次消息，可选择部分文字，而不是复制全文（Copy Selected Text）。 长按网址或长串数字可以选择打开（Open）或者复制（Copy）。 转发消息时，长按联系人 &#x2F; 群组 &#x2F; 频道可多选。 🗣 朗读消息Announce Messages 目前由 iOS 用户独占。你可以让 Siri 在你的耳机里大声读出你收到的信息，即使是在洗碗的时候也可以保持聊天的最新状态。 开启路径：iOS Settings &gt; Notifications &gt; Announce Messages。 ⏳ 自动删除 自动删除只适用于定时器设置后发送的消息，以前的消息将保留在聊天记录中。 倒计时在消息发送时开始计时；而秘密聊天是阅后即焚，是从已读后开始计时。 🗣️ 语音消息 支持 2 倍速播放（2X playback）。 支持滑动进度条。（Slide forward and back on voice messages to skip ahead or repeat something you missed.） 记忆播放位置：超过 20 分钟的音频文件（2021 年 3 月 18 日取消此限制），Telegram 会帮你记住最后的播放位置，以便中断后再次收听（Telegram apps will remember your last position when resuming playback of audio files longer than 20 minutes.）。 此外，在 Telegram 上进行语音通话（打电话），需要在翻墙服务端&#x2F;客户端开启 UDP 转发。 📲 视频通话发起视频通话和音频通话后，如果屏幕上的 4 个 Emoji 一致，表示此连接已采用端到端加密，100% 安全。 Video Calls: All voice and video calls are protected with end-to-end encryption. To confirm your connection, compare the four emoji shown on screen. If they match with your partner’s, your call is 100% secure. 🙈 生动表情Emoji（绘文字）按关键字搜索表情（Search emoji by keyword）：在消息框输入关键词，就会弹出相关的 Emoji。 能触发 Emoji 的英文关键词合集 能触发 Emoji 的简体中文关键词合集 部分 Emoji 支持动态播放（Animated Emoji）在任意聊天窗口发送 1 个 非礼勿视猿 🙈（See-No-Evil Monkey），再动 Ta 试试，可爱吧！查看更多被 Telegram 赋予「生命」的动态 Emoji，请参阅 Telegram Animated Emoji List。 以下表情符号可以作为打赌小游戏（Emoji Game） 发送单个 触发效果 🎲 掷骰子 dice 🎯 扔飞镖 darts 🏀 投篮 basketball ⚽ 射门 football 🎳 保龄球 bowling 🎰 老虎机 jackpot &#x2F; slot machine 如何在句中（mid-message）快捷添加 Emoji？语法是 :（英文半角冒号） + 关键词。例如输入 I am :happy，就会弹出开心相关的 Emoji，这样就不用从 Emoji 面板挑选 Emoji 了。 Stickers（表情包） 截至 2021 年 1 月 13 日，Telegram 上已有 20,000+ 免费的高清表情包。 在聊天窗口输入 @sticker + Emoji，可以检索所有与 Emoji 相关表情包，例如 @sticker 👍。我非常喜欢这个表情包建议功能（Suggest stickers by emoji），经常能找到一些很有创意高清表情包，给聊天体验增色不少。 在哪里找表情包 官方： 打开 Telegram 的一个对话界面，输入框选择 Sticker（旁边是选择 Emoji 和 GIF） 往下拉，即可在顶部看到 Search sticker sets（只支持用英文关键词搜索） 网站： Stickers Cloud tlgrm：只支持用英文关键词搜索 群组：Stickers Cloud 频道：Trending Stickers 📤 如何导出电报上的表情包 选择一个 Sticker to GIF Converter，例如 @tgstogifbot 或 @Sticker2GIFBot（后一个 Bot 可下载整套表情包） 发送 Stickers，Bots 就会把 Telegram 上 tgs 格式的表情包转换为 gif 格式 🗜️ 在限制多多的微信 App 上，小于 1 MB 的 GIF 图片才会自动播放。如何压缩： 打开 图贴式（网站），选择 GIF 压缩 宽度设置为 240，压缩质量 70（默认） 选择或拖拽一个或多个 GIF 到压缩窗口，开始压缩 压缩完成后，（推荐使用 IDM）打包下载 此时某些表情包可能大于 1 MB，需要再压一次： 方法一：修改 图贴式 的压缩质量等级（压得太狠会失真） 方法二：使用 docsmall（网站）或者 图压（软件）二次压缩 为什么不用 Photoshop 压缩 GIF？因为会产生毛糙的白边。 两外，推荐一个可以批量修改图片尺寸的网站：iLoveIMG 📊 投票功能只支持在群组和频道中发起，因为 they feel lonely in one-on-one chats. 发起人 支持：匿名投票（Anonymous Voting）、多选（Multiple Answers）、答题模式（ Quiz Mode）。 不支持：修改发出的 Poll。 投票者 &#x2F; 答题者 不满意长按或右击投票（Poll）可以撤回投票（Retract vote）。 缺点 Telegram 内置投票可被任意用户转发至其他对话内（如群组）进行投票，这对于公开性的投票来说是增加统计数据量的好方式，但该特性对于有私密&#x2F;非公开需求的投票来说实为不利。（截止 2021 年 5 月 28 日 by TGgeek） 改善方法：通过 @vote 创建投票。 📖 通用技巧🌐 互联开放公开（Public）的频道或群组，是可以被搜索引擎抓取的（The contents of public channels can be seen on the Web without a Telegram account and are indexed by search engines.），并且不注册 Telegram 账号也看到公开频道或群组中的内容，方法就是在 Public link（公开链接）中加一个 s，例如在浏览器的地址栏输入 t.me&#x2F;s&#x2F;tingtalk，即可查阅庭说频道的所有内容。 一个用户最多可创建 10 个公开用户名（public usernames），包括公开的频道和群组。 🔍 全局搜索Search Filters: To quickly find a specific message or media item, search filters allow users to refine results by keyword, source, media type and time period – all at once. 这里指电报内的全局搜索。 隐藏技巧：如何按日期搜索？ 打开在 Telegram 移动端首页 点击搜索框 输入日期，即可按照日期筛选历史消息 2021：2021 年 01.2021 &#x2F; Jan 2021：2021 年 1 月 01.13.2021：2021 年 1 月 13 日 📅 创建日期在任意对话窗口（例如 Saved Messages）输入 https://t.me &#x2F; ID &#x2F; 1，例如 https://t.me/tingtalk/1 或者在浏览器的地址栏输入 https://t.me &#x2F; s &#x2F; ID &#x2F; 1，例如 https://t.me/s/tingtalk/1 就会跳转到该群组或频道（未删除的）第一条消息，在其上方，可以看到创建日期（Channel created） ☁️ 多端同步 Telegram 可以在多个设备上同时使用。以下是我的设备列表： 2 台 Windows 电脑（开机自启） 1 部 Android 手机 1 部 iPhone 手机 1 个 网页端 …… 并且具备以下优势： 登录过的设备，下次登录时，不必再次扫描二维码或者输入密码。 云草稿（Cloud drafts）：除了消息可在各个平台同步之外，连未完成编辑的消息（草稿）都可以跨设备同步。Now you can start typing on your phone, then continue on your computer – right where you left off. 但是长文本还是不要放在草稿箱了，就怕 Bug 爬上来。如果草稿丢失，在桌面端按 Ctrl + Z 试试。 与 WhatsApp 不同的是，手机下线 Telegram 后，其他设备的 Telegram 并不会退出。 允许传送最大 2000 MiB 的文件，简直就是绝佳的「文件传输助手」： 把 Saved Messages（收藏夹）当作是 GTD 中 Inbox。并且每条保存的消息都有一个 ▶️ 按钮，可以将你带到最初发布消息的位置。 建立多个私人频道（无数量限制），分类存放你的信息和资讯。你甚至可以在 Telegram 上传本地音乐或者录音到自己的频道，建立自己的云端音乐播放库和播客（Podcast）。Create playlists by sending multiple songs at the same time. 🖥️ 电脑版技巧Windows 的 Ctrl 等于 macOS 中 Command ⌘。 快速多选：在对话界面的空白位置，按住鼠标左键不放，然后推拽多选信息，接着即可转发或者删除。 链接直达：按住 Ctrl 再点击 URL，直接打开链接，不必弹窗确认（Open this link? CANCEL &#x2F; OPEN）。 缩放图片：按住 Ctrl 再旋转鼠标的滚轮，即可放大或缩小图片。 快捷回复：直接在桌面右下角的消息弹窗里回复消息。 快捷引用：左键双击消息的空白处，例如在时间附近，即可引用消息。 键盘快捷键聊天 Chats 动作 Action 快捷键 Shortcut 加速浏览聊天记录Speed up in-Chat Navigation Shift + Scroll 切换到下一个会话Move to the Chat Below Ctrl + TabCtrl + PageDownAlt + ↓ 切换到上一个会话Move to the Chat Above Ctrl + Shift + TabCtrl + PageUpAlt + ↑ 发送文件Send File Ctrl + O 退出 Exit返回 Go Back取消当前操作 Cancel Current Action Esc 消息 Messages 动作 Action 快捷键 Shortcut 引用消息Reply to a Message Ctrl + ↑Ctrl + ↓按住 Ctrl 不放，通过 ↑ &#x2F; ↓ 选择需要引用的消息 取消引用Cancel Reply Ctrl + ↓Esc 编辑最后发送的消息Edit Last Message Sent ↑ 编辑媒体（例如替换图片）Edit Media Ctrl + E 放大或缩小图片&#x2F;视频Zoom Image&#x2F;Video In&#x2F;Out Ctrl + + &#x2F; -（在数字小键盘）Ctrl + 鼠标滚轮 通过内联消息打开 Bot 配置文件Open Bot Profile via Inline Message Ctrl + 点击内联机器人的名字 搜索选定的会话的聊天记录Search Selected Chat Ctrl + F 分组 Folders 动作 Action 快捷键 Shortcut 切换到收藏夹（Save Messages） Ctrl + 0 直接切换到对应的分组Jump directly to the folder Ctrl + 1Ctrl + 2Ctrl + 3Ctrl + 4Ctrl + 5Ctrl + 6Ctrl + 7 切换到最后的分组Jump to the last folder Ctrl + 8 切换到归档对话（Archived Chats） Ctrl + 9 窗口相关 Window Related 动作 Action 快捷键 Shortcut 最小化到系统托盘Minimize to System Tray Ctrl + W 退出电报Quit Telegram Ctrl + Q 锁定电报Lock Telegram Ctrl + L 最小化到任务栏Minimize Telegram Ctrl + M 选取文字 Selected Text 动作 Action 快捷键 Shortcut 加粗Bold Ctrl + B 斜体Italic Ctrl + I 插入文本链接Create Link Ctrl + K 下划线Underline Ctrl + U 等宽字体Monospace Ctrl + Shift + M 纯文本（清除所有格式）Null &#x2F; Plain Text Ctrl + Shift + N 删除线Strikethrough Ctrl + Shift + X 鼠标快捷键 动作 Action 鼠标快捷键 Shortcut 引用Reply 左键双击消息Double click the message 多选消息Select Messages 在消息外拖拽多选Drag outside the messages 显示消息具体发送时间和最后更正时间Info about Messages 鼠标悬停在时间戳上Hover the timestamp 投票总数Amount of Votes in Poll 鼠标悬停在百分比上Hover percentage 转发消息Forward a message to a chat 拖拽消息到会话列表Drag the message to a chat in the list 静音发送Send Message Silently Send定时发送Schedule Message 右击发送键Right Click on Send Button 查看后续更新的 Keyboard&#x2F;Mouse shortcuts for Telegram Desktop，请访问 UseTheKeyboard 或 telegramdesktop&#x2F;tdesktop Wiki。 UnigramUnigram 是专为 Windows 10 开发的 Telegram 第三方开源客户端（基于 TDLib），并且被 官方认可。作为 UWP 应用，基本上 Mobile app 上有的功能，Unigram 都不落下。 相比官方的 Desktop 版： 支持 Instant View 支持端到端加密的私密聊天（ Secret Chats） 支持查看阅后即焚的照片和视频（Self-destruct） 在单独的窗口中打开聊天记录（Shift + 单击） 聊天输入框下可显示格式化文本菜单（Show formatting） 在输入框粘贴 Markdown 源码，发送后即可渲染，包括超链接（Ctrl + K） 频道主右击发送的动态，可查看统计信息（Statiatics）：此条信息的分享次数以及被分享到哪些公开频道 缺点： 不能最小化到系统托盘，必须常驻在任务栏 安装 Windows + S 调出搜索框，输入 区域 把 国际或地区 换到其它地方，例如 香港特别行政区 Windows + S 调出搜索框，输入 Store，打开 Microsoft Store，搜索 Unigram 并安装 把 国际或地区 改回 中国 使用以 Clash .NET 为例，如何设置网络代理，让 Unigram 连上国际互联网： 右击桌面任务栏托盘上的 Clash .NET，选择 UWP回环 &gt; 启动助手 在弹出的窗口确定两次（如果有） 勾选 Unigram，保存（Save Changes） 官方频道：Unigram News 内测频道：Unigram Mirror（无需通过 Microsoft Sotre 安装） 官方群组：Unigram Insiders 相关新闻：Unigram 现版本（v7.8.6586.0）会未加密保存媒体文件 - by TGgeek 关联阅读： Unigram 的安装及使用 - 404 Unigram 安装及使用教程 – Telegraph by TGgeek 📁 对话列表长按某个对话的左侧（头像）即可预览消息（Preview media）。 长按某个对话的右侧： 删除对话（Delete chat）：勾选 Also delete for ***，即可同时删除双方所有的聊天记录。 不用经过对方同意。如果你的朋友遭遇不测，你可以及时清除消息来保护自己和对方。 反之，需要保留证据时，请及时截图或在桌面端导出聊天记录。 归档对话（Archive chat）：把不常用的群组和频道放到归档文件夹中，精简对话列表，Everything in its place。 在移动端的对话列表里，从顶部往下拉，即可看到「已归档对话」，长按可标记全部归档对话为已读状态。 当未设置静音的存档对话收到通知时，它将从归档列表中返回到聊天列表中。 更改置顶对话的顺序 手机：长按某个对话的右侧，即可出现顺序操纵杆。 电脑：左键长按对话并拖动。 📂对话分组从 Settings &gt; Folders 进入 分组管理 设置： 最多创建 10 个分组。 每个分组都能置顶无数个对话（Unlimited Pins）。 默认分组 Unread：未读消息组，快速消灭未读红点。 Personal：个人私聊组。 Creat New Folder（新建分组）时有以下筛选条件可选： Contacts（联系人） Non Contacts（非联系人） Groups（群组） Channels（频道） Bots（机器人） …… 操作技巧 在对话列表界面，长按或者右击分组名可进行 Reorder（排序）、Edit（重命名）、Delete（删除）和 Mark ad read（标记为已读）等操作。 目前只支持在电脑客户端中设置分组图标（Folder Icons）。 🔴 关闭通知 Settings（设置）&gt; Notifications and Sounds（通知和声音）。 Badge Counter（未读消息数量显示）：取消 Include Muted Chats（包含已关闭通知的对话） 如此设置，只有未静音的对话（私聊 &#x2F; 群组 &#x2F; 频道）来消息了，才会收到「小红点」。 🧹 清除缓存此举只是暂时释放存储空间，因为媒体文件都会保留在 Telegram 云端，若需要可以再次下载，例如翻看历史消息的时候。 Settings（设置） Data and Storage（数据和存储） Storage Usage（存储使用情况） Clear Telegram Cache（清理缓存） 📲 导入数据每个人都可以通过 WhatsApp、 Line 和 KakaoTalk 等应用程序将聊天记录（包括视频和文档）迁移到 Telegram 上。以 WhatsApp 为例： iOS 打开 WhatsApp 的联系方式或群组信息页面（Contact Info or Group Info） 点击导出聊天（Export Chat） 然后在共享（Share）菜单中选择 Telegram Android 打开 WhatsApp 聊天 点击更多（More） &gt; 导出聊天（Export Chat） 然后在分享菜单中选择 Telegram 借助 Telegram 的云存档功能，再也不用担心聊天记录丢失的问题。 🗃️ 导出数据⚠️此功能需在 Telegram 电脑版 上运行。 The original meaning of the paper plane on the Telegram logo means “freedom”. For us, freedom of choice and data portability are paramount. People should be in complete control over their own data – and their own lives. Telegram 标志上的纸飞机的原意是「自由」。对我们来说，选择自由和数据便携性是最重要的。人们应该完全控制自己的数据——以及自己的生活。by Pavel Durov 聊天历史会被存储在 Telegram 云端，但是也可以导出部分（或全部）聊天记录到电脑上离线回味，而且排版还是原来的样子。 打开 Telegram Desktop 选择某个对话 点击对话界面右上角的设置（三个点 …） 导出聊天记录（Export chat history） 你也可以导出 Telegram 的所有数据。对，是所有，不仅仅是聊天记录，还有账号信息： 打开 Telegram Desktop 依次点击 Settings &gt; Advanced &gt; Export Telegram data 选择要导出的数据类型 🔞 解锁敏感内容如何在 iOS 原生客户端查看敏感内容，例如 NSFW： 登录 Telegram Web（网页版）或者下载并登录 Telegram Desktop（客户端）。 Settings（设置）&gt; Privacy and Security（隐私和安全）。 Sensitive content（敏感内容） 客户端：打开 Disable filtering（关闭过滤） 网页版：打开 Show Sensitive Content 操作完成后，重新启动 iOS 原生客户端，即可 Display sensitive media in public channels on all your Telegram devices（允许在您所有登录 Telegram 的设备上显示公共频道内的敏感内容）。 📣 频道推荐Channels 相当于公告板，是向大众传播信息的完美工具（The perfect tool for broadcasting messages to the masses），类似微信公众号，但比公众号好用得多。 通过 Post Widget，你可以将频道或公共群组的任何消息嵌入到任何地方。You can embed messages from public groups and channels anywhere. 📢 频道主 Hashtags：多用 # （标签）给消息分类，方便快速检索（点击高亮的关键词，或者在搜索框手动输入 # + 关键词），然后把标签放在置顶信息里，或频道介绍里。 频道分析（Channel Stats）📈：订阅人数超过 50 人（之前是 1,000 人）的频道会有详细的统计数据分析报告（Statistics）。 频道可以有无数个订阅者，但是创建者只能邀请前 200 个成员到你的频道。 重新编辑（Edit）消息，多久之前发的 Post 都可以。 支持删除消息通知，减少无关紧要的动态对订阅者的干扰。出现以下通知后，可立即长按删除： 更换频道置顶的消息通知 *** pinned *** 更换频道头像的消息通知 Channel photo updated 更改频道名字的消息通知 Channel name was changed to *** 如何让你的频道或群组被更多同好知道？ 打开 @zh_secretary_bot 发送频道 ID，例如 @tingtalk 编辑简介和标签后，即可提交收录到 @zh_secretary 人工审核通过后，就会在开源非盈利的 SE-索引公告板 被更多同好看到啦 相似的索引机器人还有 @PolarisseekBot。 2020 年 9 月 30 开始，电报频道原生支持评论功能（Channel Comments） 首先要 在频道的设置里绑定一个群聊（Group），频道中的每条新帖子（new post）都会自动转发到该群组并被置顶（Pin）。 频道发送消息后，有两个评论入口： 频道：点击 Leave a comment 即可进入留言板（无需加入讨论组）。 群组： 第一层评论：引用（Reply）回复对应的频道消息。 第二层评论：接龙引用第一层评论。 第 N 层评论：以此类推。 通过 @LikeComBot 给频道的消息下增加 Emoji 按钮，例如 👍、👎、😐。 🔔 订阅者 Subscriber Privacy：关注者无法得知频道创建者（creator）是谁，也无法得知谁关注了这个频道，但是频道主知道谁关注了频道。 若用户在 24 小时内访问超过 200 个群组或频道的链接（点击打开就算访问，不需要加入），就会被打入冷宫 24 小时。禁闭期间，无法通过链接访问新的群组或频道（点击链接一直转圈而无法访问）。 频道&#x2F;超级群组的关注上限是 500 个（具体数字未得到官方的求证），但是限制是一定存在的，因为限制提示语出现在官方翻译页面：抱歉，您已加入太多频道&#x2F;超级群组。请先退出一些频道&#x2F;超级群组后再加入。（Sorry, you have joined too many channels and supergroups. Please leave some before joining this one.） 去哪里找钟意的频道（Channel），群组（Group）和机器人（Bot）呢？ ☝️ 在 Telegram 内直接搜索关键词，但中文搜索识别较差。例如，「庭说」的频道是 https://t.me/tingtalk 搜索英文 tingtalk（t.me/ 后面的字符就是 ID），可以准确识别。 搜索中文 庭说，可能无法识别。 ✌️ 在 Google 上搜索，配合一些 Google 搜索技巧： 搜索结果较少：关键词 + site:t.me，例如 电子书 site:t.me 搜索结果较多：关键词 + telegram 及其别称，例如：电子书 telegram OR 电报 OR tg 这也证明了 Telegram 的内容是可以被 Google 等搜索引擎抓取的。反观国内的互联网江湖，各自割据，搞得网民苦不堪言。就拿微信来说，你不能在 Google 或者百度搜到公众号文章，这也是庭说另开一个独立博客的原因。 也意味着如果你没有做好隐私保护，请不要在公开频道或群组发言，小心不怀好意的 网络蜘蛛 爬到你身上。 👌 Telegram 搜索引擎（非官方），可能包含不少 NSFW 内容。 索引机器人 @zh_secretary_bot 👍（支持中文搜索） @PolarisseekBot 👍（支持中文搜索） @hao1234bot @hao6bot 网页版 Lyzem Search 名刀电报搜索 sssoou.com Telegram 公眾索引系統 tlgrm：只支持用英文关键词搜索 如何通过 RSS 订阅 Telegram 频道 有些用户觉得 Telegram 用手机号码注册不安全，但是又想第一时间获得 Telegram 公开频道的更新，那么可以 借助 RSSHub 生成电报公开频道的 RSS 订阅链接，例如： https:&#x2F;&#x2F;rsshub.app&#x2F;telegram&#x2F;channel&#x2F;tingtalk 只要把 tingtalk 替换成其他公共频道的 Permanent link（永久链接）后缀即可。 须知参差多态，乃是电报之福。术业有专攻，欢迎向我推荐其它领域的优质频道： 在 Telegram 搜索 @tingbot 简单说明推荐理由 优质频道将会更新在这篇《电报教程》里，让好内容得到更多的展现 以下是我收集的频道，不代表同意其观点，也许为了丰富文章内容。如果你发现某些频道开始「作恶」了或者失效了，请联系 @tingbot 从这个列表中删除。 2021 年，你需要多运动，多吃蔬果，偶尔听 播客，放下手机早点睡觉，少看鸡零狗碎的消息。 如何加入频道方法一：直接点击频道的名字，例如 庭说，浏览器会跳转到 Telegram 客户端并进入该频道方法二：复制频道的 ID，例如 tingtalk，粘贴在 Telegram 客户端首页的 🔍 搜索框，在搜索结果中找到该频道 ✈️ 电报官方频道 频道 详情 Telegram News 👍 电报官方新闻频道。 Durov’s Channel 👍 杜罗夫（Telegram 创始人和 CEO）的频道。 Telegram Tips 👍 电报小贴士（Tips）官方频道。 Telegram APKs for Android Official channel for Telegram Android APKs. You can also download them here. Telegram for macOS Updates This channel publishes release builds for Telegram macOS. Telegram Designers 向电报提你想要的功能 @design_bot BotNews The official source for news about the Telegram Bot API. Telegram Contests Here we announce Telegram coding contests in Android Java, iOS Swift, JS, C&#x2F;C++. Desktop Themes Channel 电脑客户端主题创建指引 | Custom Themes 的简单介绍 Android Themes Channel 安卓客户端主题创建指引 | 更多技术细节参阅 Custom Cloud Themes Telegram Auditions 加入 Telegram Support Force，帮扶 Telegram 做大做强，详情参阅这份 Initiative。 ISIS Watch 电报官方反恐频道：每日汇报有多少恐怖组织相关的频道被封了。 此外，Telegram 上也有 国家或地区的领导人官方频道。 用户创建 频道 详情 TGgeek 👍 TG 极客：分享 Telegram 使用技巧、重要资讯、常见问答、中文汉化、版本更新等信息。 电报小助手 用简体中文同步翻译官方 @TelegramTips 中的小技巧。 Trending Stickers Telegram 又新增了哪些表情包。 紙飛機 欢迎搭乘纸飞机，Porsche 和你聊聊 Telegram 的大小事。播客 RSS 订阅链接。 Anti Revoke Plugin Telegram 本地消息防撤回插件，安全性未知，只支持 Windows 32 位系统。GitHub 项目地址。 电报导航 SE-索引公告板 zh_secretary👍 Telegram 中文圈资源索引服务（包含 NSFW）。 北极星搜索登记板 PolarisseekIndex 电报指南 &amp; 精品排行榜 TgTrillion CN 导航 CN_DH简单好记的中文多功能公益导航频道。 Tg Tips Tg1230瞭望台旗下 TG 电报引航：电报操作、频道、广播、群组的信息库。 電報新群推送 Telegram Group Links linkpush本頻道是新群推送頻道一般只收錄剛剛建立的群組或者人數少於 150 的群組。 🦠 疫情 频道 详情 2019-nCoV 疫情实时播报 👍 COVID-19 中文消息 by NFNF。 Coronavirus Info 各国官方疫情通报频道列表（A list of official channels with information on COVID-19）。 Financial Times: Coronavirus news COVID-19 英文消息 by 金融时报。 📰 新闻在一个后真相时代，要分清事实和观点: 对于事实，要有多个独立信源交叉验证。 对于观点，要注意论述逻辑和因果关系。 频道 详情 看鉴中国 OutsightChina 👍 一个健康的社会，不该只有一种声音。看鉴中国，每天聚焦一则关于中国的新闻事件，带你对比来自中外不同媒体多元的、不一样的观点。 乌鸦观察 👍 不定期推送新闻和杂谈。 竹新社 7×24 不定时编译国内外媒体的即时新闻报道。 有据 China Fact Check 是一个专注于对中文国际资讯进行事实核查的计划，是基于志愿和网络协作原则的事实核查计划，努力连接大学、媒体和平台三方力量。 新闻实验室 推荐订阅方可成老师的 Newsletter。微信公众号文章备份。 南方周末 在这里，读懂中国。非官方。 iDaily 每日环球视野。 新周刊 一本杂志和一个时代的体温。 南都观察 RSS 地址：https://www.nanduguancha.cn/rss 新闻联播（文字版） 《新闻联播》是中国中央电视台每日在北京时间晚间 19:00 播出的一個重点时政新闻节目，于 1978 年 1 月 1 日启播。 中国数字时代消息推送 致力于聚合「中国的社会与政治新闻，和它在世界上的新兴的角色」有关的报道和评论。 多数派Masses 我们是一群反对资本主义、反对帝国主义、反对父权制、反对一切压迫和宰制的青年。Matters 的创作空间站 | Newsletter 60 秒读懂世界 来自 60 秒读懂世界公众号。 突发新闻 突发新闻推送服务（简体中文）。 NFW News for Work, Not for Work. 电报时报 提供全天候热点中国及国际新闻，涵盖突发新闻、时事、财经、娱乐、体育，评论、杂志和博客等。 蘋果日報 Apple Daily 为香港上市公司壹传媒旗下繁体中文报纸，由大股东黎智英所创立，被民主派支持者普遍认为是香港目前唯一未被「染红」的媒体。by 维基百科 台湾 中央社 香港 苹果日报 如题。 NGOCN NGOCN 是一家中国独立媒体，非营利性质，致力向公众提供进步、负责任且多元的纪实性内容，目前由认同其理念志愿者运营。 中华人民共和国外交部发言人表态 外交部负责处理中华人民共和国政府与世界其他国家政府及政府间国际组织的外交事务。 端傳媒 Initium Media 由程式自動獲取並推送端傳媒 RSS 所有文章，链接至官网。 端传媒 RSS 链接至 Telegraph 和官网。RSS 地址：https://rsshub.app/initium/latest/zh-hans 端传媒 每日推送端传媒（付费）文章.pdf。手头宽裕，还是 付费购买端会员 或购买 新闻通讯 Newsletter。 🌐 国外媒体（简体中文） 频道 详情 纽约时报中文网 👍 The New York Times (NYT) 创刊于 1851 年，世界上最著名的报纸之一。美国严肃报刊的代表，获得过 122 项普利策奖，是获奖最多的媒体。 BBC 中文网 BBC News 是世界最大的公共广播公司，位于英国，资金主要来自英国国民缴纳的电视牌照费，是一家独立运作的公共媒体（非商业媒体，也不由英国政府控制）。 联合早报 zaobao.sg 早报 + 晚报 + 新明新闻。 路透中文网 Reuters 世界三大通讯社之一，成立于 1851 年，总部位于英国伦敦。 德国之声 Deutsche Welle (DW) 按德国公法设立的国际化公共媒体，从联邦政府获得拨款，总部位于波恩和柏林。 澳大利亚广播公司 Australian Broadcasting Corporation (ABC) 是澳大利亚的国家公共广播机构，它由政府出资，向澳大利亚和海外提供电台、电视、互联网服务。总部设在悉尼。 法国国际广播电台 Radio France Internationale (RFI) 是法国专责世界大部分地区之国际广播的电台广播机构，现隶属法国国营国际广播公司法国世界媒体旗下。by 维基百科 美国之音中文网 Voice of America (VOA) 成立于 1942 年 2 月，是美国政府对外设立和资助的国有非军事国际广播宣传喉舌，由美国国际媒体署管理，旗下拥有广播电台与电视台，总部座落在首都华盛顿。by 维基百科 华尔街日报 RSS 地址：https://feedx.net/rss/wsj.xml 俄罗斯卫星通讯社新闻 Sputnik 是俄罗斯政府控制的新闻机构今日俄罗斯媒体集团于 2014 年 10 月开通的新闻通讯社、新闻网站、广播电台与媒体新闻中心。by 维基百科 韩国新闻 朝鲜日报 + 中央日报中文版 日本新闻 共同网 + 朝日新闻中文网 + 日本经济新闻中文版 双语新闻 纽约时报双语新闻 + 中国日报网英语点津 Twitter Subscription 搬运以下 Twitter 账号：BBC News 中文、DW 中文- 德国之声、国际特赦组织中文、纽约时报中文网。 新闻播报 PDF 每天为大家送来 NYT 和 BBC 的新闻 PDF。 What’s News 推送各种英文外刊和杂志的 PDF。 以上部分介绍来自西方媒体查一查。查询可信度和倾向性，请安装 浏览器插件，或者访问 微信小程序。 国家 &amp; 发言人（已认证） 频道 详情 Gov.sg 新加坡。 Donald Trump Jr 特朗普。 💸 财经新闻 频道 详情 财经快讯 全球财经资讯 24 小时不间断直播。 FT 中文网 Financial Times（金融时报）创刊于 1888 年，编辑总部位于伦敦，2015 年被日本经济新闻收购。 💾 科技 频道 详情 Solidot 👍 奇客的资讯，重要的东西。 Readhub 👍 readhub.cn 非官方 RSS 推送频道。 Newlearnerの自留地 👍 不定期推送 IT 相关资讯。 Appinn Feed 👍 分享免费、小巧、实用、有趣、绿色的软件。 少数派 👍 少数派致力于更好地运用数字产品或科学方法，帮助用户提升工作效率和生活品质。 科技爱好者周刊 👍 记录每周值得分享的科技内容，周五发布；非官方频道。科技爱好者周刊合集。 TestFlight 科技花 发布科技新闻、App 测试版链接、软件使用相关话题。 Hacker News Top stories from news.ycombinator.com (with 100+ score). V2EX - 最新&#x2F;最热主题 V2EX 是创意工作者们的社区，可以分享生活和事业。 科技圈的日常 科技圈内的大事小事。 Telegram 中文 NEWS 聪聪 的频道：提供印象笔记、Telegram、科学上网等新闻。Telegram 知识汇总。 每日消费电子观察 不公正，不客观，不理性。 cnBeta cnBeta.COM 中文业界资讯站是一个提供 IT 相关新闻资讯、技术文章和评论的观点的中文网站。 IT 之家 RSS 地址：https://www.ithome.com/rss/ APPDO 数字生活指南 优质数字生活指南，传递数码生活和设计理念。 VPS 信号旗播报 关注 VPS 和通信自由。 硬核小卒 分享优质的科技&#x2F;商业资讯。 知乎日报 越来越难用的问答网站。 Daily Tech News 每日科技新闻。 每日 AWESOME 观察 每日更新分享最炫酷的开源项目。 LetITFly News 主题包括但不限于 Android、Windows、Web、消费电子相关，吹水为主。 Science Science News channel, videos and articles - international project, 35+ countries. OnePlus Everything OnePlus. 老毛子 Padavan 固件发布 一个路由器固件。 油油分享频道 分享开源、优秀的软件，有趣、实用的网站资源。 Widget 优质工具和软件，以及有用有趣的科技资讯。 科技互联网 即刻精选 jike_read即刻精选，以及相关讨论。这里是即友们的 TG 自留地。 Apple AppleGuide AppleBuyersGuide小胖 的苹果产品购买指南，更系统请查看 AppleGuide.cn，不断完善中。 果核 Apple Nuts AppleNuts一个果粉（Hackl0us）的闲言碎语， 用来推送苹果（Apple） 相关的技术、新闻资讯、技巧、产品&#x2F;软件心得体会等。 AppPie AppPieApple 相关的数字生活指南。 iOS 限免与优质应用推荐 iosblackteckapp免费使用正版应用，以及分享 iOS 各种高效实用应用与实用黑技巧。 iOS Releases iOSUpdatesiOS, TvOS and watchOS signing status updates. This channel will notify you when apple starts or stops signing a firmware version. Android 问道 mdqwsf该频道 apk 为个人汉化而来。 软件 简悦 - SimpRead simpread让你瞬间进入沉浸式阅读的 Chrome 扩展，还原阅读的本质，提升你的阅读体验。希望做一些让这个世界变得更美好的小事。by Kenshin网站 | 订阅中心 📚 博主 频道 详情 庭说 👍 第一时间获取博客的更新通知以及碎片化思考。 庭说 - 唠叨频道 @tingtalk_all 发布一些主频道 @tingtalk 之外的增量更新以及碎片化思考。 小破不入渠 👍 科技评论人 Jesse Chan，博客是 大破进击。 一天世界 👍 一天世界，昆乱不挡。不鸟万如一主理。IPN 出品。 caoz 的梦呓 👍 认识曹政之后，感觉互联网终于入门了。by Fenng ZUOLUOTV 👍 科技 &#x2F; 旅行 &#x2F; 摄影 &#x2F; 生活方式 &#x2F; 博客 不求甚解 👍 Newlearnerの自留地 编辑；设计师 oooooohmygosh 的代言人。 小道消息 大道无形，小道消息；公众号备份站点。 卖桃者说 博客是 MacTalk：池建强的随想录关注技术和人文。 数字移民 无法肉身移民的情况下，在数字生活上追求一定的自由；博客。 Real Spencer Woo 开发者 &#x2F; 设计师 &#x2F; 少数派 &#x2F; 学生 &#x2F; 博客。 Sukka’s Notebook Belongs to Hexo dev team &#x2F; 博客。 扫地僧笔记 每天所见所闻所想，是个树洞。 一方天地 心留一方天地，世界依旧美好。 湾区日报 关注创业与技术，不定期推送 5 篇优质英文文章。 海龙说 牢记梦想，自然生长。by 郝海龙的博客 荔枝木 这个世界很复杂，我尝试着去理解它。 KAIX.IN 思考碎片，博客 更新。 TSBBLOG 影子的博客：独立观察及记录。 AK 讲废话 科普视频系列：无线技术、显示技术、翻墙技术…… P3TERX ZONE P3TERX 读作 Peter X。 值物志 分享各种值得尝试的事物：值得读的书、值得用的软件、值得看的电视剧…… 小虎の自留地 讨论家装心得或者有趣实用的家具电器。 Leonn 的博客 低价主机（VPS）资源。 Yachen’s Channel 刘亚晨是 Surge 的开发者| Yachen’s Blog BennyThink’s Blog 随便分享点什么，可能是某部剧，可能是某首歌，可能是一点点感动的瞬间，也可能是我最爱的老婆。 MolunSays 希冀笔尖之下，世界兴旺繁华 | 博客 日常人间观察 关心科技 &#x2F; 人文 &#x2F; 艺术 &#x2F; 城市公共空间 &#x2F; 女性和性别议题 &#x2F; 劳工权益 &#x2F; 个体叙事 &#x2F; 电影 &#x2F; 音乐 &#x2F; 书 &#x2F; 星星…… In The Flux 关于文化、艺术与技术的信息流。 为也行 「书籍 | 电影 | 资源 | 技巧 | 摸鱼图」大多原创，少部分转发。 Jerry Zhang 的频道 在渥太华的长春人。博客：Overflow，向信息过载的世界大喊。播客：《科技聚变》（TechFusion），我们谈论有关互联网的一切。 老人和糟 没有频道简介，科技相关。 Karen 医生の日常 一个小医生的通讯站。不想出名，只传播一些信息和科普。谨慎关注，会发一些血淋淋的图片。 人海拾贝FlipRadio 翻转电台的 Channel，一些零零散散的要分享的东西。 Find Blog 发现优秀的博客与创作者。 TomBen’s Web Excursions PhD Student、Productivity Enhancer、Writing Enthusiast 博客 | 少数派 熊言熊语 「熊言熊语」是一档关注学习分享和知识科普的 播客 栏目，我们希望用声音记录改变与成长。思考问题的熊和他的朋友们一起聊学习工作、聊科研科普。博客 | Newsletter Hell Cell 功能教学 通过 YouTube 视频讲解一些实用软件那些有用有趣的功能。 The Sociologist 我们只谈论记忆，因为不再有记忆。 每日摄影观察 一个不严肃的摄影频道。 中國家地理雜誌中文版 Hi 探險家，和國家地理一起探索世界吧！ EdNovas 的小站 @ednovas2网站：ednovas.xyz导航：navigate.ednovas.xyz gledos 的微型博客 gledos_microblogging请记住我们，因我们也在这世上爱过和笑过。 Route 66 Blog landofmaplex网站：留学、移民、程序员、死磕北美、加拿大、美国、跑路、移民生活。 中文独立博客列表 by timqian 🔔 RSS 频道 详情 RSSHub 布告栏 万物皆可 RSS。 All About RSS 关于 RSS 技术的应用、周边、介绍、方法、教程、指南、讨论、观点。 RSS 频道收集 收集推送 RSS 的频道，把 TG 变成 RSS 阅读器。 🎙 播客采用 RSS 订阅的播客，永远都不会过时。 频道 详情 「利器x播客」计划 官网 播客先声 分享关于播客的一切。by Zac 中文播客精选 分享精选优质中文播客，目前推荐单期节目为主。by 白昼电台 的主播 Stella Your Daily Dose of Podcast 每天推荐一集让人心潮澎湃、若有所思、打开新世界大门的播客节目。by 穿堂风推荐的播客会同步更新在 Medium我在豆瓣上分享了 400 集播客节目，有什么用？ 交差点 Technology alone is not enough. 不客观 Not Objective 一档搭建在 Telegram 的简易播客，纯主观感受。by 郝海龙 白昼电台 The Day 黑夜已深，白昼将近，我们就当脱去暗昧的行为，带上光明的兵器。 维生素 E 经济学与哲学知识分享。 Go 夜聊 一档由杨文和欧长坤主持的针对 Go 语言的播客节目 阿乐杂货铺 这里每日推送小人物播客及播客周边；职业发展、自我成长、读书电影、海外工作与生活碎片。 🎵 音乐 频道 详情 知音 👍 发一些关于音乐的东西。 Imusic 音乐，就是理想的挽歌，年代久远，依然飘扬。 杂鱼Music Channel 我相信，爱音乐的人都有着一颗柔软的心。 音乐世界 温柔被我唱成了歌，伴你人山人海不停留。 心声：音乐分享频道 分享一些能引起共鸣的音乐。 每日一歌 愿你也能在这里找到属于你自己的共鸣。 Classical Music 一起来听古典音乐吧。 蛙音通讯 Feels wonderful again man. 无损音乐频道 分享无损音乐、高品质音乐、原碟整轨分轨音频。 浦镇青年 李志。 崔健无损 中国大陆摇滚先驱者。 音乐分享频道 一般为无损音乐。 音乐屋 发现音乐新世界：live、黑胶、磁带 CXPLAY MUSIC 单曲音乐试听，专辑存放在 这。 下载音乐，还可以查阅下文中提到的音乐机器人。 🏫 读书人类的悲喜并不互通，但读书是走向共同理解的捷径。 频道 详情 Word Power Made Easy 利用词根（原始印欧语、拉丁语、古希腊语）学习英语单词。 英语精读学习 夜空中最亮的星，就是你自己！我们一起精读英语，一起进步，遇见更好的自己吧！资料不定时更新哟！ ENGLISH PODCASTS INFINITY PODCASTS CHANNEL WITHOUT ANY LIMITS. 中文社科讲座资讯 一个讲座信息聚合和 PPT 共享平台。 ReadFine 电子书屋 致力于电子书分享的读书频道。EPUB 电子书一站式阅读体验（包括豆瓣评分、书籍简介、封面截图），一键下载，享受读趣。 The Economist Sharing Channel Sharing the Economist and E-books every week. 什么书值得读 仅推送某亚原版资源，可同时下载 .azw3 .epub .mobi 的电子书。 好书分享频道 学习，是一辈子的大事。 小声读书 一个探索数字阅读可能性和未来的开放项目，致力于打破信息茧房，挖掘价值信息。 值得一看的文章 阅读更少，收获更多。 云上报刊亭 英文报刊杂志、电子书、报纸和外文杂志精选。 Λ-Reading 分享书和阅读、认知科学、科技哲学、新科技以及其它给生活带来一丝美好的事物 | Newsletter 臭（xiù）文字 诗歌频道；我是一个嗅觉特别发达的人，你说，然而，没有一种艺术可供我的鼻子用武，只有生命可以。 已有丹青約［書畫］ 高清油画档案（超过两万张）。 阿银书屋 偶尔更新，没事来看看。 红楼梦 每日一章 💞DreamOfRedMansions。 插播一个免费的广告：学英语，推荐购买郝海龙老师的《英语自学手册》（￥119）。 🚀 翻墙软件 频道 详情 Clash .NET 公告 👍&#x2F; A Clash GUI Proxy For Windows Based On .NET 5 Fndroid 的日常 👍 Clash for Windows Clash for Android Channel A Graphical user interface of Clash for Android Surfboard News 安卓专享的翻墙客户端，但不支持 SSR。用户手册 SagerNet Apks 支持 SOCKS、HTTP(S)、Shadowsocks、ShadowsocksR、VMess、VLESS、Trojan……等协议SagerNet 官网 AnXray Another Xray for Android GitHub Shadowrocket News iOS 上小火箭 Quantumult News Quantumult 的非官方频道。 Quantumult X News 此频道用于发布 Quantumult 与 Quantumult X 的相关资讯。 迷雾通（Geph） 与众不同的开源翻墙软件，提供完全免费的中速浏览，够浏览新闻、查邮件、看标清视频等。超快速度的付费 Plus 账号仅需 €5&#x2F;月。截至 2021 年 5 月 29 日，暂不支持 iOS 设备。 协议 &amp; 脚本 &amp; 规则 频道 详情 V2Fly Shadowsocks 是一个纯粹的代理工具，而 V2Ray 定位为一个平台，任何开发者都可以利用 V2Ray 提供的模块开发出新的代理软件。by 新 V2Ray 白话文指南 ACL4SSR https://github.com/ACL4SSR/ACL4SSR 官方频道。 QuanX &amp; Surge &amp; Loon 脚本收集 各种脚本。 QuantumultX 教程&amp;API&amp;解析器 如题。 Cool Scripts QuanX, Loon, Surge, JsBox, Pythonista, Scriptable, Shortcuts 等脚本分享。 DivineEngine 神机规则 评测 频道 详情 毒药机场评测 由于大陆地区网络环境十分复杂，测速不代表推荐。另外，有些机场会泄露个人信息，选购时多加搜索或者进入机场用户群打探打探。 品云☁️测速 细品各种云☁️。PinYun is a non-profit organization dedicated to making the internet a better place for everyone. 科学上网与机场观察 科学上网与机场相关观察、点评、随想和新闻资讯。 关联阅读 番茄食用指南（科学上网教程） | 庭说 番茄种植指南（梯子搭建教程） | 庭说 🗄️ 搬运 频道 详情 煎蛋无聊图 自动抓取煎蛋首页推荐无聊图及其评论。 内涵段子：皮一下 如题。 美图与沙雕 如题。 糗事百科 如题。 心惊报 又一个沙雕图频道，每日随缘更新。 你知道的太多了 不定期发布和转载各类不一定靠谱的内幕、流言蜚语、小知识等。 蛋挞报 分享阅读体验。 微信搬运工 有些微信的内容分享了之后就和谐了，本频道可以做个备份，以及丰富电报上的中文内容（不可否认还是有很多非政治的优质内容在微信公众号里）。 微博精选 来自微博的文章、资源和观点。 豆瓣精选 豆瓣书影音，以及相关讨论。 鹅组精选 豆瓣鹅组 非官方搬运。 即刻精选 精选即刻 app 热门话题更新。我的即刻 ID 是 Dr_Ting。 你不知道的内幕消息 同时抓取来自即刻 app 的 #大公司的负面新闻。 Matters 閲讀精選 matters.news 一個自主、永續、有價的創作與公共討論空間。 🆓 资源 频道 详情 Google Play 限免信息 不定时推介 Play Store 上的限免游戏和 App。 Price Tag 推荐 App 限免降价，推送好物好券。 纯粹的 App Store 应用推荐 iOS 实用免费、精选限免、优质冰点应用推荐。 反斗限免 这里有反斗软件和反斗限免的文章更新。更新频繁高。 如有乐享 更新 如有乐享博客 的内容：云服务器、优惠活动、羊毛信息以及各种 Bug。 iShare News 一个没有简介的资源分享频道。 Zapro Notice 软件分享。 App 喵 破解软件资源共享。 Google Drive 资源 各种 Google Drive 资源，包括电影、电子书、无损音乐等，10 万+ 关注。 Google Voice 靓号 一个 GV 卖家。 Windows 10 激活码分享 🤫 Office Tool Plus Office Tool Plus 是一个用于部署、激活Office、Visio、Project 的小工具。借助本工具，你可以快速地完成各项Office 部署工作。 你有一个打折需要了解 分享 Steam 的周榜、折扣、资讯、喜加一等。 52 破解信息 吾爱破解。 擅长搜索的高木同学 gaomutongxue 黑科技软件资源分享 kkaifenxiang 分享免费实用高效率网络资源、黑科技软件、实用黑技巧。 Discover good software ksc666 分享 Magisk、Riru、LSPosed、虚拟框架、Xposed 模块、Magisk 模块、Android、Windows……等软件。 破解安卓 VPN 软件 vpn_cracked 发布原创破解的 VPN 和各种软件，以及分享各类资源，多位安卓逆向大佬坐镇。 万能福利吧 @wnflb分享有趣的信息，包含网站、活动、网购、下载综合症、好孩子看不见等福利。 🎞️ 视频电影 &#x2F; 剧集 四库全书 video4lib 👍一个不断收集互联网有价值内容的企划。 电影频道 TGDY188精选国内外高分电影。 华联社电影频道 Cctv365 霸王龙发布频道 T_rex2333专注于韩美剧，选取优质影片源。 苍炎影院 cangyanmovie分享最新最热门的优质电影。 双语短视频合集 english_bilingual学习英语，了解世界。 动漫 海贼王更新提醒 tingtalk_op@TingTalk 子频道，试运营。由初中开始追 One Piece 的 Dr_Ting 创建， Rick and Morty@TingTalk 子频道，试运营。曾经把《瑞克和莫蒂》作为练口语的 素材，听了上百遍，但效果甚微，Wubba Lubba Dub-Dub。 下载站 Odyssey+ odysseyplus公益服食用指南。 PT 资讯频道 @PrivateTrackerNewsPrivate Tracker 资讯以及开放注册信息推送；PT 可以简单理解为私有化的 BT。 Sync 资源更新 @shenkey只发 key。 电视机顶盒 &amp; 手机影视 App @tvbox001 可看港台电视直播、美剧等。 😺 其它软件 Aria2 Channel @Aria2_ChannelAria2 完美配置、Pro Docker、Pro Core、一键安装管理脚本增强版 (GNU&#x2F;Linux)。 未分类 NBA tingtalk_nba@TingTalk 子频道，试运营。从高中开始只练跳投，因此严重偏科，不会突破，不会抢篮板，不会防守，但崴脚少了，命中率高了。 频道 详情 iYouPort IYP 不是过眼云烟的新闻网站，我们提供实战能力，这里是值得您反复回看的档案室。 安全上网注意事项 转载一些关于安全上网的文章，这些文章都比较浅显。 博海拾贝 博海拾贝 的网站：bh.sb 回形针PaperClip &amp; 灵光灯泡 回形针内容推送。 合租 Netflix、YouTube、Spotify、Office 365、HBO、Apple、Surge…… History Digging Past. Photos from Past who shaped today. 每日无数猫 让我们打造一个全是猫的世界！ฅ^•ﻌ•^ฅ NS 新闻转报 任天堂（Nintendo）相关的新闻。 基督讲道 基督讲道资源频道。 就要造反 此频道立足生活，以非常古怪的文字风格进行生存经验书写，绘制景观与消费社会中极具现实性的个案，以此为个体提供可操的、创造性的抵制策略与造反计谋。为一切造反者辩护，为所有无用与丰饶辩护。 残障之声 在态度和环境障碍相互作用存在的情况下，提供合理便利是全社会需要一同去解决的问题，残障人士应当理直气壮地要求这种权利和便利，去定义一个无障碍的社会。 每日一句 meiriyiju每天一句心灵鸡汤，配上必应每日壁纸。 Leanote leanote今天的定位（今天的是什么日子）：单向历、mono日签等 🤖 Bot 推荐Bots（机器人）就像运行在 Telegram 内部的小程序。借助 Telegram 开放的 APIs，可以实现很多让你意想不到的功能。 BotNews：The official source for news about the Telegram Bot API. 💠 内联机器人在任意对话界面的消息编辑框，输入 Inline Bots 的名字，即可将 Ta 们唤醒（Just type @inlinebots keywords in any chat.）。 Bot Info @bing 图片搜索 by Bing（支持中英文）。 @bold 👍 使用 Markdown 编辑消息（有字数限制）。 @coub Coub 是一个视频共享网站（时长十秒的循环视频）。 @creationdatebot 获取注册 Telegram 的日期。 @fanyi_bot 为全世界语言提供中文翻译。 @foursquare 帮你找到附近的餐馆或附近的地方，并将其地址发送给朋友。 @gamee 在群组中输入 @gamee，选择一个游戏，立刻和你的朋友 在 Telegram 上玩小游戏。 @gif 👍 GIF 动图搜索，支持中文。例如 @gif 你好。 @imdb 查看影视作品在 互联网电影资料库（IMDb）的评分。 @GoogleDEBot 在任意聊天框使用 Google 搜索引擎。 @like 👍 添加 emoji-based like buttons，例如 👍 &#x2F; 👎。在搜索框输入 @like，预设一些喜欢的投票符号（最多 6 个），然后就可以在聊天框输入 @like 调用这些预设。 @music 帮你找到动听的古典音乐。 @pic 图片搜索 by Yandex（支持中英文）。 @QuizBot 答题机器人：创建一份只有单选题的考卷。点此 开始测试你对 Telegram 的了解程度。访问 quiz.directory 查看更多问卷。 @sticker 👍 检索所有与 Emoji 相关表情包。例如 @sticker 😎 。 @telegraph 👍 登录和编辑 Telegraph 文章，并 统计 telegra.ph 的浏览量。 @vid 帮你查找 YouTube 视频（支持中文搜索）。 @vote 投票机器人。 @wiki 维基百科。搜索中文条目 @wiki zh 猫；搜索英文条目 @wiki en cat @youtube 帮你查找 YouTube 视频（不支持中文搜索）。 🧱 非内联机器人以下 Bots 不能在聊天窗口调取使用。 🧡 RSS 机器人 （如果）你不懂得 RSS，上网的效率和乐趣都要大打折扣。by 阮一峰 相比于传统的 RSS 客户端，Telegram 上的 RSS 订阅器的优点是： 自动记录上次浏览的位置 某些 RSS Bots 支持 ⚡ INSTANT VIEW 在 All About RSS 里推荐了很多 RSS Bots： @FeedManBot @TheFeedReaderBot：不仅可以订阅 RSS 源，还可以在 Telegram 上浏览 Twitter。 @Feed2Telegram_bot：免费用户只有 5 条 Feeds；发送 Twitter（推特）链接，即可追踪。 @el_monitorro_bot @newlearner_rss_bot @NodeRSS_bot …… 以上大部分 Bots 都能免费使用，但是保不齐哪天服务器撑不住，就停止运营了，所以记得定期导出 OPML 文件作为备份。 如果有 VPS，自己搭一个专用的 RSS Bot 会是不错的选择。 🎵 音乐机器人在 Telegram 上实现点歌自由，或者像我一样建立频道，存放喜欢的歌单：@tingtalk_fm 找一个音乐机器人，例如 @haoyybot 搜索歌名，选择歌曲，下载后转发到频道 修改（Edit）歌曲信息，加入标签（方便搜索）和链接（例如 YouTube 上的 MV） 如遇到版权限制，无法下载，换用其它歌曲 Bots： @ChinoNyanBot @vkm_bot @vkmusic_bot @u2bu_mp3_bot 听歌识曲 @SongIDbot 下载 YouTube 音频 @YTAudioBot 下载音乐、歌词、视频等媒体 @getmediabot 内置音频播放器 长按住「下一首」 和「上一首」按钮可以快进和倒带。Press and hold on the Next and Previous buttons to fast-forward and rewind. 💽 DC 查询Telegram 的服务器分布在世界各地的数据中心（Data Center，简称 DC）。如何查询自己所在的数据中心（好像没啥用）： 第一步，在隐私和安全设置中，（临时）开启所有人都能查看你的头像（Profile Photos）。 第二步，选择一个查询 Bot，例如 @WooMaiBot 第三步，发送 /dc，即可获得你所在的数据中心。 🎁 其它机器人 Bot Info @bingdict_bot 基于 Bing 开发的中英文翻译机器人。 @BotsArchiveBot 收集了上千个 Bots（仅限英文版）；官网。 @CorsaBot 👍 Make Instant View from any article. 快速把文章把文章备份到 Telegraph。 @cnLottery_bot Telegram 群组抽奖工具。 @DogFatherPublicbot App Store 价格监控。 @githubbot 推送 GitHub 仓库的动态。 @GmailBot 👍 在 Telegram 上收发 📧 Gmail。 @he_weather_bot 和风天气小棉袄。另外还有 WIEN 产品的 广州、深圳、东莞 的天气速报频道。 @IFTTT With this bot you can use IFTTT to link your Telegram groups or channels to more than 360 other services like Twitter and Instagram, or connected devices like Hue lights and Nest. @jobs_bot This bot lists career opportunities at Telegram and accepts candidates’ applications. Available at https://telegram.org/job @LivegramBot 👍 不加好友也能私聊，可用于收集反馈及绕开 +86 手机号码的限制。因为经过一层转发，消息一旦发送，便无法删除，但有个短暂的修改期。 @MakeQrBot 发送文字，生成对应的二维码。 @sssoou_bot Telegram 搜索，支持中文。 @Stickers 👍 创建属于自己的表情包。 @tweet_for_me_bot 在 Telegram 上发布 Twitter 动态。 @tgstogifbot 把 Telegram 上 tgs 格式的表情包转换为 gif 格式。 @utubebot 同时下载 YouTube 的视频和音频，不过会推送一些广告。 @verifybot 加了官方认证后，名字后面有个 ✅（verify a big andactive official channel, bot or public group）。 @zzzdmbot 真正值得买推送机器人，可以根据关键词订阅推送什么值得买精选优惠信息。 更多 Bots 推荐，请参阅 Raw 博客 以及 合集网。 👥 群组管理 群组人数最高 20 万。转换为广播组（Broadcast Group）之后，人数将不受限制，但只有管理员可以说话，但是成员仍然可以加入语音聊天。注意，切换之后，将不能回退到普通群组。 静音群组只有在 @ 提到你、 Reply 回复你和 Pin 管理员发布群通知时才会收到通知。 新加入的成员可以看到全部的群聊历史记录（New members can see the entire message history when they join）。 加入群组之前，可看到（单向）好友是否在列。如果不想让好友知道你加入了某个群组，注册一个小号吧。 支持在任何设备上发起语音聊天（Voice Chats） 在 Telegram Desktop 和原生 macOS app 中，支持设置发言快捷键，例如大小写锁定键。（On Telegram Desktop and in the native macOS app, you can choose a push-to-talk key for Voice Chats, to control your mic even when Telegram is not focused. At long last, we’ve found a use for your Caps Lock key.） 需要在翻墙服务&#x2F;软件上开启 UDP 转发。 截至 2021 年 1 月 13 日，语音聊天支持 5000 人同时参与。Voice Chats for up to 5,000 participants. 主持人可以控制发言者的音量（Adjust the Volume），这个设置是全局的，对所有听众有效。 庭说读者群组是 @tingtalk_group。 👮 管理之道 可删除成员的单条消息或全部消息。 慢速模式（Slow Mode）：在 10 秒 &#x2F; 30 秒 &#x2F; 1 分钟 &#x2F; 5 分钟 &#x2F; 15 分钟 &#x2F; 1 个小时内，成员只能发送一条消息，这样可以使小组中的对话更加有序，也可以提高每条信息的价值。 群组权限：管理员可以限制所有成员或单个成员只能发送特定类型的内容（Partial bans），如此一来，你便可建立一个没有表情贴纸或者 gif 的高质量交流社区。或者甚至完全限制成员发送信息，让管理员彼此交谈，而群成员则默默地旁观。 可对群主（creator）及管理员（administrators）设置自定义头衔（Custom title）。 管理日志（Recent Admin Actions）：当多个管理员在一起工作时，很容易搞不清楚哪个管理员或管理机器人，在什么时候做了什么。所以 Telegram 的管理员页面增加了「最近动作」功能。用于存储过去 48 小时内在组中执行的所有服务操作的日志，仅对管理员可见。 2020 年 9 月 30 开始，管理员可以匿名发布消息了（Anonymous Group Admins）。 成员超过 500 人后，自动开通群组分析功能。Owners of large groups with over 500 members can view beautiful, detailed graphs about its activity and growth. 🔐 管理机器人 在群组设置里搜索 Bots 名字，即可添加，然后赋予尽可能少的权限。 @policr_mini_bot 开源验证机器人，详情参见 官网 赋予 Delete messages 和 Ban users 权限 @DeleteEventsBot 或 @AntiServiceMessage_Bot 删除冗余的事件通知，例如谁加入了群组。强烈建议群组管理员装备上这个 Bot，减少信息噪音 赋予 Delete messages 权限 @areply_bot 自动解除关联频道（Linked hannel）转发到群组的自动置顶消息，并恢复之前的置顶消息 赋予 Pin messages 和 Delete messages 权限 其它管理机器人： @keyworddel_bot：自动删除群组推广、广告、博采等消息。 SCP-079-INFO：免费并开源的群组管理机器人，需 申请 通过后才能使用。查看项目介绍 🤐 私密聊天Cloud Chats（默认聊天模式） 客户端 -服务器 &#x2F; 服务器 - 客户端 信息存储在 Telegram Cloud 中进行加密，这使云消息既安全又可以立即从任何设备访问，即使丢失了设备。所以你不需要将所有的信息历史记录存储在手机上，当你需要的时候，你可以随时在 Telegram 下载（缓存）旧的信息和媒体，这为你节省了大量的磁盘空间和内存。 Secret Chats（不支持在 Windows 和 Web 上发起） 客户端 - 客户端 聊天记录不能云备份，因为私人数据没有经过 Telegram 的同步服务器，所以没有任何人可以破解，包含 Telegram 团队本身。 关联阅读：为什么电报的端到端加密不是默认的？ 只能通过原始设备访问历史消息。退出并再次登录，将失去所有的秘密聊天记录。 可设置阅后即焚（self-destruct）计时器，自动销毁消息或媒体文件（只适用于计时器设置后发送的消息，对早期的信息没有影响）。 不能转发消息。 不能编辑已发送的消息。 Android 设备不能截屏；iOS 设备可以截屏 ，但对方截屏时你会收到通知。不过，只建议与你信任的人分享敏感信息。 毕竟，对方可以用另外一台设备给屏幕拍照。 删除发送方的消息，接收方那边也会强制删除。 😎 TelegraphTelegraph 一个极简的匿名内容发布工具（Minimalist publishing tool）。如果内容侵权了，例如使用有版权的图片，可能文章会被投诉下架。 ☝️ 用法一此法不需要注册账号与下载软件。 在手机或电脑的浏览器的地址栏输入 telegra.ph 写文章 发布（PUBLISH） ⚠️ 内容发布之后，只要清除浏览器缓存，便无法再编辑文章，也不能追溯到文章作者。 ✌️ 用法二通过 Telegraph 机器人 @telegraph 管理文章： 能看到你发了多少篇文章，多少人看了（但是读者依旧看不到作者是谁）。 在任意聊天窗口输入 @telegraph，即可弹出你发布的所有文章。 📝 发布流程 在 Telegram 打开 Telegraph 的小管家 @telegraph 根据提示配置 Account 写文章：Author 可以写频道或者群组的 Public link（例如 https://t.me/tingtalk），读者点击作者即可跳转。 发布（PUBLISH） ✍️ 修改流程在任何一个设备（across any number of devices）都可以再次编辑文章的标题、作者和正文（除了文章链接）： Log in as *** on this device 返回 @telegraph My posts，点击文章的标题 电脑：自动跳转到浏览器打开，然后在右上角找到 EDIT 手机：点击界面的右上角 3 个点，选择 Open in… 用浏览器打开，滑倒文章底部即可看到 EDIT 🔗 如何让文章链接更美观URL &#x3D; https://telegra.ph&#x2F;首次输入的标题-首次发表时的月份 -首次发表时的日期 如果你用中文撰写标题，例如《选择 Telegraph 的 10 个理由》，那么文章链接会变得又臭又长，且不能从链接或者文章主题： https:&#x2F;&#x2F;telegra.ph&#x2F;%E9%80%89%E6%8B%A9-Telegraph-%E7%9A%84-10-%E4%B8%AA%E7%90%86%E7%94%B1-12-04 要想得到一个 friendlier-looking link，首次编辑请使用英文标题： 英文单词全部小写：10 reasons to choose the telegraph 把 the、a、an 等去掉：10 reasons to choose telegraph 用连字符 - 代替标点和空格：10-reasons-to-choose-telegraph 是否可以精简或者采用另外一种翻译：why-telegraph 再用 Edit 功能修改标题为中文：选择电报的 10 个理由。 📝 如何让文章排版更美观 使用 Markdown 写文章（例如 Typora） 复制 Markdown 预览（不是源代码） 粘贴到 telegra.ph，即可快速排出精美的文章（不支持某些格式，例如多级项目列表） 🔗 关联阅读 Telegram FAQ：电报常见问题（英文网页）。 The Evolution of Telegram：电报的演化（简史）。 Articles about Telegram：这些文章涵盖了 Telegram 及其赞助商、全球企业家帕维尔•杜罗夫（Pavel Durov）。 Telegram Messenger - Twitter：Keep evolving and stay in touch，官方推特会介绍各种 #TelegramTips。 Telegram - reddit Telegram logos：Please feel free to use these Telegram logos. Just make sure people understand you’re not representing Telegram officially. A long way from Moscow：’Russia’s Mark Zuckerberg’ took on the Kremlin - and lost his country by Christopher Miller Telegram X 介绍视频：超级炫酷，一定要看。 给电报找 Bug：欢迎安全研究人员将 Ta 们在 Telegram 应用程序或协议中发现 🧐 的任何问题提交到 security@telegram.org。 根据问题的严重程度，奖金从 500 美元到 10 万美元或更多。 Telegram 背后的故事 Telegram 传奇：一个关于俄罗斯富豪、黑客、极权和阴谋的创业故事 - 霍炬 关于 Telegram 的一些事 - 守望的麦子：我更加相信一定会有越来越多的理想主义者，他们相信 平等 和自由，坚守信念和价值观，每天充实地生活着。 我为什么选择 Telegram 来运营粉丝社群 | 规则、经验和思考 - 罗磊 Telegram 教程全指南 by TG极客 Telegram 群组、频道、机器人 - 汇总分享 - 聪聪 Blog Telegram 频道：Newlearnerの自留地 导航页 Stay home. Wash your hands. Be safe. And stay tuned for our next updates! It is already brewing in our dungeons! 呆在家，常洗手，敬请关注，更强大的 Telegram 已经在我们的地牢里酝酿中了！ 📞 与我联系欢迎读者在 Telegram 搜索 @tingbot 与我取得联系：指出此文疏漏，推荐优质频道和机器人，一起跨越数字鸿沟，共享信息自由。","categories":[],"tags":[{"name":"网上冲浪指南","slug":"网上冲浪指南","permalink":"https://blog.ehzyil.xyz/tags/%E7%BD%91%E4%B8%8A%E5%86%B2%E6%B5%AA%E6%8C%87%E5%8D%97/"},{"name":"Telegram","slug":"Telegram","permalink":"https://blog.ehzyil.xyz/tags/Telegram/"}],"author":"ehzyil"}],"categories":[{"name":"技术","slug":"技术","permalink":"https://blog.ehzyil.xyz/categories/%E6%8A%80%E6%9C%AF/"},{"name":"记录","slug":"记录","permalink":"https://blog.ehzyil.xyz/categories/%E8%AE%B0%E5%BD%95/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.ehzyil.xyz/categories/Linux/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"工具","slug":"工具","permalink":"https://blog.ehzyil.xyz/categories/%E5%B7%A5%E5%85%B7/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.ehzyil.xyz/categories/Docker/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.ehzyil.xyz/tags/SpringBoot/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://blog.ehzyil.xyz/tags/Mybatis/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ehzyil.xyz/tags/MySQL/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.ehzyil.xyz/tags/Docker/"},{"name":"linux","slug":"linux","permalink":"https://blog.ehzyil.xyz/tags/linux/"},{"name":"Java Script","slug":"Java-Script","permalink":"https://blog.ehzyil.xyz/tags/Java-Script/"},{"name":"Java","slug":"Java","permalink":"https://blog.ehzyil.xyz/tags/Java/"},{"name":"AES","slug":"AES","permalink":"https://blog.ehzyil.xyz/tags/AES/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.ehzyil.xyz/tags/Spring/"},{"name":"Azure","slug":"Azure","permalink":"https://blog.ehzyil.xyz/tags/Azure/"},{"name":"并发","slug":"并发","permalink":"https://blog.ehzyil.xyz/tags/%E5%B9%B6%E5%8F%91/"},{"name":"CentOS","slug":"CentOS","permalink":"https://blog.ehzyil.xyz/tags/CentOS/"},{"name":"网盘","slug":"网盘","permalink":"https://blog.ehzyil.xyz/tags/%E7%BD%91%E7%9B%98/"},{"name":"服务器","slug":"服务器","permalink":"https://blog.ehzyil.xyz/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"rss","slug":"rss","permalink":"https://blog.ehzyil.xyz/tags/rss/"},{"name":"render","slug":"render","permalink":"https://blog.ehzyil.xyz/tags/render/"},{"name":"Telegram","slug":"Telegram","permalink":"https://blog.ehzyil.xyz/tags/Telegram/"},{"name":"JVM","slug":"JVM","permalink":"https://blog.ehzyil.xyz/tags/JVM/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.ehzyil.xyz/tags/Leetcode/"},{"name":"软件","slug":"软件","permalink":"https://blog.ehzyil.xyz/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"异常","slug":"异常","permalink":"https://blog.ehzyil.xyz/tags/%E5%BC%82%E5%B8%B8/"},{"name":"AOP","slug":"AOP","permalink":"https://blog.ehzyil.xyz/tags/AOP/"},{"name":"日志","slug":"日志","permalink":"https://blog.ehzyil.xyz/tags/%E6%97%A5%E5%BF%97/"},{"name":"图片上传","slug":"图片上传","permalink":"https://blog.ehzyil.xyz/tags/%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0/"},{"name":"Quartz","slug":"Quartz","permalink":"https://blog.ehzyil.xyz/tags/Quartz/"},{"name":"git","slug":"git","permalink":"https://blog.ehzyil.xyz/tags/git/"},{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"https://blog.ehzyil.xyz/tags/IntelliJ-IDEA/"},{"name":"JSP","slug":"JSP","permalink":"https://blog.ehzyil.xyz/tags/JSP/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.ehzyil.xyz/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"标签插件","slug":"标签插件","permalink":"https://blog.ehzyil.xyz/tags/%E6%A0%87%E7%AD%BE%E6%8F%92%E4%BB%B6/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.ehzyil.xyz/tags/Linux/"},{"name":"Yauaa","slug":"Yauaa","permalink":"https://blog.ehzyil.xyz/tags/Yauaa/"},{"name":"node.js","slug":"node-js","permalink":"https://blog.ehzyil.xyz/tags/node-js/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"https://blog.ehzyil.xyz/tags/Spring-Security/"},{"name":"Nacos","slug":"Nacos","permalink":"https://blog.ehzyil.xyz/tags/Nacos/"},{"name":"网上冲浪指南","slug":"网上冲浪指南","permalink":"https://blog.ehzyil.xyz/tags/%E7%BD%91%E4%B8%8A%E5%86%B2%E6%B5%AA%E6%8C%87%E5%8D%97/"}]}